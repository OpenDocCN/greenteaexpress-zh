["```py\nfrom scipy.stats import weibull_min\n\ndef weibull_dist(lam, k):\n    return weibull_min(k, scale=lam) \n```", "```py\nlam = 3\nk = 0.8\nactual_dist = weibull_dist(lam, k) \n```", "```py\nimport numpy as np\nfrom empiricaldist import Cdf\nfrom utils import decorate\n\nqs = np.linspace(0, 12, 101)\nps = actual_dist.cdf(qs)\ncdf = Cdf(ps, qs)\ncdf.plot()\n\ndecorate(xlabel='Duration in time', \n         ylabel='CDF',\n         title='CDF of a Weibull distribution') \n```", "```py\ndata = actual_dist.rvs(10)\ndata \n```", "```py\narray([0.80497283, 2.11577082, 0.43308797, 0.10862644, 5.17334866,\n       3.25745053, 3.05555883, 2.47401062, 0.05340806, 1.08386395]) \n```", "```py\nfrom utils import make_uniform\n\nlams = np.linspace(0.1, 10.1, num=101)\nprior_lam = make_uniform(lams, name='lambda') \n```", "```py\nks = np.linspace(0.1, 5.1, num=101)\nprior_k = make_uniform(ks, name='k') \n```", "```py\nfrom utils import make_joint\n\nprior = make_joint(prior_lam, prior_k) \n```", "```py\nlam_mesh, k_mesh, data_mesh = np.meshgrid(\n    prior.columns, prior.index, data) \n```", "```py\ndensities = weibull_dist(lam_mesh, k_mesh).pdf(data_mesh)\ndensities.shape \n```", "```py\n(101, 101, 10) \n```", "```py\nlikelihood = densities.prod(axis=2)\nlikelihood.sum() \n```", "```py\n2.0938302958838208e-05 \n```", "```py\nfrom utils import normalize\n\nposterior = prior * likelihood\nnormalize(posterior) \n```", "```py\n2.052573567183434e-09 \n```", "```py\ndef update_weibull(prior, data):\n  \"\"\"Update the prior based on data.\"\"\"\n    lam_mesh, k_mesh, data_mesh = np.meshgrid(\n        prior.columns, prior.index, data)\n\n    densities = weibull_dist(lam_mesh, k_mesh).pdf(data_mesh)\n    likelihood = densities.prod(axis=2)\n\n    posterior = prior * likelihood\n    normalize(posterior)\n\n    return posterior \n```", "```py\nposterior = update_weibull(prior, data) \n```", "```py\nfrom utils import plot_contour\n\nplot_contour(posterior)\ndecorate(title='Posterior joint distribution of Weibull parameters') \n```", "```py\nfrom utils import marginal\n\nposterior_lam = marginal(posterior, 0)\nposterior_k = marginal(posterior, 1) \n```", "```py\nimport matplotlib.pyplot as plt\n\nplt.axvline(3, color='C5')\nposterior_lam.plot(color='C4', label='lambda')\ndecorate(xlabel='lam',\n         ylabel='PDF', \n         title='Posterior marginal distribution of lam') \n```", "```py\nplt.axvline(0.8, color='C5')\nposterior_k.plot(color='C12', label='k')\ndecorate(xlabel='k',\n         ylabel='PDF', \n         title='Posterior marginal distribution of k') \n```", "```py\nprint(lam, posterior_lam.credible_interval(0.9)) \n```", "```py\n3 [1.2 4.4] \n```", "```py\nprint(k, posterior_k.credible_interval(0.9)) \n```", "```py\n0.8 [0.6 1.4] \n```", "```py\nstart = np.random.uniform(0, 8, size=10)\nstart \n```", "```py\narray([0.78026881, 6.08999773, 1.97550379, 1.1050535 , 2.65157251,\n       0.66399652, 5.37581665, 6.45275039, 7.86193532, 5.08528588]) \n```", "```py\nduration = actual_dist.rvs(10)\nduration \n```", "```py\narray([0.80497283, 2.11577082, 0.43308797, 0.10862644, 5.17334866,\n       3.25745053, 3.05555883, 2.47401062, 0.05340806, 1.08386395]) \n```", "```py\nimport pandas as pd\n\nd = dict(start=start, end=start+duration)\nobs = pd.DataFrame(d) \n```", "```py\nobs = obs.sort_values(by='start', ignore_index=True)\nobs \n```", "```py\ncensored = obs['end'] > 8 \n```", "```py\nobs.loc[censored, 'end'] = 8\nobs.loc[censored, 'status'] = 0 \n```", "```py\ndef plot_lifelines(obs):\n  \"\"\"Plot a line for each observation.\n\n obs: DataFrame\n \"\"\"\n    for y, row in obs.iterrows():\n        start = row['start']\n        end = row['end']\n        status = row['status']\n\n        if status == 0:\n            # ongoing\n            plt.hlines(y, start, end, color='C0')\n        else:\n            # complete\n            plt.hlines(y, start, end, color='C1')\n            plt.plot(end, y, marker='o', color='C1')\n\n    decorate(xlabel='Time (weeks)',\n             ylabel='Dog index',\n             title='Lifelines showing censored and uncensored observations')\n\n    plt.gca().invert_yaxis() \n```", "```py\nplot_lifelines(obs) \n```", "```py\nobs['T'] = obs['end'] - obs['start'] \n```", "```py\ndata1 = obs.loc[~censored, 'T']\ndata2 = obs.loc[censored, 'T'] \n```", "```py\ndata1 \n```", "```py\n0    3.257451\n1    0.804973\n2    0.108626\n3    0.433088\n4    5.173349\n5    1.083864\n9    0.053408\nName: T, dtype: float64 \n```", "```py\ndata2 \n```", "```py\n6    2.624183\n7    1.910002\n8    1.547250\nName: T, dtype: float64 \n```", "```py\nposterior1 = update_weibull(prior, data1) \n```", "```py\ndef update_weibull_incomplete(prior, data):\n  \"\"\"Update the prior using incomplete data.\"\"\"\n    lam_mesh, k_mesh, data_mesh = np.meshgrid(\n        prior.columns, prior.index, data)\n\n    # evaluate the survival function\n    probs = weibull_dist(lam_mesh, k_mesh).sf(data_mesh)\n    likelihood = probs.prod(axis=2)\n\n    posterior = prior * likelihood\n    normalize(posterior)\n\n    return posterior \n```", "```py\nposterior2 = update_weibull_incomplete(posterior1, data2) \n```", "```py\nplot_contour(posterior2)\ndecorate(title='Posterior joint distribution, incomplete data') \n```", "```py\nposterior_lam2 = marginal(posterior2, 0)\nposterior_k2 = marginal(posterior2, 1) \n```", "```py\nposterior_lam.plot(color='C5', label='All complete',\n                   linestyle='dashed')\nposterior_lam2.plot(color='C2', label='Some censored')\n\ndecorate(xlabel='lambda',\n         ylabel='PDF', \n         title='Marginal posterior distribution of lambda') \n```", "```py\nposterior_k.plot(color='C5', label='All complete',\n                   linestyle='dashed')\nposterior_k2.plot(color='C12', label='Some censored')\n\ndecorate(xlabel='k',\n         ylabel='PDF', \n         title='Posterior marginal distribution of k') \n```", "```py\ndownload('https://gist.github.com/epogrebnyak/7933e16c0ad215742c4c104be4fbdeb1/raw/c932bc5b6aa6317770c4cbf43eb591511fec08f9/lamps.csv') \n```", "```py\ndf = pd.read_csv('lamps.csv', index_col=0)\ndf.head() \n```", "```py\nfrom empiricaldist import Pmf\n\npmf_bulb = Pmf(df['f'].to_numpy(), df['h'])\npmf_bulb.normalize() \n```", "```py\n50 \n```", "```py\npmf_bulb.mean() \n```", "```py\n1413.84 \n```", "```py\nlams = np.linspace(1000, 2000, num=51)\nprior_lam = make_uniform(lams, name='lambda') \n```", "```py\nks = np.linspace(1, 10, num=51)\nprior_k = make_uniform(ks, name='k') \n```", "```py\nprior_bulb = make_joint(prior_lam, prior_k) \n```", "```py\ndata_bulb = np.repeat(df['h'], df['f'])\nlen(data_bulb) \n```", "```py\n50 \n```", "```py\nposterior_bulb = update_weibull(prior_bulb, data_bulb) \n```", "```py\nplot_contour(posterior_bulb)\ndecorate(title='Joint posterior distribution, light bulbs') \n```", "```py\nlam_mesh, k_mesh = np.meshgrid(\n    prior_bulb.columns, prior_bulb.index) \n```", "```py\nmeans = weibull_dist(lam_mesh, k_mesh).mean()\nmeans.shape \n```", "```py\n(51, 51) \n```", "```py\nprod = means * posterior_bulb \n```", "```py\nprod.to_numpy().sum() \n```", "```py\n1412.7242774305005 \n```", "```py\ndef joint_weibull_mean(joint):\n  \"\"\"Compute the mean of a joint distribution of Weibulls.\"\"\"\n    lam_mesh, k_mesh = np.meshgrid(\n        joint.columns, joint.index)\n    means = weibull_dist(lam_mesh, k_mesh).mean()\n    prod = means * joint\n    return prod.to_numpy().sum() \n```", "```py\ndef update_weibull_between(prior, data, dt=12):\n  \"\"\"Update the prior based on data.\"\"\"\n    lam_mesh, k_mesh, data_mesh = np.meshgrid(\n        prior.columns, prior.index, data)\n    dist = weibull_dist(lam_mesh, k_mesh)\n    cdf1 = dist.cdf(data_mesh)\n    cdf2 = dist.cdf(data_mesh-12)\n    likelihood = (cdf1 - cdf2).prod(axis=2)\n\n    posterior = prior * likelihood\n    normalize(posterior)\n\n    return posterior \n```", "```py\nposterior_bulb2 = update_weibull_between(prior_bulb, data_bulb) \n```", "```py\nplot_contour(posterior_bulb2)\ndecorate(title='Joint posterior distribution, light bulbs') \n```", "```py\njoint_weibull_mean(posterior_bulb) \n```", "```py\n1412.7242774305005 \n```", "```py\njoint_weibull_mean(posterior_bulb2) \n```", "```py\n1406.8171982320873 \n```", "```py\nlam = 1550\nk = 4.25\nt = 1000\n\nprob_dead = weibull_dist(lam, k).cdf(t)\nprob_dead \n```", "```py\n0.14381685899960547 \n```", "```py\nfrom utils import make_binomial\n\nn = 100\np = prob_dead\ndist_num_dead = make_binomial(n, p) \n```", "```py\ndist_num_dead.plot(label='known parameters')\n\ndecorate(xlabel='Number of dead bulbs',\n         ylabel='PMF',\n         title='Predictive distribution with known parameters') \n```", "```py\nposterior_series = posterior_bulb.stack()\nposterior_series.head() \n```", "```py\nk    lambda\n1.0  1000.0    8.146763e-25\n     1020.0    1.210486e-24\n     1040.0    1.738327e-24\n     1060.0    2.418201e-24\n     1080.0    3.265549e-24\ndtype: float64 \n```", "```py\npmf_seq = []\nfor (k, lam) in posterior_series.index:\n    prob_dead = weibull_dist(lam, k).cdf(t)\n    pmf = make_binomial(n, prob_dead)\n    pmf_seq.append(pmf) \n```", "```py\nfrom utils import make_mixture\n\npost_pred = make_mixture(posterior_series, pmf_seq) \n```", "```py\ndist_num_dead.plot(label='known parameters')\npost_pred.plot(label='unknown parameters')\ndecorate(xlabel='Number of dead bulbs',\n         ylabel='PMF',\n         title='Posterior predictive distribution') \n```", "```py\n# Solution\n\nt = 1000\n\nlam_mesh, k_mesh = np.meshgrid(\n    prior_bulb.columns, prior_bulb.index)\nprob_dead = weibull_dist(lam_mesh, k_mesh).cdf(t)\nprob_dead.shape \n```", "```py\n(51, 51) \n```", "```py\n# Solution\n\nfrom scipy.stats import binom\n\nk = 20\nn = 100\nlikelihood = binom(n, prob_dead).pmf(k)\nlikelihood.shape \n```", "```py\n(51, 51) \n```", "```py\n# Solution\n\nposterior_bulb3 = posterior_bulb * likelihood\nnormalize(posterior_bulb3)\nplot_contour(posterior_bulb3)\ndecorate(title='Joint posterior distribution with k=20') \n```", "```py\n# Solution\n\n# Since there were more dead bulbs than expected,\n# the posterior mean is a bit less after the update.\n\njoint_weibull_mean(posterior_bulb3) \n```", "```py\n1378.3949572816412 \n```", "```py\nimport scipy.stats\n\ndef gamma_dist(k, theta):\n  \"\"\"Makes a gamma object.\n\n k: shape parameter\n theta: scale parameter\n\n returns: gamma object\n \"\"\"\n    return scipy.stats.gamma(k, scale=theta) \n```", "```py\n# Load the data file\n\ndownload('https://github.com/AllenDowney/ThinkBayes2/raw/master/data/2203951.csv') \n```", "```py\nweather = pd.read_csv('2203951.csv')\nweather.head() \n```", "```py\nrained = weather['PRCP'] > 0\nrained.sum() \n```", "```py\n14 \n```", "```py\nprcp = weather.loc[rained, 'PRCP']\nprcp.describe() \n```", "```py\ncount    14.000000\nmean      0.222857\nstd       0.301060\nmin       0.010000\n25%       0.052500\n50%       0.110000\n75%       0.225000\nmax       1.140000\nName: PRCP, dtype: float64 \n```", "```py\ncdf_data = Cdf.from_seq(prcp)\ncdf_data.plot()\ndecorate(xlabel='Total rainfall (in)',\n         ylabel='CDF',\n         title='Distribution of rainfall on days it rained') \n```", "```py\n# Solution\n\n# I'll use the MLE parameters of the gamma distribution\n# to help me choose priors\n\nk_est, _, theta_est = scipy.stats.gamma.fit(prcp, floc=0)\nk_est, theta_est \n```", "```py\n(0.8898876017525283, 0.25043291132301665) \n```", "```py\n# Solution\n\n# I'll use uniform priors for the parameters.\n# I chose the upper bounds by trial and error.\n\nks = np.linspace(0.01, 2, num=51)\nprior_k = make_uniform(ks, name='k') \n```", "```py\n# Solution\n\nthetas = np.linspace(0.01, 1.5, num=51)\nprior_theta = make_uniform(thetas, name='theta') \n```", "```py\n# Solution\n\n# Here's the joint prior\n\nprior = make_joint(prior_k, prior_theta) \n```", "```py\n# Solution\n\n# I'll use a grid to compute the densities\n\nk_mesh, theta_mesh, data_mesh = np.meshgrid(\n    prior.columns, prior.index, prcp) \n```", "```py\n# Solution\n\n# Here's the 3-D array of densities\n\ndensities = gamma_dist(k_mesh, theta_mesh).pdf(data_mesh) \ndensities.shape \n```", "```py\n(51, 51, 14) \n```", "```py\n# Solution\n\n# Which we reduce by multiplying along axis 2\n\nlikelihood = densities.prod(axis=2)\nlikelihood.sum() \n```", "```py\n150287.91980136462 \n```", "```py\n# Solution\n\n# Now we can do the update in the usual way\n\nposterior = prior * likelihood\nnormalize(posterior) \n```", "```py\n57.780822684107896 \n```", "```py\n# Solution\n\n# And here's what the posterior looks like\n\nplot_contour(posterior)\n\ndecorate(title='Posterior distribution, parameters of a gamma distribution') \n```", "```py\n# Solution\n\n# I'll check the marginal distributions to make sure the\n# range of the priors is wide enough\n\nfrom utils import marginal\n\nposterior_k = marginal(posterior, 0)\nposterior_theta = marginal(posterior, 1) \n```", "```py\n# Solution\n\n# The marginal distribution for k is close to 0 at both ends\n\nposterior_k.plot(color='C4')\ndecorate(xlabel='k',\n         ylabel='PDF', \n         title='Posterior marginal distribution of k') \n```", "```py\n# Solution\n\nposterior_k.mean(), posterior_k.credible_interval(0.9) \n```", "```py\n(0.8437218523899558, array([0.4478, 1.3632])) \n```", "```py\n# Solution\n\n# Same with the marginal distribution of theta\n\nposterior_theta.plot(color='C2')\ndecorate(xlabel='theta',\n         ylabel='PDF', \n         title='Posterior marginal distribution of theta') \n```", "```py\n# Solution\n\nposterior_theta.mean(), posterior_theta.credible_interval(0.9) \n```", "```py\n(0.367761307460383, array([0.159 , 0.7848])) \n```", "```py\n# Solution\n\n# To compute the posterior predictive distribution,\n# I'll stack the joint posterior to make a Series\n# with a MultiIndex\n\nposterior_series = posterior.stack()\nposterior_series.head() \n```", "```py\ntheta  k     \n0.01   0.0100    4.306265e-156\n       0.0498    1.304069e-145\n       0.0896    2.463890e-141\n       0.1294    2.077828e-138\n       0.1692    4.227218e-136\ndtype: float64 \n```", "```py\n# Solution\n\n# I'll extend the predictive distribution up to 2 inches\n\nlow, high = 0.01, 2 \n```", "```py\n# Solution\n\n# Now we can iterate through `posterior_series`\n# and make a sequence of predictive Pmfs, one\n# for each possible pair of parameters\n\nfrom utils import pmf_from_dist\n\nqs = np.linspace(low, high, num=101)\npmf_seq = []\nfor (theta, k) in posterior_series.index:\n    dist = gamma_dist(k, theta)\n    pmf = pmf_from_dist(dist, qs)\n    pmf_seq.append(pmf) \n```", "```py\n# Solution\n\n# And we can use `make_mixture` to make the posterior predictive\n# distribution\n\npost_pred = make_mixture(posterior_series, pmf_seq) \n```", "```py\n# Solution\n\n# Here's what it looks like.\n\npost_pred.make_cdf().plot(label='rainfall')\ndecorate(xlabel='Total rainfall (in)',\n         ylabel='CDF',\n         title='Posterior predictive distribution of rainfall') \n```", "```py\n# Solution \n\n# The probability of more than 1.5 inches of rain is small\n\ncdf = post_pred.make_cdf()\np_gt = 1 - cdf(1.5)\np_gt \n```", "```py\n0.00900003598887611 \n```", "```py\n# Solution \n\n# So it's easier to interpret as the number of rainy\n# days between events, on average\n\n1 / p_gt \n```", "```py\n111.11066680577532 \n```"]