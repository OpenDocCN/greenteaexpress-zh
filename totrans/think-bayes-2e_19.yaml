- en: Logistic Regression
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://allendowney.github.io/ThinkBayes2/chap16.html](https://allendowney.github.io/ThinkBayes2/chap16.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'This chapter introduces two related topics: log odds and logistic regression.'
  prefs: []
  type: TYPE_NORMAL
- en: In <<_BayessRule>>, we rewrote Bayes’s Theorem in terms of odds and derived
    Bayes’s Rule, which can be a convenient way to do a Bayesian update on paper or
    in your head. In this chapter, we’ll look at Bayes’s Rule on a logarithmic scale,
    which provides insight into how we accumulate evidence through successive updates.
  prefs: []
  type: TYPE_NORMAL
- en: That leads directly to logistic regression, which is based on a linear model
    of the relationship between evidence and the log odds of a hypothesis. As an example,
    we’ll use data from the Space Shuttle to explore the relationship between temperature
    and the probability of damage to the O-rings.
  prefs: []
  type: TYPE_NORMAL
- en: As an exercise, you’ll have a chance to model the relationship between a child’s
    age when they start school and their probability of being diagnosed with Attention
    Deficit Hyperactivity Disorder (ADHD).
  prefs: []
  type: TYPE_NORMAL
- en: Log Odds
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When I was in grad school, I signed up for a class on the Theory of Computation.
    On the first day of class, I was the first to arrive. A few minutes later, another
    student arrived.
  prefs: []
  type: TYPE_NORMAL
- en: At the time, about 83% of the students in the computer science program [were
    male](https://www.aps.org/programs/education/statistics/fraction-phd.cfm), so
    I was mildly surprised to note that the other student was female.
  prefs: []
  type: TYPE_NORMAL
- en: When another female student arrived a few minutes later, I started to think
    I was in the wrong room. When third female student arrived, I was confident I
    was in the wrong room. And as it turned out, I was.
  prefs: []
  type: TYPE_NORMAL
- en: I’ll use this anecdote to demonstrate Bayes’s Rule on a logarithmic scale and
    show how it relates to logistic regression.
  prefs: []
  type: TYPE_NORMAL
- en: 'Using \(H\) to represent the hypothesis that I was in the right room, and \(F\)
    to represent the observation that the first other student was female, we can write
    Bayes’s Rule like this:'
  prefs: []
  type: TYPE_NORMAL
- en: \[O(H|F) = O(H) \frac{P(F|H)}{P(F|not H)}\]
  prefs: []
  type: TYPE_NORMAL
- en: 'Before I saw the other students, I was confident I was in the right room, so
    I might assign prior odds of 10:1 in favor:'
  prefs: []
  type: TYPE_NORMAL
- en: \[O(H) = 10\]
  prefs: []
  type: TYPE_NORMAL
- en: If I was in the right room, the likelihood of the first female student was about
    17%. If I was not in the right room, the likelihood of the first female student
    was more like 50%,
  prefs: []
  type: TYPE_NORMAL
- en: \[\frac{P(F|H)}{P(F|not H)} = 17 / 50\]
  prefs: []
  type: TYPE_NORMAL
- en: So the likelihood ratio is close to 1/3\. Applying Bayes’s Rule, the posterior
    odds were
  prefs: []
  type: TYPE_NORMAL
- en: \[O(H|F) = 10 / 3\]
  prefs: []
  type: TYPE_NORMAL
- en: After two students, the posterior odds were
  prefs: []
  type: TYPE_NORMAL
- en: \[O(H|FF) = 10 / 9\]
  prefs: []
  type: TYPE_NORMAL
- en: 'And after three students:'
  prefs: []
  type: TYPE_NORMAL
- en: \[O(H|FFF) = 10 / 27\]
  prefs: []
  type: TYPE_NORMAL
- en: At that point, I was right to suspect I was in the wrong room.
  prefs: []
  type: TYPE_NORMAL
- en: The following table shows the odds after each update, the corresponding probabilities,
    and the change in probability after each step, expressed in percentage points.
  prefs: []
  type: TYPE_NORMAL
- en: <details class="hide above-input"><summary aria-label="Toggle hidden content">Show
    code cell content Hide code cell content</summary>
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]</details> <details class="hide above-input"><summary aria-label="Toggle
    hidden content">Show code cell source Hide code cell source</summary>'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]</details>'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | odds | prob | prob diff |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| prior | 10.000000 | 0.909091 | -- |'
  prefs: []
  type: TYPE_TB
- en: '| 1 student | 3.333333 | 0.769231 | -13.986014 |'
  prefs: []
  type: TYPE_TB
- en: '| 2 students | 1.111111 | 0.526316 | -24.291498 |'
  prefs: []
  type: TYPE_TB
- en: '| 3 students | 0.370370 | 0.270270 | -25.604552 |'
  prefs: []
  type: TYPE_TB
- en: Each update uses the same likelihood, but the changes in probability are not
    the same. The first update decreases the probability by about 14 percentage points,
    the second by 24, and the third by 26. That’s normal for this kind of update,
    and in fact it’s necessary; if the changes were the same size, we would quickly
    get into negative probabilities.
  prefs: []
  type: TYPE_NORMAL
- en: 'The odds follow a more obvious pattern. Because each update multiplies the
    odds by the same likelihood ratio, the odds form a geometric sequence. And that
    brings us to consider another way to represent uncertainty: **log odds**, which
    is the logarithm of odds, usually expressed using the natural log (base \(e\)).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Adding log odds to the table:'
  prefs: []
  type: TYPE_NORMAL
- en: <details class="hide above-input"><summary aria-label="Toggle hidden content">Show
    code cell source Hide code cell source</summary>
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]</details>'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | odds | prob | prob diff | log odds | log odds diff |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| prior | 10.000000 | 0.909091 | -- | 2.302585 | -- |'
  prefs: []
  type: TYPE_TB
- en: '| 1 student | 3.333333 | 0.769231 | -13.986014 | 1.203973 | -1.098612 |'
  prefs: []
  type: TYPE_TB
- en: '| 2 students | 1.111111 | 0.526316 | -24.291498 | 0.105361 | -1.098612 |'
  prefs: []
  type: TYPE_TB
- en: '| 3 students | 0.370370 | 0.270270 | -25.604552 | -0.993252 | -1.098612 |'
  prefs: []
  type: TYPE_TB
- en: 'You might notice:'
  prefs: []
  type: TYPE_NORMAL
- en: When probability is greater than 0.5, odds are greater than 1, and log odds
    are positive.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When probability is less than 0.5, odds are less than 1, and log odds are negative.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You might also notice that the log odds are equally spaced. The change in log
    odds after each update is the logarithm of the likelihood ratio.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: That’s true in this example, and we can show that it’s true in general by taking
    the log of both sides of Bayes’s Rule.
  prefs: []
  type: TYPE_NORMAL
- en: \[\log O(H|F) = \log O(H) + \log \frac{P(F|H)}{P(F|not H)}\]
  prefs: []
  type: TYPE_NORMAL
- en: 'On a log odds scale, a Bayesian update is additive. So if \(F^x\) means that
    \(x\) female students arrive while I am waiting, the posterior log odds that I
    am in the right room are:'
  prefs: []
  type: TYPE_NORMAL
- en: \[\log O(H|F^x) = \log O(H) + x \log \frac{P(F|H)}{P(F|not H)}\]
  prefs: []
  type: TYPE_NORMAL
- en: This equation represents a linear relationship between the log likelihood ratio
    and the posterior log odds.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this example the linear equation is exact, but even when it’s not, it is
    common to use a linear function to model the relationship between an explanatory
    variable, \(x\), and a dependent variable expressed in log odds, like this:'
  prefs: []
  type: TYPE_NORMAL
- en: \[\log O(H | x) = \beta_0 + \beta_1 x\]
  prefs: []
  type: TYPE_NORMAL
- en: 'where \(\beta_0\) and \(\beta_1\) are unknown parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: The intercept, \(\beta_0\), is the log odds of the hypothesis when \(x\) is
    0.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The slope, \(\beta_1\), is the log of the likelihood ratio.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This equation is the basis of logistic regression.
  prefs: []
  type: TYPE_NORMAL
- en: The Space Shuttle Problem
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'As an example of logistic regression, I’ll solve a problem from Cameron Davidson-Pilon’s
    book, [*Bayesian Methods for Hackers*](http://nbviewer.jupyter.org/github/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/blob/master/Chapter2_MorePyMC/Ch2_MorePyMC_PyMC2.ipynb).
    He writes:'
  prefs: []
  type: TYPE_NORMAL
- en: “On January 28, 1986, the twenty-fifth flight of the U.S. space shuttle program
    ended in disaster when one of the rocket boosters of the Shuttle Challenger exploded
    shortly after lift-off, killing all seven crew members. The presidential commission
    on the accident concluded that it was caused by the failure of an O-ring in a
    field joint on the rocket booster, and that this failure was due to a faulty design
    that made the O-ring unacceptably sensitive to a number of factors including outside
    temperature. Of the previous 24 flights, data were available on failures of O-rings
    on 23 (one was lost at sea), and these data were discussed on the evening preceding
    the Challenger launch, but unfortunately only the data corresponding to the 7
    flights on which there was a damage incident were considered important and these
    were thought to show no obvious trend.”
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: The dataset is originally from [this paper](https://amstat.tandfonline.com/doi/abs/10.1080/01621459.1989.10478858),
    but also available from [Davidson-Pilon](https://raw.githubusercontent.com/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/master/Chapter2_MorePyMC/data/challenger_data.csv).
  prefs: []
  type: TYPE_NORMAL
- en: <details class="hide above-input"><summary aria-label="Toggle hidden content">Show
    code cell content Hide code cell content</summary>
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]</details>'
  prefs: []
  type: TYPE_NORMAL
- en: I’ll read the data and do some cleaning.
  prefs: []
  type: TYPE_NORMAL
- en: <details class="hide above-input"><summary aria-label="Toggle hidden content">Show
    code cell content Hide code cell content</summary>
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: '|  | Date | Temperature | Damage |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 0 | 1981-04-12 | 66 | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | 1981-11-12 | 70 | 1 |'
  prefs: []
  type: TYPE_TB
- en: '| 2 | 1982-03-22 | 69 | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| 4 | 1982-01-11 | 68 | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| 5 | 1983-04-04 | 67 | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| 6 | 1983-06-18 | 72 | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| 7 | 1983-08-30 | 73 | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| 8 | 1983-11-28 | 70 | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| 9 | 1984-02-03 | 57 | 1 |'
  prefs: []
  type: TYPE_TB
- en: '| 10 | 1984-04-06 | 63 | 1 |'
  prefs: []
  type: TYPE_TB
- en: '| 11 | 1984-08-30 | 70 | 1 |'
  prefs: []
  type: TYPE_TB
- en: '| 12 | 1984-10-05 | 78 | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| 13 | 1984-11-08 | 67 | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| 14 | 1985-01-24 | 53 | 1 |'
  prefs: []
  type: TYPE_TB
- en: '| 15 | 1985-04-12 | 67 | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| 16 | 1985-04-29 | 75 | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| 17 | 1985-06-17 | 70 | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| 18 | 1985-07-29 | 81 | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| 19 | 1985-08-27 | 76 | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| 20 | 1985-10-03 | 79 | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| 21 | 1985-10-30 | 75 | 1 |'
  prefs: []
  type: TYPE_TB
- en: '| 22 | 1985-11-26 | 76 | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| 23 | 1986-01-12 | 58 | 1 |</details>'
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are the first few rows:'
  prefs: []
  type: TYPE_NORMAL
- en: <details class="hide above-input"><summary aria-label="Toggle hidden content">Show
    code cell source Hide code cell source</summary>
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]</details>'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | Date | Temperature | Damage |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 0 | 1981-04-12 | 66 | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | 1981-11-12 | 70 | 1 |'
  prefs: []
  type: TYPE_TB
- en: '| 2 | 1982-03-22 | 69 | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| 4 | 1982-01-11 | 68 | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| 5 | 1983-04-04 | 67 | 0 |'
  prefs: []
  type: TYPE_TB
- en: 'The columns are:'
  prefs: []
  type: TYPE_NORMAL
- en: '`Date`: The date of launch,'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Temperature`: Outside temperature in Fahrenheit, and'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Damage`: `1` if there was a damage incident and `0` otherwise.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There are 23 launches in the dataset, 7 with damage incidents.
  prefs: []
  type: TYPE_NORMAL
- en: <details class="hide above-input"><summary aria-label="Toggle hidden content">Show
    code cell content Hide code cell content</summary>
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE9]</details>'
  prefs: []
  type: TYPE_NORMAL
- en: The following figure shows the relationship between damage and temperature.
  prefs: []
  type: TYPE_NORMAL
- en: <details class="hide above-input"><summary aria-label="Toggle hidden content">Show
    code cell source Hide code cell source</summary>
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]</details> <details class="hide above-input"><summary aria-label="Toggle
    hidden content">Show code cell source Hide code cell source</summary>'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]</details> ![_images/9c176560b9752003e2f6e6e100518c13a4375e65aa388ab988866eb61c444569.png](../Images/d4d696fb17142eb2541d5857df0c70b9.png)'
  prefs: []
  type: TYPE_NORMAL
- en: When the outside temperature was below 65 degrees, there was always damage to
    the O-rings. When the temperature was above 65 degrees, there was usually no damage.
  prefs: []
  type: TYPE_NORMAL
- en: 'Based on this figure, it seems plausible that the probability of damage is
    related to temperature. If we assume this probability follows a logistic model,
    we can write:'
  prefs: []
  type: TYPE_NORMAL
- en: \[\log O(H | x) = \beta_0 + \beta_1 x\]
  prefs: []
  type: TYPE_NORMAL
- en: where \(H\) is the hypothesis that the O-rings will be damaged, \(x\) is temperature,
    and \(\beta_0\) and \(\beta_1\) are the parameters we will estimate. For reasons
    I’ll explain soon, I’ll define \(x\) to be temperature shifted by an offset so
    its mean is 0.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: And for consistency I’ll create a copy of the `Damage` columns called `y`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: Before doing a Bayesian update, I’ll use `statsmodels` to run a conventional
    (non-Bayesian) logistic regression.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: '`results` contains a “point estimate” for each parameter, that is, a single
    value rather than a posterior distribution.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The intercept is about -1.2, and the estimated slope is about -0.23. To see
    what these parameters mean, I’ll use them to compute probabilities for a range
    of temperatures. Here’s the range:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'We can use the logistic regression equation to compute log odds:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: And then convert to probabilities.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: <details class="hide above-input"><summary aria-label="Toggle hidden content">Show
    code cell content Hide code cell content</summary>
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE21]</details>'
  prefs: []
  type: TYPE_NORMAL
- en: Converting log odds to probabilities is a common enough operation that it has
    a name, `expit`, and SciPy provides a function that computes it.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: <details class="hide above-input"><summary aria-label="Toggle hidden content">Show
    code cell content Hide code cell content</summary>
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE24]</details>'
  prefs: []
  type: TYPE_NORMAL
- en: Here’s what the logistic model looks like with these estimated parameters.
  prefs: []
  type: TYPE_NORMAL
- en: <details class="hide above-input"><summary aria-label="Toggle hidden content">Show
    code cell source Hide code cell source</summary>
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]</details> ![_images/184359ae741869c825727d898cd709c7876cb15a30627a4ac069ec7a766dda27.png](../Images/02337f43c9bd6ff6ed033cb5db254145.png)'
  prefs: []
  type: TYPE_NORMAL
- en: At low temperatures, the probability of damage is high; at high temperatures,
    it drops off to near 0.
  prefs: []
  type: TYPE_NORMAL
- en: But that’s based on conventional logistic regression. Now we’ll do the Bayesian
    version.
  prefs: []
  type: TYPE_NORMAL
- en: Prior Distribution
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: I’ll use uniform distributions for both parameters, using the point estimates
    from the previous section to help me choose the upper and lower bounds.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: We can use `make_joint` to construct the joint prior distribution.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: The values of `intercept` run across the columns, the values of `slope` run
    down the rows.
  prefs: []
  type: TYPE_NORMAL
- en: For this problem, it will be convenient to “stack” the prior so the parameters
    are levels in a `MultiIndex`, and put the result in a `Pmf`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: '|  |  | probs |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Slope | Intercept |  |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| -0.8 | -5.00 | 0.000098 |'
  prefs: []
  type: TYPE_TB
- en: '| -4.94 | 0.000098 |'
  prefs: []
  type: TYPE_TB
- en: '| -4.88 | 0.000098 |'
  prefs: []
  type: TYPE_TB
- en: '`joint_pmf` is a `Pmf` with two levels in the index, one for each parameter.
    That makes it easy to loop through possible pairs of parameters, as we’ll see
    in the next section.'
  prefs: []
  type: TYPE_NORMAL
- en: Likelihood
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To do the update, we have to compute the likelihood of the data for each possible
    pair of parameters.
  prefs: []
  type: TYPE_NORMAL
- en: To make that easier, I’m going to group the data by temperature, `x`, and count
    the number of launches and damage incidents at each temperature.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: '|  | count | sum |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| x |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| -17.0 | 1 | 1 |'
  prefs: []
  type: TYPE_TB
- en: '| -13.0 | 1 | 1 |'
  prefs: []
  type: TYPE_TB
- en: '| -12.0 | 1 | 1 |'
  prefs: []
  type: TYPE_TB
- en: '| -7.0 | 1 | 1 |'
  prefs: []
  type: TYPE_TB
- en: '| -4.0 | 1 | 0 |'
  prefs: []
  type: TYPE_TB
- en: 'The result is a `DataFrame` with two columns: `count` is the number of launches
    at each temperature; `sum` is the number of damage incidents. To be consistent
    with the parameters of the binomial distributions, I’ll assign them to variables
    named `ns` and `ks`.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: To compute the likelihood of the data, let’s assume temporarily that the parameters
    we just estimated, `slope` and `inter`, are correct.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can use them to compute the probability of damage at each launch temperature,
    like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: '`ps` contains the probability of damage for each launch temperature, according
    to the model.'
  prefs: []
  type: TYPE_NORMAL
- en: Now, for each temperature we have `ns`, `ps`, and `ks`; we can use the binomial
    distribution to compute the likelihood of the data.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: Each element of `likes` is the probability of seeing `k` damage incidents in
    `n` launches if the probability of damage is `p`. The likelihood of the whole
    dataset is the product of this array.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'That’s how we compute the likelihood of the data for a particular pair of parameters.
    Now we can compute the likelihood of the data for all possible pairs:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: To initialize `likelihood`, we make a copy of `joint_pmf`, which is a convenient
    way to make sure that `likelihood` has the same type, index, and data type as
    `joint_pmf`.
  prefs: []
  type: TYPE_NORMAL
- en: The loop iterates through the parameters. For each possible pair, it uses the
    logistic model to compute `ps`, computes the likelihood of the data, and assigns
    the result to a row in `likelihood`.
  prefs: []
  type: TYPE_NORMAL
- en: The Update
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now we can compute the posterior distribution in the usual way.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'Because we used a uniform prior, the parameter pair with the highest likelihood
    is also the pair with maximum posterior probability:'
  prefs: []
  type: TYPE_NORMAL
- en: <details class="hide above-input"><summary aria-label="Toggle hidden content">Show
    code cell content Hide code cell content</summary>
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE40]</details>'
  prefs: []
  type: TYPE_NORMAL
- en: 'So we can confirm that the results of the Bayesian update are consistent with
    the maximum likelihood estimate computed by StatsModels:'
  prefs: []
  type: TYPE_NORMAL
- en: <details class="hide above-input"><summary aria-label="Toggle hidden content">Show
    code cell content Hide code cell content</summary>
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE42]</details>'
  prefs: []
  type: TYPE_NORMAL
- en: They are approximately the same, within the precision of the grid we’re using.
  prefs: []
  type: TYPE_NORMAL
- en: If we unstack the posterior `Pmf` we can make a contour plot of the joint posterior
    distribution.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: '![_images/6fa00d5595996c520a41b3e76de338d79c39c384f930bc01ba19b7604f32c850.png](../Images/fb6869a9be510eeca3c1389df899ec45.png)'
  prefs: []
  type: TYPE_IMG
- en: The ovals in the contour plot are aligned along a diagonal, which indicates
    that there is some correlation between `slope` and `inter` in the posterior distribution.
  prefs: []
  type: TYPE_NORMAL
- en: But the correlation is weak, which is one of the reasons we subtracted off the
    mean launch temperature when we computed `x`; centering the data minimizes the
    correlation between the parameters.
  prefs: []
  type: TYPE_NORMAL
- en: '**Exercise:** To see why this matters, go back and set `offset=60` and run
    the analysis again. The slope should be the same, but the intercept will be different.
    And if you plot the joint distribution, the contours you get will be elongated,
    indicating stronger correlation between the estimated parameters.'
  prefs: []
  type: TYPE_NORMAL
- en: In theory, this correlation is not a problem, but in practice it is. With uncentered
    data, the posterior distribution is more spread out, so it’s harder to cover with
    the joint prior distribution. Centering the data maximizes the precision of the
    estimates; with uncentered data, we have to do more computation to get the same
    precision.
  prefs: []
  type: TYPE_NORMAL
- en: Marginal Distributions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Finally, we can extract the marginal distributions.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: Here’s the posterior distribution of `inter`.
  prefs: []
  type: TYPE_NORMAL
- en: <details class="hide above-input"><summary aria-label="Toggle hidden content">Show
    code cell source Hide code cell source</summary>
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]</details> ![_images/b06adb0eb4e2bec88511c82b4d847ba57ba32ad397ab1b2c6a8c77dad4aba9f0.png](../Images/f3b94b3f1bc46134208bdb54c255ad3c.png)'
  prefs: []
  type: TYPE_NORMAL
- en: And here’s the posterior distribution of `slope`.
  prefs: []
  type: TYPE_NORMAL
- en: <details class="hide above-input"><summary aria-label="Toggle hidden content">Show
    code cell source Hide code cell source</summary>
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]</details> ![_images/282201b1bee504c51b0c181166c0dedfe417f37e44ca3fad23e76f8a5865a3ef.png](../Images/8efbc3f30e4e6f76a7e2dbe86d5e7d88.png)'
  prefs: []
  type: TYPE_NORMAL
- en: Here are the posterior means.
  prefs: []
  type: TYPE_NORMAL
- en: <details class="hide above-input"><summary aria-label="Toggle hidden content">Show
    code cell content Hide code cell content</summary>
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE48]</details>'
  prefs: []
  type: TYPE_NORMAL
- en: Both marginal distributions are moderately skewed, so the posterior means are
    somewhat different from the point estimates.
  prefs: []
  type: TYPE_NORMAL
- en: <details class="hide above-input"><summary aria-label="Toggle hidden content">Show
    code cell content Hide code cell content</summary>
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE50]</details>'
  prefs: []
  type: TYPE_NORMAL
- en: Transforming Distributions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let’s interpret these parameters. Recall that the intercept is the log odds
    of the hypothesis when \(x\) is 0, which is when temperature is about 70 degrees
    F (the value of `offset`). So we can interpret the quantities in `marginal_inter`
    as log odds.
  prefs: []
  type: TYPE_NORMAL
- en: 'To convert them to probabilities, I’ll use the following function, which transforms
    the quantities in a `Pmf` by applying a given function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: If we call `transform` and pass `expit` as a parameter, it transforms the log
    odds in `marginal_inter` into probabilities and returns the posterior distribution
    of `inter` expressed in terms of probabilities.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: '`Pmf` provides a `transform` method that does the same thing.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: Here’s the posterior distribution for the probability of damage at 70 degrees
    F.
  prefs: []
  type: TYPE_NORMAL
- en: <details class="hide above-input"><summary aria-label="Toggle hidden content">Show
    code cell source Hide code cell source</summary>
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]</details> ![_images/d4a0ba125f94c8d8a1007b700d5bdd5bab05c13b7e0b00f8e94c59eb068ef384.png](../Images/c7e489fb2ab8b75a9ae3383449fff948.png)'
  prefs: []
  type: TYPE_NORMAL
- en: The mean of this distribution is about 22%, which is the probability of damage
    at 70 degrees F, according to the model.
  prefs: []
  type: TYPE_NORMAL
- en: <details class="hide above-input"><summary aria-label="Toggle hidden content">Show
    code cell content Hide code cell content</summary>
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE56]</details>'
  prefs: []
  type: TYPE_NORMAL
- en: This result shows the second reason I defined `x` to be zero when temperature
    is 70 degrees F; this way, the intercept corresponds to the probability of damage
    at a relevant temperature, rather than 0 degrees F.
  prefs: []
  type: TYPE_NORMAL
- en: Now let’s look more closely at the estimated slope. In the logistic model, the
    parameter \(\beta_1\) is the log of the likelihood ratio.
  prefs: []
  type: TYPE_NORMAL
- en: So we can interpret the quantities in `marginal_slope` as log likelihood ratios,
    and we can use `exp` to transform them to likelihood ratios (also known as Bayes
    factors).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: The result is the posterior distribution of likelihood ratios; here’s what it
    looks like.
  prefs: []
  type: TYPE_NORMAL
- en: <details class="hide above-input"><summary aria-label="Toggle hidden content">Show
    code cell source Hide code cell source</summary>
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]</details> ![_images/027bce9b65abb343c2f6a22dba21f4090f49d688afdcf61bf519088cf5b30dc8.png](../Images/384df6dd201224fcbc4e303e60ee143f.png)<details
    class="hide above-input"><summary aria-label="Toggle hidden content">Show code
    cell content Hide code cell content</summary>'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE60]</details>'
  prefs: []
  type: TYPE_NORMAL
- en: The mean of this distribution is about 0.75, which means that each additional
    degree Fahrenheit provides evidence against the possibility of damage, with a
    likelihood ratio (Bayes factor) of 0.75.
  prefs: []
  type: TYPE_NORMAL
- en: 'Notice:'
  prefs: []
  type: TYPE_NORMAL
- en: I computed the posterior mean of the probability of damage at 70 deg F by transforming
    the marginal distribution of the intercept to the marginal distribution of probability,
    and then computing the mean.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: I computed the posterior mean of the likelihood ratio by transforming the marginal
    distribution of slope to the marginal distribution of likelihood ratios, and then
    computing the mean.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This is the correct order of operations, as opposed to computing the posterior
    means first and then transforming them.
  prefs: []
  type: TYPE_NORMAL
- en: To see the difference, let’s compute both values the other way around. Here’s
    the posterior mean of `marginal_inter`, transformed to a probability, compared
    to the mean of `marginal_probs`.
  prefs: []
  type: TYPE_NORMAL
- en: <details class="hide above-input"><summary aria-label="Toggle hidden content">Show
    code cell content Hide code cell content</summary>
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE62]</details>'
  prefs: []
  type: TYPE_NORMAL
- en: And here’s the posterior mean of `marginal_slope`, transformed to a likelihood
    ratio, compared to the mean `marginal_lr`.
  prefs: []
  type: TYPE_NORMAL
- en: <details class="hide above-input"><summary aria-label="Toggle hidden content">Show
    code cell content Hide code cell content</summary>
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE64]</details>'
  prefs: []
  type: TYPE_NORMAL
- en: In this example, the differences are not huge, but they can be. As a general
    rule, transform first, then compute summary statistics.
  prefs: []
  type: TYPE_NORMAL
- en: Predictive Distributions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the logistic model, the parameters are interpretable, at least after transformation.
    But often what we care about are predictions, not parameters. In the Space Shuttle
    problem, the most important prediction is, “What is the probability of O-ring
    damage if the outside temperature is 31 degrees F?”
  prefs: []
  type: TYPE_NORMAL
- en: To make that prediction, I’ll draw a sample of parameter pairs from the posterior
    distribution.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs: []
  type: TYPE_PRE
- en: The result is an array of 101 tuples, each representing a possible pair of parameters.
    I chose this sample size to make the computation fast. Increasing it would not
    change the results much, but they would be a little more precise.
  prefs: []
  type: TYPE_NORMAL
- en: <details class="hide above-input"><summary aria-label="Toggle hidden content">Show
    code cell content Hide code cell content</summary>
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE67]</details> <details class="hide above-input"><summary aria-label="Toggle
    hidden content">Show code cell content Hide code cell content</summary>'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE69]</details> <details class="hide above-input"><summary aria-label="Toggle
    hidden content">Show code cell content Hide code cell content</summary>'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE70]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE71]</details>'
  prefs: []
  type: TYPE_NORMAL
- en: To generate predictions, I’ll use a range of temperatures from 31 degrees F
    (the temperature when the Challenger launched) to 82 degrees F (the highest observed
    temperature).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE72]'
  prefs: []
  type: TYPE_PRE
- en: The following loop uses `xs` and the sample of parameters to construct an array
    of predicted probabilities.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE73]'
  prefs: []
  type: TYPE_PRE
- en: The result has one column for each value in `xs` and one row for each element
    of `sample`.
  prefs: []
  type: TYPE_NORMAL
- en: To get a quick sense of what the predictions look like, we can loop through
    the rows and plot them.
  prefs: []
  type: TYPE_NORMAL
- en: <details class="hide above-input"><summary aria-label="Toggle hidden content">Show
    code cell content Hide code cell content</summary>
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE74]'
  prefs: []
  type: TYPE_PRE
- en: '![_images/21874fcd51b6d4d7c1877c9f9dd8744832e07b62154132a31ee4e2c8f92428f7.png](../Images/a85a52adc5748136290ed7fd06400b61.png)</details>'
  prefs: []
  type: TYPE_NORMAL
- en: The overlapping lines in this figure give a sense of the most likely value at
    each temperature and the degree of uncertainty.
  prefs: []
  type: TYPE_NORMAL
- en: In each column, I’ll compute the median to quantify the central tendency and
    a 90% credible interval to quantify the uncertainty.
  prefs: []
  type: TYPE_NORMAL
- en: '`np.percentile` computes the given percentiles; with the argument `axis=0`,
    it computes them for each column.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE75]'
  prefs: []
  type: TYPE_PRE
- en: The results are arrays containing predicted probabilities for the lower bound
    of the 90% CI, the median, and the upper bound of the CI.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s what they look like:'
  prefs: []
  type: TYPE_NORMAL
- en: <details class="hide above-input"><summary aria-label="Toggle hidden content">Show
    code cell source Hide code cell source</summary>
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE76]</details> ![_images/d6ed2327e5042d3ea7f9418465186f43a7bc1122f9fce65442c9b565564a6cfc.png](../Images/9941ea28a2708ac4f8d37322e5d6aa7e.png)'
  prefs: []
  type: TYPE_NORMAL
- en: According to these results, the probability of damage to the O-rings at 80 degrees
    F is near 2%, but there is some uncertainty about that prediction; the upper bound
    of the CI is around 10%.
  prefs: []
  type: TYPE_NORMAL
- en: At 60 degrees, the probability of damage is near 80%, but the CI is even wider,
    from 48% to 97%.
  prefs: []
  type: TYPE_NORMAL
- en: But the primary goal of the model is to predict the probability of damage at
    31 degrees F, and the answer is at least 97%, and more likely to be more than
    99.9%.
  prefs: []
  type: TYPE_NORMAL
- en: <details class="hide above-input"><summary aria-label="Toggle hidden content">Show
    code cell content Hide code cell content</summary>
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE77]</details> <details class="hide above-input"><summary aria-label="Toggle
    hidden content">Show code cell content Hide code cell content</summary>'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE78]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE79]</details> <details class="hide above-input"><summary aria-label="Toggle
    hidden content">Show code cell content Hide code cell content</summary>'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE80]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE81]</details> <details class="hide above-input"><summary aria-label="Toggle
    hidden content">Show code cell content Hide code cell content</summary>'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE82]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE83]</details>'
  prefs: []
  type: TYPE_NORMAL
- en: 'One conclusion we might draw is this: If the people responsible for the Challenger
    launch had taken into account all of the data, and not just the seven damage incidents,
    they could have predicted that the probability of damage at 31 degrees F was nearly
    certain. If they had, it seems likely they would have postponed the launch.'
  prefs: []
  type: TYPE_NORMAL
- en: At the same time, if they considered the previous figure, they might have realized
    that the model makes predictions that extend far beyond the data. When we extrapolate
    like that, we have to remember not just the uncertainty quantified by the model,
    which we expressed as a credible interval; we also have to consider the possibility
    that the model itself is unreliable.
  prefs: []
  type: TYPE_NORMAL
- en: This example is based on a logistic model, which assumes that each additional
    degree of temperature contributes the same amount of evidence in favor of (or
    against) the possibility of damage. Within a narrow range of temperatures, that
    might be a reasonable assumption, especially if it is supported by data. But over
    a wider range, and beyond the bounds of the data, reality has no obligation to
    stick to the model.
  prefs: []
  type: TYPE_NORMAL
- en: Empirical Bayes
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this chapter I used StatsModels to compute the parameters that maximize the
    probability of the data, and then used those estimates to choose the bounds of
    the uniform prior distributions. It might have occurred to you that this process
    uses the data twice, once to choose the priors and again to do the update. If
    that bothers you, you are not alone. The process I used is an example of what’s
    called the [Empirical Bayes method](https://en.wikipedia.org/wiki/Empirical_Bayes_method),
    although I don’t think that’s a particularly good name for it.
  prefs: []
  type: TYPE_NORMAL
- en: 'Although it might seem problematic to use the data twice, in these examples,
    it is not. To see why, consider an alternative: instead of using the estimated
    parameters to choose the bounds of the prior distribution, I could have used uniform
    distributions with much wider ranges. In that case, the results would be the same;
    the only difference is that I would spend more time computing likelihoods for
    parameters where the posterior probabilities are negligibly small.'
  prefs: []
  type: TYPE_NORMAL
- en: So you can think of this version of Empirical Bayes as an optimization that
    minimizes computation by putting the prior distributions where the likelihood
    of the data is worth computing. This optimization doesn’t affect the results,
    so it doesn’t “double-count” the data.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'So far we have seen three ways to represent degrees of confidence in a hypothesis:
    probability, odds, and log odds. When we write Bayes’s Rule in terms of log odds,
    a Bayesian update is the sum of the prior and the likelihood; in this sense, Bayesian
    statistics is the arithmetic of hypotheses and evidence.'
  prefs: []
  type: TYPE_NORMAL
- en: This form of Bayes’s Theorem is also the foundation of logistic regression,
    which we used to infer parameters and make predictions. In the Space Shuttle problem,
    we modeled the relationship between temperature and the probability of damage,
    and showed that the Challenger disaster might have been predictable. But this
    example is also a warning about the hazards of using a model to extrapolate far
    beyond the data.
  prefs: []
  type: TYPE_NORMAL
- en: In the exercises below you’ll have a chance to practice the material in this
    chapter, using log odds to evaluate a political pundit and using logistic regression
    to model diagnosis rates for Attention Deficit Hyperactivity Disorder (ADHD).
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter we’ll move from logistic regression to linear regression,
    which we will use to model changes over time in temperature, snowfall, and the
    marathon world record.
  prefs: []
  type: TYPE_NORMAL
- en: Exercises
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Exercise:** Suppose a political pundit claims to be able to predict the outcome
    of elections, but instead of picking a winner, they give each candidate a probability
    of winning. With that kind of prediction, it can be hard to say whether it is
    right or wrong.'
  prefs: []
  type: TYPE_NORMAL
- en: For example, suppose the pundit says that Alice has a 70% chance of beating
    Bob, and then Bob wins the election. Does that mean the pundit was wrong?
  prefs: []
  type: TYPE_NORMAL
- en: 'One way to answer this question is to consider two hypotheses:'
  prefs: []
  type: TYPE_NORMAL
- en: '`H`: The pundit’s algorithm is legitimate; the probabilities it produces are
    correct in the sense that they accurately reflect the candidates’ probabilities
    of winning.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`not H`: The pundit’s algorithm is bogus; the probabilities it produces are
    random values with a mean of 50%.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If the pundit says Alice has a 70% chance of winning, and she does, that provides
    evidence in favor of `H` with likelihood ratio 70/50.
  prefs: []
  type: TYPE_NORMAL
- en: If the pundit says Alice has a 70% chance of winning, and she loses, that’s
    evidence against `H` with a likelihood ratio of 50/30.
  prefs: []
  type: TYPE_NORMAL
- en: 'Suppose we start with some confidence in the algorithm, so the prior odds are
    4 to 1\. And suppose the pundit generates predictions for three elections:'
  prefs: []
  type: TYPE_NORMAL
- en: In the first election, the pundit says Alice has a 70% chance of winning and
    she does.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the second election, the pundit says Bob has a 30% chance of winning and
    he does.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the third election, the pundit says Carol has an 90% chance of winning and
    she does.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What is the log likelihood ratio for each of these outcomes? Use the log-odds
    form of Bayes’s Rule to compute the posterior log odds for `H` after these outcomes.
    In total, do these outcomes increase or decrease your confidence in the pundit?
  prefs: []
  type: TYPE_NORMAL
- en: If you are interested in this topic, you can [read more about it in this blog
    post](http://allendowney.blogspot.com/2016/11/why-are-we-so-surprised.html).
  prefs: []
  type: TYPE_NORMAL
- en: <details class="hide above-input"><summary aria-label="Toggle hidden content">Show
    code cell content Hide code cell content</summary>
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE84]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE85]</details> <details class="hide above-input"><summary aria-label="Toggle
    hidden content">Show code cell content Hide code cell content</summary>'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE86]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE87]</details> <details class="hide above-input"><summary aria-label="Toggle
    hidden content">Show code cell content Hide code cell content</summary>'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE88]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE89]</details>'
  prefs: []
  type: TYPE_NORMAL
- en: '**Exercise:** An article in the *New England Journal of Medicine* reports results
    from a study that looked at the diagnosis rate of Attention Deficit Hyperactivity
    Disorder (ADHD) as a function of birth month: [“Attention Deficit–Hyperactivity
    Disorder and Month of School Enrollment”](https://www.nejm.org/doi/10.1056/NEJMoa1806828).'
  prefs: []
  type: TYPE_NORMAL
- en: They found that children born in June, July, and August were substantially more
    likely to be diagnosed with ADHD, compared to children born in September, but
    only in states that use a September cutoff for children to enter kindergarten.
    In these states, children born in August start school almost a year younger than
    children born in September. The authors of the study suggest that the cause is
    “age-based variation in behavior that may be attributed to ADHD rather than to
    the younger age of the children”.
  prefs: []
  type: TYPE_NORMAL
- en: Use the methods in this chapter to estimate the probability of diagnosis as
    a function of birth month. The notebook for this chapter provides the data and
    some suggestions for getting started.
  prefs: []
  type: TYPE_NORMAL
- en: 'The paper includes this figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '[![https://www.nejm.org/na101/home/literatum/publisher/mms/journals/content/nejm/2018/nejm_2018.379.issue-22/nejmoa1806828/20190131/images/img_xlarge/nejmoa1806828_f1.jpeg](../Images/f46c09554caa11c0e698e9d4112e95b1.png)](https://www.nejm.org/na101/home/literatum/publisher/mms/journals/content/nejm/2018/nejm_2018.379.issue-22/nejmoa1806828/20190131/images/img_xlarge/nejmoa1806828_f1.jpeg)'
  prefs: []
  type: TYPE_NORMAL
- en: In my opinion, this representation of the data does not show the effect as clearly
    as it could.
  prefs: []
  type: TYPE_NORMAL
- en: But the figure includes the raw data, so we can analyze it ourselves.
  prefs: []
  type: TYPE_NORMAL
- en: 'Note: there is an error in the figure, confirmed by personal correspondence:'
  prefs: []
  type: TYPE_NORMAL
- en: The May and June [diagnoses] are reversed. May should be 317 (not 287) and June
    should be 287 (not 317).
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: So here is the corrected data, where `n` is the number of children born in each
    month, starting with January, and `k` is the number of children diagnosed with
    ADHD.
  prefs: []
  type: TYPE_NORMAL
- en: <details class="hide above-input"><summary aria-label="Toggle hidden content">Show
    code cell content Hide code cell content</summary>
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE90]</details>'
  prefs: []
  type: TYPE_NORMAL
- en: First, I’m going to “roll” the data so it starts in September rather than January.
  prefs: []
  type: TYPE_NORMAL
- en: <details class="hide above-input"><summary aria-label="Toggle hidden content">Show
    code cell content Hide code cell content</summary>
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE91]</details>'
  prefs: []
  type: TYPE_NORMAL
- en: And I’ll put it in a `DataFrame` with one row for each month and the diagnosis
    rate per 10,000.
  prefs: []
  type: TYPE_NORMAL
- en: <details class="hide above-input"><summary aria-label="Toggle hidden content">Show
    code cell content Hide code cell content</summary>
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE92]'
  prefs: []
  type: TYPE_PRE
- en: '|  | x | k | n | rate |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 0 | 0 | 225 | 35353 | 63.643821 |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | 1 | 240 | 34405 | 69.757303 |'
  prefs: []
  type: TYPE_TB
- en: '| 2 | 2 | 232 | 31285 | 74.156944 |'
  prefs: []
  type: TYPE_TB
- en: '| 3 | 3 | 243 | 31617 | 76.857387 |'
  prefs: []
  type: TYPE_TB
- en: '| 4 | 4 | 265 | 32690 | 81.064546 |'
  prefs: []
  type: TYPE_TB
- en: '| 5 | 5 | 280 | 31238 | 89.634420 |'
  prefs: []
  type: TYPE_TB
- en: '| 6 | 6 | 307 | 34405 | 89.231216 |'
  prefs: []
  type: TYPE_TB
- en: '| 7 | 7 | 312 | 34565 | 90.264719 |'
  prefs: []
  type: TYPE_TB
- en: '| 8 | 8 | 317 | 34977 | 90.630986 |'
  prefs: []
  type: TYPE_TB
- en: '| 9 | 9 | 287 | 34415 | 83.393869 |'
  prefs: []
  type: TYPE_TB
- en: '| 10 | 10 | 320 | 36577 | 87.486672 |'
  prefs: []
  type: TYPE_TB
- en: '| 11 | 11 | 309 | 36319 | 85.079435 |</details>'
  prefs: []
  type: TYPE_NORMAL
- en: Here’s what the diagnosis rates look like.
  prefs: []
  type: TYPE_NORMAL
- en: <details class="hide above-input"><summary aria-label="Toggle hidden content">Show
    code cell content Hide code cell content</summary>
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE93]</details> <details class="hide above-input"><summary aria-label="Toggle
    hidden content">Show code cell content Hide code cell content</summary>'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE94]'
  prefs: []
  type: TYPE_PRE
- en: '![_images/f7fcadfc675c91a1017eeedc3aceabe80e38f562484fb583b6ae2dc2712a8110.png](../Images/fc55cb668a66d64a73295c05ec30c03e.png)</details>'
  prefs: []
  type: TYPE_NORMAL
- en: For the first 9 months, from September to May, we see what we would expect if
    some of the excess diagnoses are due to “age-based variation in behavior”. For
    each month of difference in age, we see an increase in the number of diagnoses.
  prefs: []
  type: TYPE_NORMAL
- en: This pattern breaks down for the last three months, June, July, and August.
    This might be explained by random variation, but it also might be due to parental
    manipulation; if some parents hold back children born near the deadline, the observations
    for these month would include a mixture of children who are relatively old for
    their grade and therefore less likely to be diagnosed.
  prefs: []
  type: TYPE_NORMAL
- en: Unfortunately, the dataset includes only month of birth, not year, so we don’t
    know the actual ages of these students when they started school. However, we can
    use the first nine months to estimate the effect of age on diagnosis rate; then
    we can think about what to do with the other three months.
  prefs: []
  type: TYPE_NORMAL
- en: Use the methods in this chapter to estimate the probability of diagnosis as
    a function of birth month. Start with the following prior distributions.
  prefs: []
  type: TYPE_NORMAL
- en: <details class="hide above-input"><summary aria-label="Toggle hidden content">Show
    code cell content Hide code cell content</summary>
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE95]</details> <details class="hide above-input"><summary aria-label="Toggle
    hidden content">Show code cell content Hide code cell content</summary>'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE96]</details>'
  prefs: []
  type: TYPE_NORMAL
- en: Make a joint prior distribution and update it using the data for the first nine
    months.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Then draw a sample from the posterior distribution and use it to compute the
    median probability of diagnosis for each month and a 90% credible interval.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: As a bonus exercise, do a second update using the data from the last three months,
    but treating the observed number of diagnoses as a lower bound on the number of
    diagnoses there would be if no children were kept back.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: <details class="hide above-input"><summary aria-label="Toggle hidden content">Show
    code cell content Hide code cell content</summary>
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE97]'
  prefs: []
  type: TYPE_PRE
- en: '| Intercept | -5.200 | -5.188 | -5.176 | -5.164 | -5.152 | -5.140 | -5.128
    | -5.116 | -5.104 | -5.092 | ... | -4.708 | -4.696 | -4.684 | -4.672 | -4.660
    | -4.648 | -4.636 | -4.624 | -4.612 | -4.600 |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | ---
    | --- | --- | --- | --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Slope |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | ---
    | --- | --- | --- | --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 0.0000 | 0.000384 | 0.000384 | 0.000384 | 0.000384 | 0.000384 | 0.000384
    | 0.000384 | 0.000384 | 0.000384 | 0.000384 | ... | 0.000384 | 0.000384 | 0.000384
    | 0.000384 | 0.000384 | 0.000384 | 0.000384 | 0.000384 | 0.000384 | 0.000384 |'
  prefs: []
  type: TYPE_TB
- en: '| 0.0016 | 0.000384 | 0.000384 | 0.000384 | 0.000384 | 0.000384 | 0.000384
    | 0.000384 | 0.000384 | 0.000384 | 0.000384 | ... | 0.000384 | 0.000384 | 0.000384
    | 0.000384 | 0.000384 | 0.000384 | 0.000384 | 0.000384 | 0.000384 | 0.000384 |'
  prefs: []
  type: TYPE_TB
- en: '| 0.0032 | 0.000384 | 0.000384 | 0.000384 | 0.000384 | 0.000384 | 0.000384
    | 0.000384 | 0.000384 | 0.000384 | 0.000384 | ... | 0.000384 | 0.000384 | 0.000384
    | 0.000384 | 0.000384 | 0.000384 | 0.000384 | 0.000384 | 0.000384 | 0.000384 |'
  prefs: []
  type: TYPE_TB
- en: '| 0.0048 | 0.000384 | 0.000384 | 0.000384 | 0.000384 | 0.000384 | 0.000384
    | 0.000384 | 0.000384 | 0.000384 | 0.000384 | ... | 0.000384 | 0.000384 | 0.000384
    | 0.000384 | 0.000384 | 0.000384 | 0.000384 | 0.000384 | 0.000384 | 0.000384 |'
  prefs: []
  type: TYPE_TB
- en: '| 0.0064 | 0.000384 | 0.000384 | 0.000384 | 0.000384 | 0.000384 | 0.000384
    | 0.000384 | 0.000384 | 0.000384 | 0.000384 | ... | 0.000384 | 0.000384 | 0.000384
    | 0.000384 | 0.000384 | 0.000384 | 0.000384 | 0.000384 | 0.000384 | 0.000384 |'
  prefs: []
  type: TYPE_TB
- en: 5 rows × 51 columns</details> <details class="hide above-input"><summary aria-label="Toggle
    hidden content">Show code cell content Hide code cell content</summary>
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE98]'
  prefs: []
  type: TYPE_PRE
- en: '|  |  | probs |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Slope | Intercept |  |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 0.0 | -5.200 | 0.000384 |'
  prefs: []
  type: TYPE_TB
- en: '| -5.188 | 0.000384 |'
  prefs: []
  type: TYPE_TB
- en: '| -5.176 | 0.000384 |</details> <details class="hide above-input"><summary
    aria-label="Toggle hidden content">Show code cell content Hide code cell content</summary>'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE99]'
  prefs: []
  type: TYPE_PRE
- en: '|  | x | k | n | rate |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 0 | 0 | 225 | 35353 | 63.643821 |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | 1 | 240 | 34405 | 69.757303 |'
  prefs: []
  type: TYPE_TB
- en: '| 2 | 2 | 232 | 31285 | 74.156944 |'
  prefs: []
  type: TYPE_TB
- en: '| 3 | 3 | 243 | 31617 | 76.857387 |'
  prefs: []
  type: TYPE_TB
- en: '| 4 | 4 | 265 | 32690 | 81.064546 |'
  prefs: []
  type: TYPE_TB
- en: '| 5 | 5 | 280 | 31238 | 89.634420 |'
  prefs: []
  type: TYPE_TB
- en: '| 6 | 6 | 307 | 34405 | 89.231216 |'
  prefs: []
  type: TYPE_TB
- en: '| 7 | 7 | 312 | 34565 | 90.264719 |'
  prefs: []
  type: TYPE_TB
- en: '| 8 | 8 | 317 | 34977 | 90.630986 |</details> <details class="hide above-input"><summary
    aria-label="Toggle hidden content">Show code cell content Hide code cell content</summary>'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE100]'
  prefs: []
  type: TYPE_PRE
- en: '|  | x | k | n | rate |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 9 | 9 | 287 | 34415 | 83.393869 |'
  prefs: []
  type: TYPE_TB
- en: '| 10 | 10 | 320 | 36577 | 87.486672 |'
  prefs: []
  type: TYPE_TB
- en: '| 11 | 11 | 309 | 36319 | 85.079435 |</details> <details class="hide above-input"><summary
    aria-label="Toggle hidden content">Show code cell content Hide code cell content</summary>'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE101]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE102]</details> <details class="hide above-input"><summary aria-label="Toggle
    hidden content">Show code cell content Hide code cell content</summary>'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE103]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE104]</details> <details class="hide above-input"><summary aria-label="Toggle
    hidden content">Show code cell content Hide code cell content</summary>'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE105]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE106]</details> <details class="hide above-input"><summary aria-label="Toggle
    hidden content">Show code cell content Hide code cell content</summary>'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE107]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE108]</details> <details class="hide above-input"><summary aria-label="Toggle
    hidden content">Show code cell content Hide code cell content</summary>'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE109]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE110]</details> <details class="hide above-input"><summary aria-label="Toggle
    hidden content">Show code cell content Hide code cell content</summary>'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE111]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE112]</details> <details class="hide above-input"><summary aria-label="Toggle
    hidden content">Show code cell content Hide code cell content</summary>'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE113]'
  prefs: []
  type: TYPE_PRE
- en: '![_images/8d4f98743b92db5422c7fe2b019ad6b7803f2191347c176038fa4c9c488d08f3.png](../Images/877768dbfe81bcaf9a2987e3c6c619c1.png)</details><details
    class="hide above-input"><summary aria-label="Toggle hidden content">Show code
    cell content Hide code cell content</summary>'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE114]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE115]</details> <details class="hide above-input"><summary aria-label="Toggle
    hidden content">Show code cell content Hide code cell content</summary>'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE116]'
  prefs: []
  type: TYPE_PRE
- en: '![_images/b337e10727df99215bb86fa06d97261ab7c199eae928d7a36397babd31f2df3d.png](../Images/1e3b0ee906d6865b47751784829dc3ac.png)</details><details
    class="hide above-input"><summary aria-label="Toggle hidden content">Show code
    cell content Hide code cell content</summary>'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE117]'
  prefs: []
  type: TYPE_PRE
- en: '![_images/516901f5e13958d8a6c10717e88d32e21a505a54720c437b42eb3f97fdebb5b8.png](../Images/6bf5df4ebf404b58a2db1ed8ee8d60db.png)</details><details
    class="hide above-input"><summary aria-label="Toggle hidden content">Show code
    cell content Hide code cell content</summary>'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE118]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE119]</details> <details class="hide above-input"><summary aria-label="Toggle
    hidden content">Show code cell content Hide code cell content</summary>'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE120]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE121]</details> <details class="hide above-input"><summary aria-label="Toggle
    hidden content">Show code cell content Hide code cell content</summary>'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE122]'
  prefs: []
  type: TYPE_PRE
- en: '![_images/168f84e18b3338f4328e277a388b22e3d4da7f79745b6dcaa9369aeaadfde554.png](../Images/b128cc3045bc131b17f67874087d5b22.png)</details>'
  prefs: []
  type: TYPE_NORMAL
