["```py\nimport numpy as np\nfrom empiricaldist import Pmf\n\nxs = np.linspace(0, 1, 101)\nuniform = Pmf(1, xs) \n```", "```py\nfrom scipy.stats import binom\n\nk, n = 140, 250\nlikelihood = binom.pmf(k, n, xs) \n```", "```py\nposterior = uniform * likelihood\nposterior.normalize() \n```", "```py\nfrom utils import decorate\n\nposterior.plot(label='140 heads out of 250')\n\ndecorate(xlabel='Proportion of heads (x)',\n         ylabel='Probability',\n         title='Posterior distribution of x') \n```", "```py\nprint(posterior.mean(), \n      posterior.credible_interval(0.9)) \n```", "```py\n0.5595238095238094 [0.51 0.61] \n```", "```py\nk = 140\nn = 250\n\nlike_fair = binom.pmf(k, n, p=0.5)\nlike_fair \n```", "```py\n0.008357181724918204 \n```", "```py\nlike_biased = binom.pmf(k, n, p=0.56)\nlike_biased \n```", "```py\n0.05077815959518337 \n```", "```py\nK = like_biased / like_fair\nK \n```", "```py\n6.075990838368465 \n```", "```py\nbiased_uniform = uniform.copy()\nbiased_uniform[0.5] = 0\nbiased_uniform.normalize() \n```", "```py\nxs = biased_uniform.qs\nlikelihood = binom.pmf(k, n, xs) \n```", "```py\nlike_uniform = np.sum(biased_uniform * likelihood)\nlike_uniform \n```", "```py\n0.003900491927770735 \n```", "```py\nK = like_fair / like_uniform\nK \n```", "```py\n2.1425968518013625 \n```", "```py\nprior_odds = 1\nposterior_odds = prior_odds * K\nposterior_odds \n```", "```py\n2.1425968518013625 \n```", "```py\ndef prob(o):\n    return o / (o+1) \n```", "```py\nposterior_probability = prob(posterior_odds)\nposterior_probability \n```", "```py\n0.6817918278551092 \n```", "```py\nramp_up = np.arange(50)\nramp_down = np.arange(50, -1, -1)\na = np.append(ramp_up, ramp_down)\n\ntriangle = Pmf(a, xs, name='triangle')\ntriangle.normalize() \n```", "```py\nbiased_triangle = triangle.copy()\nbiased_triangle[0.5] = 0\nbiased_triangle.normalize() \n```", "```py\nbiased_uniform.plot(label='uniform prior')\nbiased_triangle.plot(label='triangle prior')\n\ndecorate(xlabel='Proportion of heads (x)',\n         ylabel='Probability',\n         title='Uniform and triangle prior distributions') \n```", "```py\n# Solution\n\nlike_triangle = np.sum(biased_triangle * likelihood)\nlike_triangle \n```", "```py\n0.00698132546485788 \n```", "```py\n# Solution\n\nK = like_fair / like_triangle\nK \n```", "```py\n1.1970766535647157 \n```", "```py\n# Solution\n\n# For this definition of \"biased\", the data are \n# very slightly in favor of the fair hypothesis. \n```", "```py\nxs = np.linspace(0, 1, 101)\nprior = Pmf(1, xs)\nprior.normalize() \n```", "```py\nbeliefs = [prior.copy() for i in range(4)] \n```", "```py\nimport matplotlib.pyplot as plt\n\noptions = dict(xticklabels='invisible', yticklabels='invisible')\n\ndef plot(beliefs, **options):\n    for i, pmf in enumerate(beliefs):\n        plt.subplot(2, 2, i+1)\n        pmf.plot(label='Machine %s' % i)\n        decorate(yticklabels=[])\n\n        if i in [0, 2]:\n            decorate(ylabel='PDF')\n\n        if i in [2, 3]:\n            decorate(xlabel='Probability of winning')\n\n    plt.tight_layout() \n```", "```py\nplot(beliefs) \n```", "```py\nlikelihood = {\n    'W': xs,\n    'L': 1 - xs\n} \n```", "```py\ndef update(pmf, data):\n  \"\"\"Update the probability of winning.\"\"\"\n    pmf *= likelihood[data]\n    pmf.normalize() \n```", "```py\nbandit = prior.copy()\n\nfor outcome in 'WLLLLLLLLL':\n    update(bandit, outcome) \n```", "```py\nbandit.plot()\ndecorate(xlabel='Probability of winning',\n         ylabel='PDF',\n         title='Posterior distribution, nine losses, one win') \n```", "```py\nactual_probs = [0.10, 0.20, 0.30, 0.40] \n```", "```py\nfrom collections import Counter\n\n# count how many times we've played each machine\ncounter = Counter()\n\ndef play(i):\n  \"\"\"Play machine i.\n\n i: index of the machine to play\n\n returns: string 'W' or 'L'\n \"\"\"\n    counter[i] += 1\n    p = actual_probs[i]\n    if np.random.random() < p:\n        return 'W'\n    else:\n        return 'L' \n```", "```py\nfor i in range(4):\n    for _ in range(10):\n        outcome = play(i)\n        update(beliefs[i], outcome) \n```", "```py\nplot(beliefs) \n```", "```py\nimport pandas as pd\n\ndef summarize_beliefs(beliefs):\n  \"\"\"Compute means and credible intervals.\n\n beliefs: sequence of Pmf\n\n returns: DataFrame\n \"\"\"\n    columns = ['Actual P(win)', \n               'Posterior mean', \n               'Credible interval']\n\n    df = pd.DataFrame(columns=columns)\n    for i, b in enumerate(beliefs):\n        mean = np.round(b.mean(), 3)\n        ci = b.credible_interval(0.9)\n        ci = np.round(ci, 3)\n        df.loc[i] = actual_probs[i], mean, ci\n    return df \n```", "```py\nsummarize_beliefs(beliefs) \n```", "```py\nsamples = np.array([b.choice(1000) \n                    for b in beliefs])\nsamples.shape \n```", "```py\n(4, 1000) \n```", "```py\nindices = np.argmax(samples, axis=0)\nindices.shape \n```", "```py\n(1000,) \n```", "```py\npmf = Pmf.from_seq(indices)\npmf \n```", "```py\npmf.choice() \n```", "```py\n1 \n```", "```py\ndef choose(beliefs):\n  \"\"\"Use Thompson sampling to choose a machine.\n\n Draws a single sample from each distribution.\n\n returns: index of the machine that yielded the highest value\n \"\"\"\n    ps = [b.choice() for b in beliefs]\n    return np.argmax(ps) \n```", "```py\nchoose(beliefs) \n```", "```py\n3 \n```", "```py\ndef choose_play_update(beliefs):\n  \"\"\"Choose a machine, play it, and update beliefs.\"\"\"\n\n    # choose a machine\n    machine = choose(beliefs)\n\n    # play it\n    outcome = play(machine)\n\n    # update beliefs\n    update(beliefs[machine], outcome) \n```", "```py\nbeliefs = [prior.copy() for i in range(4)]\ncounter = Counter() \n```", "```py\nnum_plays = 100\n\nfor i in range(num_plays):\n    choose_play_update(beliefs)\n\nplot(beliefs) \n```", "```py\nsummarize_beliefs(beliefs) \n```", "```py\ndef summarize_counter(counter):\n  \"\"\"Report the number of times each machine was played.\n\n counter: Collections.Counter\n\n returns: DataFrame\n \"\"\"\n    index = range(4)\n    columns = ['Actual P(win)', 'Times played']\n    df = pd.DataFrame(index=index, columns=columns)\n    for i, count in counter.items():\n        df.loc[i] = actual_probs[i], count\n    return df \n```", "```py\nsummarize_counter(counter) \n```", "```py\ndef prob_correct(ability, difficulty):\n  \"\"\"Probability of a correct response.\"\"\"\n    a = 100\n    c = 0.25\n    x = (ability - difficulty) / a\n    p = c + (1-c) / (1 + np.exp(-x))\n    return p \n```", "```py\nabilities = np.linspace(100, 900)\ndiff = 500\nps = prob_correct(abilities, diff) \n```", "```py\nplt.plot(abilities, ps)\ndecorate(xlabel='Ability',\n         ylabel='Probability correct',\n         title='Probability of correct answer, difficulty=500',\n         ylim=[0, 1.05]) \n```", "```py\ndef play(ability, difficulty):\n  \"\"\"Simulate a test-taker answering a question.\"\"\"\n    p = prob_correct(ability, difficulty)\n    return np.random.random() < p \n```", "```py\nprob_correct(600, 500) \n```", "```py\n0.7982939339725037 \n```", "```py\nnum_questions = 51\noutcomes = [play(600, 500) for _ in range(num_questions)]\nnp.mean(outcomes) \n```", "```py\n0.803921568627451 \n```", "```py\nfrom scipy.stats import norm\n\nmean = 500\nstd = 300\n\nqs = np.linspace(0, 1000)\nps = norm(mean, std).pdf(qs)\n\nprior = Pmf(ps, qs)\nprior.normalize() \n```", "```py\nprior.plot(label='std=300', color='C5')\n\ndecorate(xlabel='Ability',\n         ylabel='PDF',\n         title='Prior distribution of ability',\n         ylim=[0, 0.032]) \n```", "```py\ndef update_ability(pmf, data):\n  \"\"\"Update the distribution of ability.\"\"\"\n    difficulty, outcome = data\n\n    abilities = pmf.qs\n    ps = prob_correct(abilities, difficulty)\n\n    if outcome:\n        pmf *= ps\n    else:\n        pmf *= 1 - ps\n\n    pmf.normalize() \n```", "```py\nactual_600 = prior.copy()\n\nfor outcome in outcomes:\n    data = (500, outcome)\n    update_ability(actual_600, data) \n```", "```py\nactual_600.plot(color='C4')\n\ndecorate(xlabel='Ability',\n         ylabel='PDF',\n         title='Posterior distribution of ability') \n```", "```py\nactual_600.mean() \n```", "```py\n604.3325737356816 \n```", "```py\ndef choose(i, belief):\n  \"\"\"Choose the difficulty of the next question.\"\"\"\n    return 500 \n```", "```py\ndef simulate_test(actual_ability):\n  \"\"\"Simulate a person taking a test.\"\"\"\n    belief = prior.copy()\n    trace = pd.DataFrame(columns=['difficulty', 'outcome'])\n\n    for i in range(num_questions):\n        difficulty = choose(i, belief)\n        outcome = play(actual_ability, difficulty)\n        data = (difficulty, outcome)\n        update_ability(belief, data)\n        trace.loc[i] = difficulty, outcome\n\n    return belief, trace \n```", "```py\nbelief, trace = simulate_test(600) \n```", "```py\ntrace['outcome'].sum() \n```", "```py\n42 \n```", "```py\nbelief.plot(color='C4', label='ability=600')\n\ndecorate(xlabel='Ability',\n         ylabel='PDF',\n         title='Posterior distribution of ability') \n```", "```py\nbelief.mean(), belief.std() \n```", "```py\n(618.6942050450824, 40.08554296596485) \n```", "```py\nactual_abilities = np.linspace(200, 800)\nresults = pd.DataFrame(columns=['ability', 'posterior_std'])\nseries = pd.Series(index=actual_abilities, dtype=float, name='std')\n\nfor actual_ability in actual_abilities:\n    belief, trace = simulate_test(actual_ability)\n    series[actual_ability] = belief.std() \n```", "```py\nfrom utils import plot_series_lowess\n\nplot_series_lowess(series, 'C1')\n\ndecorate(xlabel='Actual ability',\n         ylabel='Standard deviation of posterior') \n```", "```py\ndef sample_posterior(actual_ability, iters):\n  \"\"\"Simulate multiple tests and compute posterior means.\n\n actual_ability: number\n iters: number of simulated tests\n\n returns: array of scores\n \"\"\"\n    scores = []\n\n    for i in range(iters):\n        belief, trace = simulate_test(actual_ability)\n        score = belief.mean()\n        scores.append(score)\n\n    return np.array(scores) \n```", "```py\nsample_500 = sample_posterior(500, iters=100) \n```", "```py\nsample_600 = sample_posterior(600, iters=100) \n```", "```py\nsample_700 = sample_posterior(700, iters=100) \n```", "```py\nsample_800 = sample_posterior(800, iters=100) \n```", "```py\nfrom empiricaldist import Cdf\n\ncdf_500 = Cdf.from_seq(sample_500)\ncdf_600 = Cdf.from_seq(sample_600)\ncdf_700 = Cdf.from_seq(sample_700)\ncdf_800 = Cdf.from_seq(sample_800) \n```", "```py\ncdf_500.plot(label='ability=500', color='C1',\n            linestyle='dashed')\ncdf_600.plot(label='ability=600', color='C3')\ncdf_700.plot(label='ability=700', color='C2',\n            linestyle='dashed')\ncdf_800.plot(label='ability=800', color='C0')\n\ndecorate(xlabel='Test score',\n         ylabel='CDF',\n         title='Sampling distribution of test scores') \n```", "```py\nnp.mean(sample_600 > sample_500) \n```", "```py\n0.98 \n```", "```py\nnp.mean(sample_700 > sample_600) \n```", "```py\n0.95 \n```", "```py\nnp.mean(sample_800 > sample_700) \n```", "```py\n0.85 \n```", "```py\n# Solution\n\n# I don't know what the optimal distribution of questions\n# is, but my guess is that it would follow the distribution\n# of ability.\n\n# But as a simplification, I used a uniform distribution\n# from 200 to 800.\n\n# It works pretty well (and substantially better than the\n# test where all questions are equally difficult.)\n\nnum_questions = 51\ndifficulties = np.linspace(200, 800, num_questions)\n\ndef choose(i, belief):\n  \"\"\"Choose the difficulty of the next question.\n\n i: index from [0..num_questions-1]\n belief: Pmf representing current estimate of ability\n\n returns: difficulty\n \"\"\"\n    return difficulties[i] \n```", "```py\n# Solution\n\n# I suspect that the optimal strategy is to choose\n# a question so that the test-taker has a 50% chance\n# of getting it right.\n\n# As rough approximation of that, I choose a question\n# with difficulty equal to the posterior mean of ability.\n\n# It works quite well (and substantially better than\n# the previous version).\n\ndef choose(i, belief):\n  \"\"\"Choose the difficulty of the next question.\n\n i: index from [0..num_questions-1]\n belief: Pmf representing current estimate of ability\n\n returns: difficulty\n \"\"\"\n    return belief.mean() \n```"]