- en: MCMC
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://allendowney.github.io/ThinkBayes2/chap19.html](https://allendowney.github.io/ThinkBayes2/chap19.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: For most of this book we’ve been using grid methods to approximate posterior
    distributions. For models with one or two parameters, grid algorithms are fast
    and the results are precise enough for most practical purposes. With three parameters,
    they start to be slow, and with more than three they are usually not practical.
  prefs: []
  type: TYPE_NORMAL
- en: In the previous chapter we saw that we can solve some problems using conjugate
    priors. But the problems we can solve this way tend to be the same ones we can
    solve with grid algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: For problems with more than a few parameters, the most powerful tool we have
    is MCMC, which stands for “Markov chain Monte Carlo”. In this context, “Monte
    Carlo” refers to to methods that generate random samples from a distribution.
    Unlike grid methods, MCMC methods don’t try to compute the posterior distribution;
    they sample from it instead.
  prefs: []
  type: TYPE_NORMAL
- en: It might seem strange that you can generate a sample without ever computing
    the distribution, but that’s the magic of MCMC.
  prefs: []
  type: TYPE_NORMAL
- en: To demonstrate, we’ll start by solving the World Cup problem. Yes, again.
  prefs: []
  type: TYPE_NORMAL
- en: The World Cup Problem
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In <<_PoissonProcesses>> we modeled goal scoring in football (soccer) as a Poisson
    process characterized by a goal-scoring rate, denoted \(\lambda\).
  prefs: []
  type: TYPE_NORMAL
- en: We used a gamma distribution to represent the prior distribution of \(\lambda\),
    then we used the outcome of the game to compute the posterior distribution for
    both teams.
  prefs: []
  type: TYPE_NORMAL
- en: To answer the first question, we used the posterior distributions to compute
    the “probability of superiority” for France.
  prefs: []
  type: TYPE_NORMAL
- en: To answer the second question, we computed the posterior predictive distributions
    for each team, that is, the distribution of goals we expect in a rematch.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter we’ll solve this problem again using PyMC3, which is a library
    that provide implementations of several MCMC methods. But we’ll start by reviewing
    the grid approximation of the prior and the prior predictive distribution.
  prefs: []
  type: TYPE_NORMAL
- en: Grid Approximation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As we did in <<_TheGammaDistribution>> we’ll use a gamma distribution with parameter
    \(\alpha=1.4\) to represent the prior.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: I’ll use `linspace` to generate possible values for \(\lambda\), and `pmf_from_dist`
    to compute a discrete approximation of the prior.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: We can use the Poisson distribution to compute the likelihood of the data; as
    an example, we’ll use 4 goals.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Now we can do the update in the usual way.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Soon we will solve the same problem with PyMC3, but first it will be useful
    to introduce something new: the prior predictive distribution.'
  prefs: []
  type: TYPE_NORMAL
- en: Prior Predictive Distribution
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We have seen the posterior predictive distribution in previous chapters; the
    prior predictive distribution is similar except that (as you might have guessed)
    it is based on the prior.
  prefs: []
  type: TYPE_NORMAL
- en: To estimate the prior predictive distribution, we’ll start by drawing a sample
    from the prior.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: The result is an array of possible values for the goal-scoring rate, \(\lambda\).
    For each value in `sample_prior`, I’ll generate one value from a Poisson distribution.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: '`sample_prior_pred` is a sample from the prior predictive distribution. To
    see what it looks like, we’ll compute the PMF of the sample.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'And here’s what it looks like:'
  prefs: []
  type: TYPE_NORMAL
- en: <details class="hide above-input"><summary aria-label="Toggle hidden content">Show
    code cell source Hide code cell source</summary>
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]</details> ![_images/eca8cc1de30bb001a105eb6a2bf94133ee6740cbf48d21dadeb130afe219aac7.png](../Images/3dd262bbe6abdce4ea23ae2cb00d096b.png)'
  prefs: []
  type: TYPE_NORMAL
- en: One reason to compute the prior predictive distribution is to check whether
    our model of the system seems reasonable. In this case, the distribution of goals
    seems consistent with what we know about World Cup football.
  prefs: []
  type: TYPE_NORMAL
- en: 'But in this chapter we have another reason: computing the prior predictive
    distribution is a first step toward using MCMC.'
  prefs: []
  type: TYPE_NORMAL
- en: Introducing PyMC3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'PyMC3 is a Python library that provides several MCMC methods. To use PyMC3,
    we have to specify a model of the process that generates the data. In this example,
    the model has two steps:'
  prefs: []
  type: TYPE_NORMAL
- en: First we draw a goal-scoring rate from the prior distribution,
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Then we draw a number of goals from a Poisson distribution.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Here’s how we specify this model in PyMC3:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: After importing `pymc3`, we create a `Model` object named `model`.
  prefs: []
  type: TYPE_NORMAL
- en: If you are not familiar with the `with` statement in Python, it is a way to
    associate a block of statements with an object. In this example, the two indented
    statements are associated with the new `Model` object. As a result, when we create
    the distribution objects, `Gamma` and `Poisson`, they are added to the `Model`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Inside the `with` statement:'
  prefs: []
  type: TYPE_NORMAL
- en: The first line creates the prior, which is a gamma distribution with the given
    parameters.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The second line creates the prior predictive, which is a Poisson distribution
    with the parameter `lam`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The first parameter of `Gamma` and `Poisson` is a string variable name.
  prefs: []
  type: TYPE_NORMAL
- en: PyMC3 provides a function that generates a visual representation of the model.
  prefs: []
  type: TYPE_NORMAL
- en: <details class="hide above-input"><summary aria-label="Toggle hidden content">Show
    code cell content Hide code cell content</summary>
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: '![_images/609b52cdd995310fa9f12f9f2aa7d3f49ae50dbdca73040d1e57a879aeaa36fc.svg](../Images/20d889a293bd0942c8e78861a5bfe4d9.png)</details>'
  prefs: []
  type: TYPE_NORMAL
- en: In this visualization, the ovals show that `lam` is drawn from a gamma distribution
    and `goals` is drawn from a Poisson distribution. The arrow shows that the values
    of `lam` are used as parameters for the distribution of `goals`.
  prefs: []
  type: TYPE_NORMAL
- en: Sampling the Prior
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: PyMC3 provides a function that generates samples from the prior and prior predictive
    distributions. We can use a `with` statement to run this function in the context
    of the model.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'The result is a dictionary-like object that maps from the variables, `lam`
    and `goals`, to the samples. We can extract the sample of `lam` like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: The following figure compares the CDF of this sample to the CDF of the sample
    we generated using the `gamma` object from SciPy.
  prefs: []
  type: TYPE_NORMAL
- en: <details class="hide above-input"><summary aria-label="Toggle hidden content">Show
    code cell content Hide code cell content</summary>
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]</details> <details class="hide above-input"><summary aria-label="Toggle
    hidden content">Show code cell source Hide code cell source</summary>'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]</details> ![_images/193b0b47427fd7f39ff507b2ce0793f76d0f69476bfc766c47bc5e428f929d77.png](../Images/4a581ee15ec55f6c43db331b3e69b294.png)'
  prefs: []
  type: TYPE_NORMAL
- en: The results are similar, which confirms that the specification of the model
    is correct and the sampler works as advertised.
  prefs: []
  type: TYPE_NORMAL
- en: From the trace we can also extract `goals`, which is a sample from the prior
    predictive distribution.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: And we can compare it to the sample we generated using the `poisson` object
    from SciPy.
  prefs: []
  type: TYPE_NORMAL
- en: Because the quantities in the posterior predictive distribution are discrete
    (number of goals) I’ll plot the CDFs as step functions.
  prefs: []
  type: TYPE_NORMAL
- en: <details class="hide above-input"><summary aria-label="Toggle hidden content">Show
    code cell content Hide code cell content</summary>
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]</details> <details class="hide above-input"><summary aria-label="Toggle
    hidden content">Show code cell source Hide code cell source</summary>'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]</details> ![_images/dc0f98c00bcdf866da67931d6c2c2c5b2478e90be73e2a3f295493d47e4a36b4.png](../Images/3e04bb6f8d13f6f6a8c646159fc0add6.png)'
  prefs: []
  type: TYPE_NORMAL
- en: Again, the results are similar, so we have some confidence we are using PyMC3
    right.
  prefs: []
  type: TYPE_NORMAL
- en: When Do We Get to Inference?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Finally, we are ready for actual inference. We just have to make one small
    change. Here is the model we used to generate the prior predictive distribution:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: And here is the model we’ll use to compute the posterior distribution.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: The difference is that we mark goals as `observed` and provide the observed
    data, `4`.
  prefs: []
  type: TYPE_NORMAL
- en: And instead of calling `sample_prior_predictive`, we’ll call `sample`, which
    is understood to sample from the posterior distribution of `lam`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: <details class="hide below-input"><summary aria-label="Toggle hidden content">Show
    code cell output Hide code cell output</summary>
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: '<progress value="3000" class="" max="3000" style="width:300px; height:20px;
    vertical-align: middle;">100.00% [3000/3000 00:01<00:00 Sampling 2 chains, 0 divergences]</progress>'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]</details>'
  prefs: []
  type: TYPE_NORMAL
- en: 'Although the specification of these models is similar, the sampling process
    is very different. I won’t go into the details of how PyMC3 works, but here are
    a few things you should be aware of:'
  prefs: []
  type: TYPE_NORMAL
- en: Depending on the model, PyMC3 uses one of several MCMC methods; in this example,
    it uses the [No U-Turn Sampler](https://en.wikipedia.org/wiki/Hamiltonian_Monte_Carlo#No_U-Turn_Sampler)
    (NUTS), which is one of the most efficient and reliable methods we have.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When the sampler starts, the first values it generates are usually not a representative
    sample from the posterior distribution, so these values are discarded. This process
    is called “tuning”.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Instead of using a single Markov chain, PyMC3 uses multiple chains. Then we
    can compare results from multiple chains to make sure they are consistent.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Although we asked for a sample of 500, PyMC3 generated two samples of 1000,
    discarded half of each, and returned the remaining 1000. From `trace2` we can
    extract a sample from the posterior distribution, like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: <details class="hide above-input"><summary aria-label="Toggle hidden content">Show
    code cell content Hide code cell content</summary>
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE27]</details>'
  prefs: []
  type: TYPE_NORMAL
- en: 'And we can compare the CDF of this sample to the posterior we computed by grid
    approximation:'
  prefs: []
  type: TYPE_NORMAL
- en: <details class="hide above-input"><summary aria-label="Toggle hidden content">Show
    code cell source Hide code cell source</summary>
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]</details> ![_images/df033dddfe2e28c72653c7a90266da82aa4902fbd977ec312df43d87c2bb4607.png](../Images/8732cbe552885e122226632c2238e45e.png)'
  prefs: []
  type: TYPE_NORMAL
- en: The results from PyMC3 are consistent with the results from the grid approximation.
  prefs: []
  type: TYPE_NORMAL
- en: Posterior Predictive Distribution
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Finally, to sample from the posterior predictive distribution, we can use `sample_posterior_predictive`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: '<details class="hide below-input"><summary aria-label="Toggle hidden content">Show
    code cell output Hide code cell output</summary> <progress value="1000" class=""
    max="1000" style="width:300px; height:20px; vertical-align: middle;">100.00% [1000/1000
    00:00<00:00]</progress></details>'
  prefs: []
  type: TYPE_NORMAL
- en: The result is a dictionary that contains a sample of `goals`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: <details class="hide above-input"><summary aria-label="Toggle hidden content">Show
    code cell content Hide code cell content</summary>
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE32]</details>'
  prefs: []
  type: TYPE_NORMAL
- en: I’ll also generate a sample from the posterior distribution we computed by grid
    approximation.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: And we can compare the two samples.
  prefs: []
  type: TYPE_NORMAL
- en: <details class="hide above-input"><summary aria-label="Toggle hidden content">Show
    code cell source Hide code cell source</summary>
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]</details> ![_images/e72732e7236a3458b5cc5d33844fdc3fed5b8289d8a9181a56868e1235c80003.png](../Images/8561fce647062c70fa4fe583e77acf8d.png)'
  prefs: []
  type: TYPE_NORMAL
- en: Again, the results are consistent. So we’ve established that we can compute
    the same results using a grid approximation or PyMC3.
  prefs: []
  type: TYPE_NORMAL
- en: But it might not be clear why. In this example, the grid algorithm requires
    less computation than MCMC, and the result is a pretty good approximation of the
    posterior distribution, rather than a sample.
  prefs: []
  type: TYPE_NORMAL
- en: However, this is a simple model with just one parameter. In fact, we could have
    solved it with even less computation, using a conjugate prior. The power of PyMC3
    will be clearer with a more complex model.
  prefs: []
  type: TYPE_NORMAL
- en: Happiness
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Recently I read [“Happiness and Life Satisfaction”](https://ourworldindata.org/happiness-and-life-satisfaction)
    by Esteban Ortiz-Ospina and Max Roser, which discusses (among many other things)
    the relationship between income and happiness, both between countries, within
    countries, and over time.
  prefs: []
  type: TYPE_NORMAL
- en: 'It cites the [“World Happiness Report”](https://worldhappiness.report/), which
    includes [results of a multiple regression analysis](https://worldhappiness.report/ed/2020/social-environments-for-world-happiness/)
    that explores the relationship between happiness and six potentially predictive
    factors:'
  prefs: []
  type: TYPE_NORMAL
- en: Income as represented by per capita GDP
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Social support
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Healthy life expectancy at birth
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Freedom to make life choices
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Generosity
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Perceptions of corruption
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The dependent variable is the national average of responses to the “Cantril
    ladder question” used by the [Gallup World Poll](https://news.gallup.com/poll/122453/understanding-gallup-uses-cantril-scale.aspx):'
  prefs: []
  type: TYPE_NORMAL
- en: Please imagine a ladder with steps numbered from zero at the bottom to 10 at
    the top. The top of the ladder represents the best possible life for you and the
    bottom of the ladder represents the worst possible life for you. On which step
    of the ladder would you say you personally feel you stand at this time?
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: I’ll refer to the responses as “happiness”, but it might be more precise to
    think of them as a measure of satisfaction with quality of life.
  prefs: []
  type: TYPE_NORMAL
- en: In the next few sections we’ll replicate the analysis in this report using Bayesian
    regression.
  prefs: []
  type: TYPE_NORMAL
- en: We can use Pandas to read the data into a `DataFrame`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: <details class="hide above-input"><summary aria-label="Toggle hidden content">Show
    code cell content Hide code cell content</summary>
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: '|  | Country name | Regional indicator | Ladder score | Standard error of ladder
    score | upperwhisker | lowerwhisker | Logged GDP per capita | Social support |
    Healthy life expectancy | Freedom to make life choices | Generosity | Perceptions
    of corruption | Ladder score in Dystopia | Explained by: Log GDP per capita |
    Explained by: Social support | Explained by: Healthy life expectancy | Explained
    by: Freedom to make life choices | Explained by: Generosity | Explained by: Perceptions
    of corruption | Dystopia + residual |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | ---
    | --- | --- | --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 0 | Finland | Western Europe | 7.8087 | 0.031156 | 7.869766 | 7.747634 |
    10.639267 | 0.954330 | 71.900826 | 0.949172 | -0.059482 | 0.195445 | 1.972317
    | 1.285190 | 1.499526 | 0.961271 | 0.662317 | 0.159670 | 0.477857 | 2.762835 |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | Denmark | Western Europe | 7.6456 | 0.033492 | 7.711245 | 7.579955 |
    10.774001 | 0.955991 | 72.402504 | 0.951444 | 0.066202 | 0.168489 | 1.972317 |
    1.326949 | 1.503449 | 0.979333 | 0.665040 | 0.242793 | 0.495260 | 2.432741 |'
  prefs: []
  type: TYPE_TB
- en: '| 2 | Switzerland | Western Europe | 7.5599 | 0.035014 | 7.628528 | 7.491272
    | 10.979933 | 0.942847 | 74.102448 | 0.921337 | 0.105911 | 0.303728 | 1.972317
    | 1.390774 | 1.472403 | 1.040533 | 0.628954 | 0.269056 | 0.407946 | 2.350267 |</details>
    <details class="hide above-input"><summary aria-label="Toggle hidden content">Show
    code cell content Hide code cell content</summary>'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE38]</details>'
  prefs: []
  type: TYPE_NORMAL
- en: The `DataFrame` has one row for each of 153 countries and one column for each
    of 20 variables.
  prefs: []
  type: TYPE_NORMAL
- en: The column called `'Ladder score'` contains the measurements of happiness we
    will try to predict.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: Simple Regression
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To get started, let’s look at the relationship between happiness and income
    as represented by gross domestic product (GDP) per person.
  prefs: []
  type: TYPE_NORMAL
- en: The column named `'Logged GDP per capita'` represents the natural logarithm
    of GDP for each country, divided by population, corrected for [purchasing power
    parity](https://en.wikipedia.org/wiki/Purchasing_power_parity) (PPP).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: The following figure is a scatter plot of `score` versus `log_gdp`, with one
    marker for each country.
  prefs: []
  type: TYPE_NORMAL
- en: <details class="hide above-input"><summary aria-label="Toggle hidden content">Show
    code cell source Hide code cell source</summary>
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]</details> ![_images/e8d32d702c0b82a48796b8eac7bce082b9e28192f892eddb25f8fc18bdc32a50.png](../Images/d353ec4ff47106dcc2019c7369b7f92f.png)'
  prefs: []
  type: TYPE_NORMAL
- en: 'It’s clear that there is a relationship between these variables: people in
    countries with higher GDP generally report higher levels of happiness.'
  prefs: []
  type: TYPE_NORMAL
- en: We can use `linregress` from SciPy to compute a simple regression of these variables.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: And here are the results.
  prefs: []
  type: TYPE_NORMAL
- en: <details class="hide above-input"><summary aria-label="Toggle hidden content">Show
    code cell source Hide code cell source</summary>
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]</details>'
  prefs: []
  type: TYPE_NORMAL
- en: '|  |  |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Slope | 0.717738 |'
  prefs: []
  type: TYPE_TB
- en: '| Intercept | -1.198646 |'
  prefs: []
  type: TYPE_TB
- en: The estimated slope is about 0.72, which suggests that an increase of one unit
    in log-GDP, which is a factor of \(e \approx 2.7\) in GDP, is associated with
    an increase of 0.72 units on the happiness ladder.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now let’s estimate the same parameters using PyMC3. We’ll use the same regression
    model as in Section <<_RegressionModel>>:'
  prefs: []
  type: TYPE_NORMAL
- en: \[y = a x + b + \epsilon\]
  prefs: []
  type: TYPE_NORMAL
- en: where \(y\) is the dependent variable (ladder score), \(x\) is the predictive
    variable (log GDP) and \(\epsilon\) is a series of values from a normal distribution
    with standard deviation \(\sigma\).
  prefs: []
  type: TYPE_NORMAL
- en: \(a\) and \(b\) are the slope and intercept of the regression line. They are
    unknown parameters, so we will use the data to estimate them.
  prefs: []
  type: TYPE_NORMAL
- en: The following is the PyMC3 specification of this model.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: The prior distributions for the parameters `a`, `b`, and `sigma` are uniform
    with ranges that are wide enough to cover the posterior distributions.
  prefs: []
  type: TYPE_NORMAL
- en: '`y_est` is the estimated value of the dependent variable, based on the regression
    equation. And `y` is a normal distribution with mean `y_est` and standard deviation
    `sigma`.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Notice how the data are included in the model:'
  prefs: []
  type: TYPE_NORMAL
- en: The values of the predictive variable, `x_data`, are used to compute `y_est`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The values of the dependent variable, `y_data`, are provided as the observed
    values of `y`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now we can use this model to generate a sample from the posterior distribution.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: <details class="hide below-input"><summary aria-label="Toggle hidden content">Show
    code cell output Hide code cell output</summary>
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: '<progress value="3000" class="" max="3000" style="width:300px; height:20px;
    vertical-align: middle;">100.00% [3000/3000 00:04<00:00 Sampling 2 chains, 0 divergences]</progress>'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]</details>'
  prefs: []
  type: TYPE_NORMAL
- en: When you run the sampler, you might get warning messages about “divergences”
    and the “acceptance probability”. You can ignore them for now.
  prefs: []
  type: TYPE_NORMAL
- en: The result is an object that contains samples from the joint posterior distribution
    of `a`, `b`, and `sigma`.
  prefs: []
  type: TYPE_NORMAL
- en: <details class="hide above-input"><summary aria-label="Toggle hidden content">Show
    code cell content Hide code cell content</summary>
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE49]</details>'
  prefs: []
  type: TYPE_NORMAL
- en: ArviZ provides `plot_posterior`, which we can use to plot the posterior distributions
    of the parameters. Here are the posterior distributions of slope, `a`, and intercept,
    `b`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: '![_images/2d0315a450aa2983502a89de28f3ca4f0bc5a82b977339041634e6e0c2faeb43.png](../Images/82eb00df25d4da6bf463032f64860e89.png)'
  prefs: []
  type: TYPE_IMG
- en: The graphs show the distributions of the samples, estimated by KDE, and 94%
    credible intervals. In the figure, “HDI” stands for [“highest-density interval”](https://www.sciencedirect.com/topics/mathematics/highest-density-interval).
  prefs: []
  type: TYPE_NORMAL
- en: The means of these samples are consistent with the parameters we estimated with
    `linregress`.
  prefs: []
  type: TYPE_NORMAL
- en: <details class="hide above-input"><summary aria-label="Toggle hidden content">Show
    code cell content Hide code cell content</summary>
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE52]</details> <details class="hide above-input"><summary aria-label="Toggle
    hidden content">Show code cell content Hide code cell content</summary>'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE54]</details>'
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we can check the marginal posterior distribution of `sigma`
  prefs: []
  type: TYPE_NORMAL
- en: <details class="hide above-input"><summary aria-label="Toggle hidden content">Show
    code cell content Hide code cell content</summary>
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: '![_images/76feb6bc1ab4570c10da92150b8c385ac493214901021ea2a2d7431582540ee3.png](../Images/d075f68956ee5fc62f1d2774da56482e.png)</details>'
  prefs: []
  type: TYPE_NORMAL
- en: The values in the posterior distribution of `sigma` seem plausible.
  prefs: []
  type: TYPE_NORMAL
- en: The simple regression model has only three parameters, so we could have used
    a grid algorithm. But the regression model in the happiness report has six predictive
    variables, so it has eight parameters in total, including the intercept and `sigma`.
  prefs: []
  type: TYPE_NORMAL
- en: It is not practical to compute a grid approximation for a model with eight parameters.
    Even a coarse grid, with 20 points along each dimension, would have more than
    25 billion points. And with 153 countries, we would have to compute almost 4 trillion
    likelihoods.
  prefs: []
  type: TYPE_NORMAL
- en: But PyMC3 can handle a model with eight parameters comfortably, as we’ll see
    in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: <details class="hide above-input"><summary aria-label="Toggle hidden content">Show
    code cell content Hide code cell content</summary>
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE57]</details> <details class="hide above-input"><summary aria-label="Toggle
    hidden content">Show code cell content Hide code cell content</summary>'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE59]</details>'
  prefs: []
  type: TYPE_NORMAL
- en: Multiple Regression
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Before we implement the multiple regression model, I’ll select the columns we
    need from the `DataFrame`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: <details class="hide above-input"><summary aria-label="Toggle hidden content">Show
    code cell content Hide code cell content</summary>
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: '|  | Ladder score | Logged GDP per capita | Social support | Healthy life expectancy
    | Freedom to make life choices | Generosity | Perceptions of corruption |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 0 | 7.8087 | 10.639267 | 0.954330 | 71.900826 | 0.949172 | -0.059482 | 0.195445
    |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | 7.6456 | 10.774001 | 0.955991 | 72.402504 | 0.951444 | 0.066202 | 0.168489
    |'
  prefs: []
  type: TYPE_TB
- en: '| 2 | 7.5599 | 10.979933 | 0.942847 | 74.102448 | 0.921337 | 0.105911 | 0.303728
    |</details>'
  prefs: []
  type: TYPE_NORMAL
- en: 'The predictive variables have different units: log-GDP is in log-dollars, life
    expectancy is in years, and the other variables are on arbitrary scales. To make
    these factors comparable, I’ll standardize the data so that each variable has
    mean 0 and standard deviation 1.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: Now let’s build the model. I’ll extract the dependent variable.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: And the dependent variables.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: And here’s the model. `b0` is the intercept; `b1` through `b6` are the parameters
    associated with the predictive variables.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs: []
  type: TYPE_PRE
- en: We could express this model more concisely using a vector of predictive variables
    and a vector of parameters, but I decided to keep it simple.
  prefs: []
  type: TYPE_NORMAL
- en: Now we can sample from the joint posterior distribution.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs: []
  type: TYPE_PRE
- en: <details class="hide below-input"><summary aria-label="Toggle hidden content">Show
    code cell output Hide code cell output</summary>
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs: []
  type: TYPE_PRE
- en: '<progress value="3000" class="" max="3000" style="width:300px; height:20px;
    vertical-align: middle;">100.00% [3000/3000 00:04<00:00 Sampling 2 chains, 0 divergences]</progress>'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE68]</details>'
  prefs: []
  type: TYPE_NORMAL
- en: Because we standardized the data, we expect the intercept to be 0, and in fact
    the posterior mean of `b0` is close to 0.
  prefs: []
  type: TYPE_NORMAL
- en: <details class="hide above-input"><summary aria-label="Toggle hidden content">Show
    code cell content Hide code cell content</summary>
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE70]</details>'
  prefs: []
  type: TYPE_NORMAL
- en: 'We can also check the posterior mean of `sigma`:'
  prefs: []
  type: TYPE_NORMAL
- en: <details class="hide above-input"><summary aria-label="Toggle hidden content">Show
    code cell content Hide code cell content</summary>
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE71]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE72]</details>'
  prefs: []
  type: TYPE_NORMAL
- en: From `trace4` we can extract samples from the posterior distributions of the
    parameters and compute their means.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE73]'
  prefs: []
  type: TYPE_PRE
- en: We can also compute 94% credible intervals (between the 3rd and 97th percentiles).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE74]'
  prefs: []
  type: TYPE_PRE
- en: The following table summarizes the results.
  prefs: []
  type: TYPE_NORMAL
- en: <details class="hide above-input"><summary aria-label="Toggle hidden content">Show
    code cell source Hide code cell source</summary>
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE75]</details>'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | Posterior mean | 94% CI |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Logged GDP per capita | 0.244 | [0.085, 0.41] |'
  prefs: []
  type: TYPE_TB
- en: '| Social support | 0.225 | [0.081, 0.377] |'
  prefs: []
  type: TYPE_TB
- en: '| Healthy life expectancy | 0.225 | [0.081, 0.377] |'
  prefs: []
  type: TYPE_TB
- en: '| Freedom to make life choices | 0.187 | [0.087, 0.289] |'
  prefs: []
  type: TYPE_TB
- en: '| Generosity | 0.054 | [-0.039, 0.14] |'
  prefs: []
  type: TYPE_TB
- en: '| Perceptions of corruption | -0.100 | [-0.197, 0.002] |'
  prefs: []
  type: TYPE_TB
- en: It looks like GDP has the strongest association with happiness (or satisfaction),
    followed by social support, life expectancy, and freedom.
  prefs: []
  type: TYPE_NORMAL
- en: After controlling for those other factors, the parameters of the other factors
    are substantially smaller, and since the CI for generosity includes 0, it is plausible
    that generosity is not substantially related to happiness, at least as they were
    measured in this study.
  prefs: []
  type: TYPE_NORMAL
- en: This example demonstrates the power of MCMC to handle models with more than
    a few parameters. But it does not really demonstrate the power of Bayesian regression.
  prefs: []
  type: TYPE_NORMAL
- en: If the goal of a regression model is to estimate parameters, there is no great
    advantage to Bayesian regression compared to conventional least squares regression.
  prefs: []
  type: TYPE_NORMAL
- en: Bayesian methods are more useful if we plan to use the posterior distribution
    of the parameters as part of a decision analysis process.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this chapter we used PyMC3 to implement two models we’ve seen before: a
    Poisson model of goal-scoring in soccer and a simple regression model. Then we
    implemented a multiple regression model that would not have been possible to compute
    with a grid approximation.'
  prefs: []
  type: TYPE_NORMAL
- en: 'MCMC is more powerful than grid methods, but that power comes with some disadvantages:'
  prefs: []
  type: TYPE_NORMAL
- en: MCMC algorithms are fiddly. The same model might behave well with some priors
    and less well with others. And the sampling process often produces warnings about
    tuning steps, divergences, “r-hat statistics”, acceptance rates, and effective
    samples. It takes some expertise to diagnose and correct these issues.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: I find it easier to develop models incrementally using grid algorithms, checking
    intermediate results along the way. With PyMC3, it is not as easy to be confident
    that you have specified a model correctly.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For these reasons, I recommend a model development process that starts with
    grid algorithms and resorts to MCMC if necessary. As we saw in the previous chapters,
    you can solve a lot of real-world problems with grid methods. But when you need
    MCMC, it is useful to have a grid algorithm to compare to (even if it is based
    on a simpler model).
  prefs: []
  type: TYPE_NORMAL
- en: All of the models in this book can be implemented in PyMC3, but some of them
    are easier to translate than others. In the exercises, you will have a chance
    to practice.
  prefs: []
  type: TYPE_NORMAL
- en: Exercises
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Exercise:** As a warmup, let’s use PyMC3 to solve the Euro problem. Suppose
    we spin a coin 250 times and it comes up heads 140 times. What is the posterior
    distribution of \(x\), the probability of heads?'
  prefs: []
  type: TYPE_NORMAL
- en: For the prior, use a beta distribution with parameters \(\alpha=1\) and \(\beta=1\).
  prefs: []
  type: TYPE_NORMAL
- en: See [the PyMC3 documentation](https://docs.pymc.io/api/distributions/continuous.html)
    for the list of continuous distributions.
  prefs: []
  type: TYPE_NORMAL
- en: <details class="hide above-input"><summary aria-label="Toggle hidden content">Show
    code cell content Hide code cell content</summary>
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE76]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE77]'
  prefs: []
  type: TYPE_PRE
- en: '<progress value="3000" class="" max="3000" style="width:300px; height:20px;
    vertical-align: middle;">100.00% [3000/3000 00:00<00:00 Sampling 2 chains, 0 divergences]</progress>'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE78]'
  prefs: []
  type: TYPE_PRE
- en: '![_images/9aceeffa47605e83ecf31ae37b480a41d897024e249e5e6400cf268e5aeecd95.png](../Images/76c133082854e9fd2a774b69a9a190a4.png)</details>'
  prefs: []
  type: TYPE_NORMAL
- en: '**Exercise:** Now let’s use PyMC3 to replicate the solution to the Grizzly
    Bear problem in <<_TheGrizzlyBearProblem>>, which is based on the hypergeometric
    distribution.'
  prefs: []
  type: TYPE_NORMAL
- en: I’ll present the problem with slightly different notation, to make it consistent
    with PyMC3.
  prefs: []
  type: TYPE_NORMAL
- en: Suppose that during the first session, `k=23` bears are tagged. During the second
    session, `n=19` bears are identified, of which `x=4` had been tagged.
  prefs: []
  type: TYPE_NORMAL
- en: Estimate the posterior distribution of `N`, the number of bears in the environment.
  prefs: []
  type: TYPE_NORMAL
- en: For the prior, use a discrete uniform distribution from 50 to 500.
  prefs: []
  type: TYPE_NORMAL
- en: See [the PyMC3 documentation](https://docs.pymc.io/api/distributions/discrete.html)
    for the list of discrete distributions.
  prefs: []
  type: TYPE_NORMAL
- en: 'Note: `HyperGeometric` was added to PyMC3 after version 3.8, so you might need
    to update your installation to do this exercise.'
  prefs: []
  type: TYPE_NORMAL
- en: <details class="hide above-input"><summary aria-label="Toggle hidden content">Show
    code cell content Hide code cell content</summary>
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE79]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE80]'
  prefs: []
  type: TYPE_PRE
- en: '<progress value="4000" class="" max="4000" style="width:300px; height:20px;
    vertical-align: middle;">100.00% [4000/4000 00:00<00:00 Sampling 2 chains, 0 divergences]</progress>'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE81]'
  prefs: []
  type: TYPE_PRE
- en: '![_images/6508eeee449a1c8e82ce7ce0664789351b1fd247cb5460e9429a6934db033734.png](../Images/dee9f9d8c3a7ab7b7a7cad18a04ff162.png)</details>'
  prefs: []
  type: TYPE_NORMAL
- en: '**Exercise:** In <<_TheWeibullDistribution>> we generated a sample from a Weibull
    distribution with \(\lambda=3\) and \(k=0.8\). Then we used the data to compute
    a grid approximation of the posterior distribution of those parameters.'
  prefs: []
  type: TYPE_NORMAL
- en: Now let’s do the same with PyMC3.
  prefs: []
  type: TYPE_NORMAL
- en: For the priors, you can use uniform distributions as we did in <<_SurvivalAnalysis>>,
    or you could use `HalfNormal` distributions provided by PyMC3.
  prefs: []
  type: TYPE_NORMAL
- en: 'Note: The `Weibull` class in PyMC3 uses different parameters than SciPy. The
    parameter `alpha` in PyMC3 corresponds to \(k\), and `beta` corresponds to \(\lambda\).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s the data again:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE82]'
  prefs: []
  type: TYPE_PRE
- en: <details class="hide above-input"><summary aria-label="Toggle hidden content">Show
    code cell content Hide code cell content</summary>
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE83]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE84]'
  prefs: []
  type: TYPE_PRE
- en: '<progress value="4000" class="" max="4000" style="width:300px; height:20px;
    vertical-align: middle;">100.00% [4000/4000 00:01<00:00 Sampling 2 chains, 0 divergences]</progress>'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE85]'
  prefs: []
  type: TYPE_PRE
- en: '![_images/20ca2eef771e17ce366680fbf0cd5b3fa489b23d328038c5def182f25c399a5e.png](../Images/90b78b9ea67cbd74076b70a4cef6125f.png)</details>'
  prefs: []
  type: TYPE_NORMAL
- en: '**Exercise:** In <<_ImprovingReadingAbility>> we used data from a reading test
    to estimate the parameters of a normal distribution.'
  prefs: []
  type: TYPE_NORMAL
- en: Make a model that defines uniform prior distributions for `mu` and `sigma` and
    uses the data to estimate their posterior distributions.
  prefs: []
  type: TYPE_NORMAL
- en: Now estimate the parameters for the treated group.
  prefs: []
  type: TYPE_NORMAL
- en: <details class="hide above-input"><summary aria-label="Toggle hidden content">Show
    code cell content Hide code cell content</summary>
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE86]</details> <details class="hide above-input"><summary aria-label="Toggle
    hidden content">Show code cell content Hide code cell content</summary>'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE87]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE88]'
  prefs: []
  type: TYPE_PRE
- en: '<progress value="3000" class="" max="3000" style="width:300px; height:20px;
    vertical-align: middle;">100.00% [3000/3000 00:01<00:00 Sampling 2 chains, 0 divergences]</progress>'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE89]</details> <details class="hide above-input"><summary aria-label="Toggle
    hidden content">Show code cell content Hide code cell content</summary>'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE90]'
  prefs: []
  type: TYPE_PRE
- en: '![_images/d8e1802f0f4db48c5429de4dc2411d4445c82281b3e3719facb259a356c7daac.png](../Images/0ea3f1ef40964a9f6ae59de890108f8d.png)</details>'
  prefs: []
  type: TYPE_NORMAL
- en: '**Exercise:** In <<_TheLincolnIndexProblem>> we used a grid algorithm to solve
    the Lincoln Index problem as presented by John D. Cook:'
  prefs: []
  type: TYPE_NORMAL
- en: “Suppose you have a tester who finds 20 bugs in your program. You want to estimate
    how many bugs are really in the program. You know there are at least 20 bugs,
    and if you have supreme confidence in your tester, you may suppose there are around
    20 bugs. But maybe your tester isn’t very good. Maybe there are hundreds of bugs.
    How can you have any idea how many bugs there are? There’s no way to know with
    one tester. But if you have two testers, you can get a good idea, even if you
    don’t know how skilled the testers are.”
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Suppose the first tester finds 20 bugs, the second finds 15, and they find 3
    in common; use PyMC3 to estimate the number of bugs.
  prefs: []
  type: TYPE_NORMAL
- en: 'Note: This exercise is more difficult that some of the previous ones. One of
    the challenges is that the data includes `k00`, which depends on `N`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE91]'
  prefs: []
  type: TYPE_PRE
- en: 'So we have to construct the data as part of the model. To do that, we can use
    `pm.math.stack`, which makes an array:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE92]'
  prefs: []
  type: TYPE_PRE
- en: Finally, you might find it helpful to use `pm.Multinomial`.
  prefs: []
  type: TYPE_NORMAL
- en: 'I’ll use the following notation for the data:'
  prefs: []
  type: TYPE_NORMAL
- en: k11 is the number of bugs found by both testers,
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: k10 is the number of bugs found by the first tester but not the second,
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: k01 is the number of bugs found by the second tester but not the first, and
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: k00 is the unknown number of undiscovered bugs.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Here are the values for all but `k00`:'
  prefs: []
  type: TYPE_NORMAL
- en: <details class="hide above-input"><summary aria-label="Toggle hidden content">Show
    code cell content Hide code cell content</summary>
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE93]</details>'
  prefs: []
  type: TYPE_NORMAL
- en: 'In total, 32 bugs have been discovered:'
  prefs: []
  type: TYPE_NORMAL
- en: <details class="hide above-input"><summary aria-label="Toggle hidden content">Show
    code cell content Hide code cell content</summary>
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE94]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE95]</details> <details class="hide above-input"><summary aria-label="Toggle
    hidden content">Show code cell content Hide code cell content</summary>'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE96]</details> <details class="hide above-input"><summary aria-label="Toggle
    hidden content">Show code cell content Hide code cell content</summary>'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE97]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE98]'
  prefs: []
  type: TYPE_PRE
- en: '<progress value="4000" class="" max="4000" style="width:300px; height:20px;
    vertical-align: middle;">100.00% [4000/4000 00:02<00:00 Sampling 2 chains, 0 divergences]</progress>'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE99]</details> <details class="hide above-input"><summary aria-label="Toggle
    hidden content">Show code cell content Hide code cell content</summary>'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE100]'
  prefs: []
  type: TYPE_PRE
- en: '![_images/beeaa10ba1b2c50623f3239a25baa2d674c0a47c8035caaac00df5f38eebf9b4.png](../Images/c82753560176a0cc0aa0c7e546e6dc9a.png)</details>'
  prefs: []
  type: TYPE_NORMAL
