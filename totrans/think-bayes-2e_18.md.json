["```py\nimport numpy as np\nfrom scipy.stats import hypergeom\n\nN = 100\nK = 23\nn = 19\n\nks = np.arange(12)\nps = hypergeom(N, K, n).pmf(ks) \n```", "```py\nimport matplotlib.pyplot as plt\nfrom utils import decorate\n\nplt.bar(ks, ps)\n\ndecorate(xlabel='Number of bears observed twice',\n         ylabel='PMF',\n         title='Hypergeometric distribution of k (known population 100)') \n```", "```py\nimport numpy as np\nfrom utils import make_uniform\n\nqs = np.arange(50, 501)\nprior_N = make_uniform(qs, name='N')\nprior_N.shape \n```", "```py\n(451,) \n```", "```py\nNs = prior_N.qs\nK = 23\nn = 19\nk = 4\n\nlikelihood = hypergeom(Ns, K, n).pmf(k) \n```", "```py\nposterior_N = prior_N * likelihood\nposterior_N.normalize() \n```", "```py\n0.07755224277106727 \n```", "```py\nposterior_N.plot(color='C4')\n\ndecorate(xlabel='Population of bears (N)',\n         ylabel='PDF',\n         title='Posterior distribution of N') \n```", "```py\nposterior_N.max_prob() \n```", "```py\n109 \n```", "```py\nposterior_N.mean() \n```", "```py\n173.79880627085637 \n```", "```py\nposterior_N.credible_interval(0.9) \n```", "```py\narray([ 77., 363.]) \n```", "```py\nK = 23\nn = 19\nk = 4 \n```", "```py\nk10 = 23 - 4\nk01 = 19 - 4\nk11 = 4 \n```", "```py\nN = 100\n\nobserved = k01 + k10 + k11\nk00 = N - observed\nk00 \n```", "```py\n62 \n```", "```py\nx = [k00, k01, k10, k11]\nx \n```", "```py\n[62, 15, 19, 4] \n```", "```py\np = 0.2\nq = 1-p\ny = [q*q, q*p, p*q, p*p]\ny \n```", "```py\n[0.6400000000000001,\n 0.16000000000000003,\n 0.16000000000000003,\n 0.04000000000000001] \n```", "```py\nfrom scipy.stats import multinomial\n\nlikelihood = multinomial.pmf(x, N, y)\nlikelihood \n```", "```py\n0.0016664011988507257 \n```", "```py\nqs = np.linspace(0, 0.99, num=100)\nprior_p = make_uniform(qs, name='p') \n```", "```py\nfrom utils import make_joint\n\njoint_prior = make_joint(prior_p, prior_N)\njoint_prior.shape \n```", "```py\n(451, 100) \n```", "```py\nfrom empiricaldist import Pmf\n\njoint_pmf = Pmf(joint_prior.stack())\njoint_pmf.head(3) \n```", "```py\ntype(joint_pmf) \n```", "```py\nempiricaldist.empiricaldist.Pmf \n```", "```py\ntype(joint_pmf.index) \n```", "```py\npandas.core.indexes.multi.MultiIndex \n```", "```py\njoint_pmf.shape \n```", "```py\n(45100,) \n```", "```py\nlikelihood = joint_pmf.copy() \n```", "```py\nobserved = k01 + k10 + k11\n\nfor N, p in joint_pmf.index:\n    k00 = N - observed\n    x = [k00, k01, k10, k11]\n    q = 1-p\n    y = [q*q, q*p, p*q, p*p]\n    likelihood[N, p] = multinomial.pmf(x, N, y) \n```", "```py\nposterior_pmf = joint_pmf * likelihood\nposterior_pmf.normalize() \n```", "```py\n2.9678796190279657e-05 \n```", "```py\njoint_posterior = posterior_pmf.unstack() \n```", "```py\nfrom utils import plot_contour\n\nplot_contour(joint_posterior)\n\ndecorate(title='Joint posterior distribution of N and p') \n```", "```py\nfrom utils import marginal\n\nposterior2_p = marginal(joint_posterior, 0)\nposterior2_N = marginal(joint_posterior, 1) \n```", "```py\nposterior2_p.plot(color='C1')\n\ndecorate(xlabel='Probability of observing a bear',\n         ylabel='PDF',\n         title='Posterior marginal distribution of p') \n```", "```py\nposterior_N.plot(label='one-parameter model', color='C4')\nposterior2_N.plot(label='two-parameter model', color='C1')\n\ndecorate(xlabel='Population of bears (N)',\n         ylabel='PDF',\n         title='Posterior marginal distribution of N') \n```", "```py\nprint(posterior_N.mean(), \n      posterior_N.credible_interval(0.9)) \n```", "```py\n173.79880627085637 [ 77\\. 363.] \n```", "```py\nprint(posterior2_N.mean(), \n      posterior2_N.credible_interval(0.9)) \n```", "```py\n138.750521364726 [ 68\\. 277.] \n```", "```py\nN1 = 138 \n```", "```py\nmean = (23 + 19) / 2\np = mean/N1\np \n```", "```py\n0.15217391304347827 \n```", "```py\nfrom scipy.stats import binom\n\nbinom(N1, p).std() \n```", "```py\n4.219519857292647 \n```", "```py\nN2 = 173\np = mean/N2\np \n```", "```py\n0.12138728323699421 \n```", "```py\nbinom(N2, p).std() \n```", "```py\n4.2954472470306415 \n```", "```py\nimport pandas as pd\nfrom seaborn import JointGrid\n\ndef joint_plot(joint, **options):\n  \"\"\"Show joint and marginal distributions.\n\n joint: DataFrame that represents a joint distribution\n options: passed to JointGrid\n \"\"\"\n    # get the names of the parameters\n    x = joint.columns.name\n    x = 'x' if x is None else x\n\n    y = joint.index.name\n    y = 'y' if y is None else y\n\n    # make a JointGrid with minimal data\n    data = pd.DataFrame({x:[0], y:[0]})\n    g = JointGrid(x=x, y=y, data=data, **options)\n\n    # replace the contour plot\n    g.ax_joint.contour(joint.columns, \n                       joint.index, \n                       joint, \n                       cmap='viridis')\n\n    # replace the marginals\n    marginal_x = marginal(joint, 0)\n    g.ax_marg_x.plot(marginal_x.qs, marginal_x.ps)\n\n    marginal_y = marginal(joint, 1)\n    g.ax_marg_y.plot(marginal_y.ps, marginal_y.qs) \n```", "```py\njoint_plot(joint_posterior) \n```", "```py\nk10 = 20 - 3\nk01 = 15 - 3\nk11 = 3 \n```", "```py\np0, p1 = 0.2, 0.15 \n```", "```py\ndef compute_probs(p0, p1):\n  \"\"\"Computes the probability for each of 4 categories.\"\"\"\n    q0 = 1-p0\n    q1 = 1-p1\n    return [q0*q1, q0*p1, p0*q1, p0*p1] \n```", "```py\ny = compute_probs(p0, p1)\ny \n```", "```py\n[0.68, 0.12, 0.17, 0.03] \n```", "```py\nqs = np.arange(32, 350, step=5) \nprior_N = make_uniform(qs, name='N')\nprior_N.head(3) \n```", "```py\ndata = np.array([0, k01, k10, k11]) \n```", "```py\nlikelihood = prior_N.copy()\nobserved = data.sum()\nx = data.copy()\n\nfor N in prior_N.qs:\n    x[0] = N - observed\n    likelihood[N] = multinomial.pmf(x, N, y) \n```", "```py\nposterior_N = prior_N * likelihood\nposterior_N.normalize() \n```", "```py\n0.0003425201572557094 \n```", "```py\nposterior_N.plot(color='C4')\n\ndecorate(xlabel='Number of bugs (N)',\n         ylabel='PMF',\n         title='Posterior marginal distribution of n with known p1, p2') \n```", "```py\nprint(posterior_N.mean(), \n      posterior_N.credible_interval(0.9)) \n```", "```py\n102.1249999999998 [ 77\\. 127.] \n```", "```py\nqs = np.linspace(0, 1, num=51)\nprior_p0 = make_uniform(qs, name='p0')\nprior_p1 = make_uniform(qs, name='p1') \n```", "```py\njoint2 = make_joint(prior_p0, prior_N)\njoint2.shape \n```", "```py\n(64, 51) \n```", "```py\njoint2_pmf = Pmf(joint2.stack())\njoint2_pmf.head(3) \n```", "```py\njoint3 = make_joint(prior_p1, joint2_pmf)\njoint3.shape \n```", "```py\n(3264, 51) \n```", "```py\njoint3.head(3) \n```", "```py\njoint3_pmf = Pmf(joint3.stack())\njoint3_pmf.head(3) \n```", "```py\njoint3_pmf.shape \n```", "```py\n(166464,) \n```", "```py\nlikelihood = joint3_pmf.copy()\nobserved = data.sum()\nx = data.copy()\n\nfor N, p0, p1 in joint3_pmf.index:\n    x[0] = N - observed\n    y = compute_probs(p0, p1)\n    likelihood[N, p0, p1] = multinomial.pmf(x, N, y) \n```", "```py\nposterior_pmf = joint3_pmf * likelihood\nposterior_pmf.normalize() \n```", "```py\n8.941088283758206e-06 \n```", "```py\nposterior_N = posterior_pmf.marginal(0) \n```", "```py\nposterior_N.plot(color='C4')\n\ndecorate(xlabel='Number of bugs (N)',\n         ylabel='PDF',\n         title='Posterior marginal distributions of N') \n```", "```py\nposterior_N.mean() \n```", "```py\n105.7656173219623 \n```", "```py\nposterior_p1 = posterior_pmf.marginal(1)\nposterior_p2 = posterior_pmf.marginal(2)\n\nposterior_p1.plot(label='p1')\nposterior_p2.plot(label='p2')\n\ndecorate(xlabel='Probability of finding a bug',\n         ylabel='PDF',\n         title='Posterior marginal distributions of p1 and p2') \n```", "```py\nposterior_p1.mean(), posterior_p1.credible_interval(0.9) \n```", "```py\n(0.2297065971677732, array([0.1, 0.4])) \n```", "```py\nposterior_p2.mean(), posterior_p2.credible_interval(0.9) \n```", "```py\n(0.17501172155925757, array([0.06, 0.32])) \n```", "```py\ndata2 = np.array([0, 73, 86, 49]) \n```", "```py\nqs = np.arange(200, 500, step=5)\nprior_N = make_uniform(qs, name='N')\nprior_N.head(3) \n```", "```py\nqs = np.linspace(0, 0.98, num=50)\nprior_p = make_uniform(qs, name='p')\nprior_p.head(3) \n```", "```py\n# Solution\n\njoint_prior = make_joint(prior_p, prior_N)\njoint_prior.head(3) \n```", "```py\n# Solution\n\nprior_pmf = Pmf(joint_prior.stack())\nprior_pmf.head(3) \n```", "```py\n# Solution\n\nobserved = data2.sum()\nx = data2.copy()\nlikelihood = prior_pmf.copy()\n\nfor N, p in prior_pmf.index:\n    x[0] = N - observed\n    q = 1-p\n    y = [q*q, q*p, p*q, p*p]\n    likelihood.loc[N, p] = multinomial.pmf(x, N, y) \n```", "```py\n# Solution\n\nposterior_pmf = prior_pmf * likelihood\nposterior_pmf.normalize() \n```", "```py\n1.266226682238907e-06 \n```", "```py\n# Solution\n\njoint_posterior = posterior_pmf.unstack() \n```", "```py\n# Solution\n\nplot_contour(joint_posterior)\n\ndecorate(title='Joint posterior distribution of N and p') \n```", "```py\n# Solution\n\nmarginal_N = marginal(joint_posterior, 1)\nmarginal_N.plot(color='C4')\n\ndecorate(xlabel='Number of cases (N)',\n         ylabel='PDF',\n         title='Posterior marginal distribution of N') \n```", "```py\n# Solution\n\nmarginal_N.mean(), marginal_N.credible_interval(0.9) \n```", "```py\n(342.1317040018937, array([295., 400.])) \n```", "```py\nHepatitis A virus list\nP    Q    E    Data\n1    1    1    k111 =28\n1    1    0    k110 =21\n1    0    1    k101 =17\n1    0    0    k100 =69\n0    1    1    k011 =18\n0    1    0    k010 =55\n0    0    1    k001 =63\n0    0    0    k000 =?? \n```", "```py\ndata3 = np.array([0, 63, 55, 18, 69, 17, 21, 28]) \n```", "```py\nq = 1-p\nps = [q*q, q*p, p*q, p*p] \n```", "```py\ndef cartesian_product(*args, **options):\n  \"\"\"Cartesian product of sequences.\n\n args: any number of sequences\n options: passes to `MultiIndex.from_product`\n\n returns: DataFrame with one column per sequence\n \"\"\"\n    index = pd.MultiIndex.from_product(args, **options)\n    return pd.DataFrame(index=index).reset_index() \n```", "```py\np = 0.2\nt = (1-p, p)\ndf = cartesian_product(t, t, t)\ndf \n```", "```py\ny = df.prod(axis=1)\ny \n```", "```py\n0    0.512\n1    0.128\n2    0.128\n3    0.032\n4    0.128\n5    0.032\n6    0.032\n7    0.008\ndtype: float64 \n```", "```py\n# Solution\n\nobserved = data3.sum()\nx = data3.copy()\nlikelihood = prior_pmf.copy()\n\nfor N, p in prior_pmf.index:\n    x[0] = N - observed\n    t = (1-p, p)\n    df = cartesian_product(t, t, t)\n    y = df.prod(axis=1)\n    likelihood.loc[N, p] = multinomial.pmf(x, N, y) \n```", "```py\n# Solution\n\nposterior_pmf = prior_pmf * likelihood\nposterior_pmf.normalize() \n```", "```py\n2.6359517829553705e-16 \n```", "```py\n# Solution\n\njoint_posterior = posterior_pmf.unstack() \n```", "```py\n# Solution\n\nplot_contour(joint_posterior)\n\ndecorate(title='Joint posterior distribution of N and p') \n```", "```py\n# Solution\n\nmarginal3_N = marginal(joint_posterior, 1) \n```", "```py\n# Solution\n\nmarginal_N.plot(label='After two lists', color='C4')\nmarginal3_N.plot(label='After three lists', color='C1')\n\ndecorate(xlabel='Number of cases (N)',\n         ylabel='PDF',\n         title='Posterior marginal distribution of N') \n```", "```py\n# Solution\n\nmarginal_N.mean(), marginal_N.credible_interval(0.9) \n```", "```py\n(342.1317040018937, array([295., 400.])) \n```", "```py\n# Solution\n\nmarginal3_N.mean(), marginal3_N.credible_interval(0.9) \n```", "```py\n(391.0050140750373, array([360., 430.])) \n```"]