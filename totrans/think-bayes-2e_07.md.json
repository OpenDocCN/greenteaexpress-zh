["```py\nfrom scipy.stats import binom\n\nn = 2\np = 0.5\nk = 1\n\nbinom.pmf(k, n, p) \n```", "```py\n0.5 \n```", "```py\nimport numpy as np\nks = np.arange(n+1)\n\nps = binom.pmf(ks, n, p)\nps \n```", "```py\narray([0.25, 0.5 , 0.25]) \n```", "```py\nfrom empiricaldist import Pmf\n\npmf_k = Pmf(ps, ks)\npmf_k \n```", "```py\ndef make_binomial(n, p):\n  \"\"\"Make a binomial Pmf.\"\"\"\n    ks = np.arange(n+1)\n    ps = binom.pmf(ks, n, p)\n    return Pmf(ps, ks) \n```", "```py\npmf_k = make_binomial(n=250, p=0.5) \n```", "```py\nfrom utils import decorate\n\npmf_k.plot(label='n=250, p=0.5')\n\ndecorate(xlabel='Number of heads (k)',\n         ylabel='PMF',\n         title='Binomial distribution') \n```", "```py\npmf_k.max_prob() \n```", "```py\n125 \n```", "```py\npmf_k[125] \n```", "```py\n0.05041221314731537 \n```", "```py\npmf_k[140] \n```", "```py\n0.008357181724917673 \n```", "```py\ndef prob_ge(pmf, threshold):\n  \"\"\"Probability of quantities greater than threshold.\"\"\"\n    ge = (pmf.qs >= threshold)\n    total = pmf[ge].sum()\n    return total \n```", "```py\nprob_ge(pmf_k, 140) \n```", "```py\n0.033210575620022706 \n```", "```py\npmf_k.prob_ge(140) \n```", "```py\n0.033210575620022706 \n```", "```py\nimport matplotlib.pyplot as plt\n\ndef fill_below(pmf):\n    qs = pmf.index\n    ps = pmf.values\n    plt.fill_between(qs, ps, 0, color='C5', alpha=0.4)\n\nqs = pmf_k.index\nfill_below(pmf_k[qs>=140])\nfill_below(pmf_k[qs<=110])\npmf_k.plot(label='n=250, p=0.5')\n\ndecorate(xlabel='Number of heads (k)',\n         ylabel='PMF',\n         title='Binomial distribution') \n```", "```py\npmf_k.prob_le(110) \n```", "```py\n0.033210575620022706 \n```", "```py\nhypos = np.linspace(0, 1, 101)\nprior = Pmf(1, hypos) \n```", "```py\nlikelihood_heads = hypos\nlikelihood_tails = 1 - hypos \n```", "```py\nlikelihood = {\n    'H': likelihood_heads,\n    'T': likelihood_tails\n} \n```", "```py\ndataset = 'H' * 140 + 'T' * 110 \n```", "```py\ndef update_euro(pmf, dataset):\n  \"\"\"Update pmf with a given sequence of H and T.\"\"\"\n    for data in dataset:\n        pmf *= likelihood[data]\n\n    pmf.normalize() \n```", "```py\nposterior = prior.copy()\nupdate_euro(posterior, dataset) \n```", "```py\ndef decorate_euro(title):\n    decorate(xlabel='Proportion of heads (x)',\n             ylabel='Probability',\n             title=title) \n```", "```py\nposterior.plot(label='140 heads out of 250', color='C4')\ndecorate_euro(title='Posterior distribution of x') \n```", "```py\nposterior.max_prob() \n```", "```py\n0.56 \n```", "```py\nuniform = Pmf(1, hypos, name='uniform')\nuniform.normalize() \n```", "```py\nramp_up = np.arange(50)\nramp_down = np.arange(50, -1, -1)\n\na = np.append(ramp_up, ramp_down)\n\ntriangle = Pmf(a, hypos, name='triangle')\ntriangle.normalize() \n```", "```py\n2500 \n```", "```py\nuniform.plot()\ntriangle.plot()\ndecorate_euro(title='Uniform and triangle prior distributions') \n```", "```py\nupdate_euro(uniform, dataset)\nupdate_euro(triangle, dataset) \n```", "```py\nuniform.plot()\ntriangle.plot()\ndecorate_euro(title='Posterior distributions') \n```", "```py\nfrom scipy.stats import binom\n\ndef update_binomial(pmf, data):\n  \"\"\"Update pmf using the binomial distribution.\"\"\"\n    k, n = data\n    xs = pmf.qs\n    likelihood = binom.pmf(k, n, xs)\n    pmf *= likelihood\n    pmf.normalize() \n```", "```py\nuniform2 = Pmf(1, hypos, name='uniform2')\ndata = 140, 250\nupdate_binomial(uniform2, data) \n```", "```py\nnp.allclose(uniform, uniform2) \n```", "```py\nTrue \n```", "```py\nhypos = np.linspace(0.1, 0.4, 101)\nprior = Pmf(1, hypos) \n```", "```py\nlikelihood = {\n    'Y': hypos,\n    'N': 1-hypos\n} \n```", "```py\ndataset = 'Y' * 25 + 'N' * 75 \n```", "```py\nfor data in dataset:\n    prior *= likelihood[data]\n\nprior.normalize() \n```", "```py\nprior.plot(label='prior')\ndecorate(xlabel='Probability of getting a hit',\n         ylabel='PMF') \n```", "```py\n# Solution\n\nposterior = prior.copy()\n\nfor data in 'YYY':\n    posterior *= likelihood[data]\n\nposterior.normalize() \n```", "```py\n0.017944179687707326 \n```", "```py\n# Solution\n\nprior.plot(label='prior')\nposterior.plot(label='posterior ')\ndecorate(xlabel='Probability of getting a hit',\n         ylabel='PMF') \n```", "```py\n# Solution\n\nprior.max_prob() \n```", "```py\n0.25 \n```", "```py\n# Solution\n\nposterior.max_prob() \n```", "```py\n0.271 \n```", "```py\n# Solution\n\n# I'll use a uniform distribution again, although there might\n# be background information we could use to choose a more\n# specific prior.\n\nhypos = np.linspace(0, 1, 101)\nprior = Pmf(1, hypos) \n```", "```py\n# Solution\n\n# If the actual fraction of cheaters is `x`, the number of\n# YESes is (0.5 + x/2), and the number of NOs is (1-x)/2\n\nlikelihood = {\n    'Y': 0.5 + hypos/2,\n    'N': (1-hypos)/2\n} \n```", "```py\n# Solution\n\ndataset = 'Y' * 80 + 'N' * 20\n\nposterior = prior.copy()\n\nfor data in dataset:\n    posterior *= likelihood[data]\n\nposterior.normalize() \n```", "```py\n3.6945139133967024e-21 \n```", "```py\n# Solution\n\nposterior.plot(label='80 YES, 20 NO')\ndecorate(xlabel='Proportion of cheaters',\n         ylabel='PMF') \n```", "```py\n# Solution\n\nposterior.idxmax() \n```", "```py\n0.6 \n```", "```py\n# Solution\n\ndef update_unreliable(pmf, dataset, y):\n\n    likelihood = {\n        'H': (1-y) * hypos + y * (1-hypos),\n        'T': y * hypos + (1-y) * (1-hypos)\n    }\n    for data in dataset:\n        pmf *= likelihood[data]\n\n    pmf.normalize() \n```", "```py\n# Solution\n\nhypos = np.linspace(0, 1, 101)\nprior = Pmf(1, hypos)\ndataset = 'H' * 140 + 'T' * 110\n\nposterior00 = prior.copy()\nupdate_unreliable(posterior00, dataset, 0.0)\n\nposterior02 = prior.copy()\nupdate_unreliable(posterior02, dataset, 0.2)\n\nposterior04 = prior.copy()\nupdate_unreliable(posterior04, dataset, 0.4) \n```", "```py\n# Solution\n\nposterior00.plot(label='y = 0.0')\nposterior02.plot(label='y = 0.2')\nposterior04.plot(label='y = 0.4')\ndecorate(xlabel='Proportion of heads',\n         ylabel='PMF') \n```", "```py\n# Solution\n\nposterior00.idxmax(), posterior02.idxmax(), posterior04.idxmax() \n```", "```py\n(0.56, 0.6, 0.8) \n```", "```py\n# Solution\n\nhypos = np.linspace(0.1, 0.4, 101)\nprior = Pmf(1, hypos) \n```", "```py\n# Solution\n\n# Here's a specific version for n=2 shots per test\n\nx = hypos\nlikes = [(1-x)**4, (2*x*(1-x))**2, x**4]\nlikelihood = np.sum(likes, axis=0) \n```", "```py\n# Solution\n\n# Here's a more general version for any n shots per test\n\nfrom scipy.stats import binom\n\nn = 2\nlikes2 = [binom.pmf(k, n, x)**2 for k in range(n+1)]\nlikelihood2 = np.sum(likes2, axis=0) \n```", "```py\n# Solution\n\n# Here are the likelihoods, computed both ways\n\nimport matplotlib.pyplot as plt\n\nplt.plot(x, likelihood, label='special case')\nplt.plot(x, likelihood2, label='general formula')\ndecorate(xlabel='Probability of hitting the target',\n         ylabel='Likelihood',\n         title='Likelihood of getting the same result') \n```", "```py\n# Solution\n\nposterior = prior * likelihood\nposterior.normalize() \n```", "```py\n49.129627998379995 \n```", "```py\n# Solution\n\nposterior.plot(label='Two tests, two shots, same outcome',\n               color='C4')\ndecorate(xlabel='Probability of hitting the target',\n         ylabel='PMF',\n         title='Posterior distribution',\n         ylim=[0, 0.015]) \n```", "```py\n# Solution\n\n# Getting the same result in both tests is more likely for \n# extreme values of `x` and least likely when `x=0.5`.\n\n# In this example, the prior indicates that `x` is less than 0.5,\n# and the update gives more weight to extreme values.\n\n# So the dataset makes lower values of `x` more likely. \n```"]