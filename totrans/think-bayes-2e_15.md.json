["```py\nimport pandas as pd\n\ndf = pd.read_csv('penguins_raw.csv').dropna(subset=['Body Mass (g)'])\ndf.shape \n```", "```py\n(342, 17) \n```", "```py\ndf.head() \n```", "```py\ndef make_cdf_map(df, colname, by='Species2'):\n  \"\"\"Make a CDF for each species.\"\"\"\n    cdf_map = {}\n    grouped = df.groupby(by)[colname]\n    for species, group in grouped:\n        cdf_map[species] = Cdf.from_seq(group, name=species)\n    return cdf_map \n```", "```py\nfrom empiricaldist import Cdf\nfrom utils import decorate\n\ndef plot_cdfs(df, colname, by='Species2'):\n  \"\"\"Make a CDF for each species.\n\n df: DataFrame\n colname: string column name\n by: string column name\n\n returns: dictionary from species name to Cdf\n \"\"\"\n    cdf_map = make_cdf_map(df, colname, by)\n\n    for species, cdf in cdf_map.items():\n        cdf.plot(label=species, marker='')\n\n    decorate(xlabel=colname,\n             ylabel='CDF') \n```", "```py\ncolname = 'Culmen Length (mm)'\nplot_cdfs(df, colname) \n```", "```py\ncolname = 'Flipper Length (mm)'\nplot_cdfs(df, colname) \n```", "```py\ncolname = 'Culmen Depth (mm)'\nplot_cdfs(df, colname) \n```", "```py\ncolname = 'Body Mass (g)'\nplot_cdfs(df, colname) \n```", "```py\nfrom scipy.stats import norm\n\ndef make_norm_map(df, colname, by='Species2'):\n  \"\"\"Make a map from species to norm object.\"\"\"\n    norm_map = {}\n    grouped = df.groupby(by)[colname]\n    for species, group in grouped:\n        mean = group.mean()\n        std = group.std()\n        norm_map[species] = norm(mean, std)\n    return norm_map \n```", "```py\nflipper_map = make_norm_map(df, 'Flipper Length (mm)')\nflipper_map.keys() \n```", "```py\ndict_keys(['Adelie', 'Chinstrap', 'Gentoo']) \n```", "```py\ndata = 193\nflipper_map['Adelie'].pdf(data) \n```", "```py\n0.054732511875530694 \n```", "```py\nhypos = flipper_map.keys()\nlikelihood = [flipper_map[hypo].pdf(data) for hypo in hypos]\nlikelihood \n```", "```py\n[0.054732511875530694, 0.051721356158881626, 5.866045366199098e-05] \n```", "```py\nfrom empiricaldist import Pmf\n\nprior = Pmf(1/3, hypos)\nprior \n```", "```py\nposterior = prior * likelihood\nposterior.normalize()\nposterior \n```", "```py\ndef update_penguin(prior, data, norm_map):\n  \"\"\"Update hypothetical species.\"\"\"\n    hypos = prior.qs\n    likelihood = [norm_map[hypo].pdf(data) for hypo in hypos]\n    posterior = prior * likelihood\n    posterior.normalize()\n    return posterior \n```", "```py\nposterior1 = update_penguin(prior, 193, flipper_map)\nposterior1 \n```", "```py\nculmen_map = make_norm_map(df, 'Culmen Length (mm)') \n```", "```py\nposterior2 = update_penguin(prior, 48, culmen_map)\nposterior2 \n```", "```py\ndef update_naive(prior, data_seq, norm_maps):\n  \"\"\"Naive Bayesian classifier\n\n prior: Pmf\n data_seq: sequence of measurements\n norm_maps: sequence of maps from species to distribution\n\n returns: Pmf representing the posterior distribution\n \"\"\"\n    posterior = prior.copy()\n    for data, norm_map in zip(data_seq, norm_maps):\n        posterior = update_penguin(posterior, data, norm_map)\n    return posterior \n```", "```py\ncolnames = ['Flipper Length (mm)', 'Culmen Length (mm)']\nnorm_maps = [flipper_map, culmen_map] \n```", "```py\ndata_seq = 193, 48\nposterior = update_naive(prior, data_seq, norm_maps)\nposterior \n```", "```py\nposterior.max_prob() \n```", "```py\n'Chinstrap' \n```", "```py\nimport numpy as np\n\ndf['Classification'] = \"None\"\n\nfor i, row in df.iterrows():\n    data_seq = row[colnames]\n    posterior = update_naive(prior, data_seq, norm_maps)\n    df.loc[i, 'Classification'] = posterior.max_prob() \n```", "```py\nlen(df) \n```", "```py\n342 \n```", "```py\nvalid = df['Classification'].notna()\nvalid.sum() \n```", "```py\n342 \n```", "```py\nsame = df['Species2'] == df['Classification']\nsame.sum() \n```", "```py\n324 \n```", "```py\nsame.sum() / valid.sum() \n```", "```py\n0.9473684210526315 \n```", "```py\ndef accuracy(df):\n  \"\"\"Compute the accuracy of classification.\"\"\"\n    valid = df['Classification'].notna()\n    same = df['Species2'] == df['Classification']\n    return same.sum() / valid.sum() \n```", "```py\nimport matplotlib.pyplot as plt\n\ndef scatterplot(df, var1, var2):\n  \"\"\"Make a scatter plot.\"\"\"\n    grouped = df.groupby('Species2')\n    for species, group in grouped:\n        plt.plot(group[var1], group[var2],\n                 label=species, ls=\"None\", alpha=0.3)\n\n    decorate(xlabel=var1, ylabel=var2) \n```", "```py\nvar1 = 'Flipper Length (mm)'\nvar2 = 'Culmen Length (mm)'\nscatterplot(df, var1, var2) \n```", "```py\ndef make_pmf_norm(dist, sigmas=3, n=101):\n  \"\"\"Make a Pmf approximation to a normal distribution.\"\"\"\n    mean, std = dist.mean(), dist.std()\n    low = mean - sigmas * std\n    high = mean + sigmas * std\n    qs = np.linspace(low, high, n)\n    ps = dist.pdf(qs)\n    pmf = Pmf(ps, qs)\n    pmf.normalize()\n    return pmf \n```", "```py\nfrom utils import make_joint\n\njoint_map = {}\nfor species in hypos:\n    pmf1 = make_pmf_norm(flipper_map[species])\n    pmf2 = make_pmf_norm(culmen_map[species])\n    joint_map[species] = make_joint(pmf1, pmf2) \n```", "```py\nfrom utils import plot_contour\n\nscatterplot(df, var1, var2)\nfor species in hypos:\n    plot_contour(joint_map[species], alpha=0.5) \n```", "```py\nfeatures = df[[var1, var2]] \n```", "```py\nmean = features.mean()\nmean \n```", "```py\nFlipper Length (mm)    200.915205\nCulmen Length (mm)      43.921930\ndtype: float64 \n```", "```py\ncov = features.cov()\ncov \n```", "```py\nfrom scipy.stats import multivariate_normal\n\nmultinorm = multivariate_normal(mean, cov) \n```", "```py\ndef make_multinorm_map(df, colnames):\n  \"\"\"Make a map from each species to a multivariate normal.\"\"\"\n    multinorm_map = {}\n    grouped = df.groupby('Species2')\n    for species, group in grouped:\n        features = group[colnames]\n        mean = features.mean()\n        cov = features.cov()\n        multinorm_map[species] = multivariate_normal(mean, cov)\n    return multinorm_map \n```", "```py\nmultinorm_map = make_multinorm_map(df, [var1, var2]) \n```", "```py\nnorm1 = flipper_map['Adelie']\nnorm2 = culmen_map['Adelie']\nmultinorm = multinorm_map['Adelie'] \n```", "```py\npmf1 = make_pmf_norm(norm1)\npmf2 = make_pmf_norm(norm2) \n```", "```py\nX, Y = np.meshgrid(pmf1.qs, pmf2.qs)\nX.shape \n```", "```py\n(101, 101) \n```", "```py\npos = np.dstack((X, Y))\npos.shape \n```", "```py\n(101, 101, 2) \n```", "```py\ndensities = multinorm.pdf(pos)\ndensities.shape \n```", "```py\n(101, 101) \n```", "```py\nfrom utils import normalize\n\njoint = pd.DataFrame(densities, columns=pmf1.qs, index=pmf2.qs)\nnormalize(joint) \n```", "```py\n15.87134363991382 \n```", "```py\nplot_contour(joint)\ndecorate(xlabel=var1,\n         ylabel=var2) \n```", "```py\ndef make_joint(norm1, norm2, multinorm):\n  \"\"\"Make a joint distribution.\n\n norm1: `norm` object representing the distribution of the first feature\n norm2: `norm` object representing the distribution of the second feature\n multinorm: `multivariate_normal` object representing the joint distribution\n \"\"\"\n    pmf1 = make_pmf_norm(norm1)\n    pmf2 = make_pmf_norm(norm2)\n    X, Y = np.meshgrid(pmf1.qs, pmf2.qs)\n    pos = np.dstack((X, Y))\n    densities = multinorm.pdf(pos)\n    joint = pd.DataFrame(densities, columns=pmf1.qs, index=pmf2.qs)\n    return joint \n```", "```py\nscatterplot(df, var1, var2)\n\nfor species in hypos:\n    norm1 = flipper_map[species]\n    norm2 = culmen_map[species]\n    multinorm = multinorm_map[species]\n    joint = make_joint(norm1, norm2, multinorm)\n    plot_contour(joint, alpha=0.5) \n```", "```py\ndef update_penguin(prior, data, norm_map):\n  \"\"\"Update hypothetical species.\"\"\"\n    hypos = prior.qs\n    likelihood = [norm_map[hypo].pdf(data) for hypo in hypos]\n    posterior = prior * likelihood\n    posterior.normalize()\n    return posterior \n```", "```py\ndata = 193, 48\nupdate_penguin(prior, data, multinorm_map) \n```", "```py\ndf['Classification'] = \"None\"\n\nfor i, row in df.iterrows():\n    data = row[colnames]\n    posterior = update_penguin(prior, data, multinorm_map)\n    df.loc[i, 'Classification'] = posterior.idxmax() \n```", "```py\naccuracy(df) \n```", "```py\n0.9532163742690059 \n```", "```py\n# Solution\n\n# Here are the norm maps for the other two features\n\ndepth_map = make_norm_map(df, 'Culmen Depth (mm)')\nmass_map = make_norm_map(df, 'Body Mass (g)') \n```", "```py\n# Solution\n\n# And here are sequences for the features and the norm maps\n\ncolnames4 = ['Culmen Length (mm)', 'Flipper Length (mm)', \n             'Culmen Depth (mm)', 'Body Mass (g)']\nnorm_maps4 = [culmen_map, flipper_map, \n              depth_map, mass_map] \n```", "```py\n# Solution\n\n# Now let's classify and compute accuracy.\n\n# We can do a little better with all four features,\n# almost 97% accuracy\n\ndf['Classification'] = \"None\"\n\nfor i, row in df.iterrows():\n    data_seq = row[colnames4]\n    posterior = update_naive(prior, data_seq, norm_maps4)\n    df.loc[i, 'Classification'] = posterior.max_prob()\n\naccuracy(df) \n```", "```py\n0.9678362573099415 \n```", "```py\ngentoo = (df['Species2'] == 'Gentoo')\nsubset = df[gentoo].copy() \n```", "```py\nsubset['Sex'].value_counts() \n```", "```py\nSex\nMALE      61\nFEMALE    58\nName: count, dtype: int64 \n```", "```py\nvalid = df['Sex'] != '.'\nvalid.sum() \n```", "```py\n342 \n```", "```py\nsubset = df[valid & gentoo].copy() \n```", "```py\n# Solution\n\n# Here are the feature distributions grouped by sex\n\nplot_cdfs(subset, 'Culmen Length (mm)', by='Sex') \n```", "```py\n# Solution\n\nplot_cdfs(subset, 'Culmen Depth (mm)', by='Sex') \n```", "```py\n# Solution\n\nplot_cdfs(subset, 'Flipper Length (mm)', by='Sex') \n```", "```py\n# Solution\n\nplot_cdfs(subset, 'Body Mass (g)', by='Sex') \n```", "```py\n# Solution\n\n# Here are the norm maps for the features, grouped by sex\n\nculmen_map = make_norm_map(subset, 'Culmen Length (mm)', by='Sex')\nflipper_map = make_norm_map(subset, 'Flipper Length (mm)', by='Sex')\ndepth_map = make_norm_map(subset, 'Culmen Depth (mm)', by='Sex')\nmass_map = make_norm_map(subset, 'Body Mass (g)', by='Sex') \n```", "```py\n# Solution\n\n# And here are the sequences we need for `update_naive`\n\nnorm_maps4 = [culmen_map, flipper_map, depth_map, mass_map]\ncolnames4 = ['Culmen Length (mm)', 'Flipper Length (mm)', \n             'Culmen Depth (mm)', 'Body Mass (g)'] \n```", "```py\n# Solution\n\n# Here's the prior\n\nhypos = culmen_map.keys()\nprior = Pmf(1/2, hypos)\nprior \n```", "```py\n# Solution\n\n# And the update\n\nsubset['Classification'] = \"None\"\n\nfor i, row in subset.iterrows():\n    data_seq = row[colnames4]\n    posterior = update_naive(prior, data_seq, norm_maps4)\n    subset.loc[i, 'Classification'] = posterior.max_prob() \n```", "```py\n# Solution\n\n# This function computes accuracy\n\ndef accuracy_sex(df):\n  \"\"\"Compute the accuracy of classification.\n\n Compares columns Classification and Sex\n\n df: DataFrame\n \"\"\"\n    valid = df['Classification'].notna()\n    same = df['Sex'] == df['Classification']\n    return same.sum() / valid.sum() \n```", "```py\n# Solution\n\n# Using these features we can classify Gentoo penguins by\n# sex with almost 92% accuracy\n\naccuracy_sex(subset) \n```", "```py\n0.9186991869918699 \n```", "```py\n# Solution\n\n# Here's the whole process in a function so we can\n# classify the other species\n\ndef classify_by_sex(subset):\n  \"\"\"Run the whole classification process.\n\n subset: DataFrame\n \"\"\"\n    culmen_map = make_norm_map(subset, 'Culmen Length (mm)', by='Sex')\n    flipper_map = make_norm_map(subset, 'Flipper Length (mm)', by='Sex')\n    depth_map = make_norm_map(subset, 'Culmen Depth (mm)', by='Sex')\n    mass_map = make_norm_map(subset, 'Body Mass (g)', by='Sex')\n\n    norm_maps4 = [culmen_map, flipper_map, depth_map, mass_map]\n\n    hypos = culmen_map.keys()\n    prior = Pmf(1/2, hypos)\n\n    subset['Classification'] = \"None\"\n\n    for i, row in subset.iterrows():\n        data_seq = row[colnames4]\n        posterior = update_naive(prior, data_seq, norm_maps4)\n        subset.loc[i, 'Classification'] = posterior.max_prob()\n\n    return accuracy_sex(subset) \n```", "```py\n# Solution\n\n# Here's the subset of Adelie penguins\n\n# The accuracy is about 88%\n\nadelie = df['Species2']=='Adelie'\nsubset = df[adelie].copy()\nclassify_by_sex(subset) \n```", "```py\n0.8807947019867549 \n```", "```py\n# Solution\n\n# And for Chinstrap, accuracy is about 92%\n\nchinstrap = df['Species2']=='Chinstrap'\nsubset = df[chinstrap].copy()\nclassify_by_sex(subset) \n```", "```py\n0.9264705882352942 \n```", "```py\n# Solution\n\n# It looks like Gentoo and Chinstrap penguins are about equally\n# dimorphic, Adelie penguins a little less so.\n\n# All of these results are consistent with what's in the paper. \n```"]