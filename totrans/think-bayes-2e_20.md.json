["```py\ndownload('https://github.com/AllenDowney/ThinkBayes2/raw/master/data/2239075.csv') \n```", "```py\nimport pandas as pd\n\ndf = pd.read_csv('2239075.csv', parse_dates=[2]) \n```", "```py\ndf.tail(3) \n```", "```py\ndf['YEAR'] = df['DATE'].dt.year \n```", "```py\nsnow = df.groupby('YEAR')['SNOW'].sum() \n```", "```py\nsnow = snow.iloc[1:-1]\nlen(snow) \n```", "```py\n55 \n```", "```py\nfrom utils import decorate\n\nsnow.plot(ls='', marker='o', alpha=0.5)\n\ndecorate(xlabel='Year',\n         ylabel='Total annual snowfall (inches)',\n         title='Total annual snowfall in Norfolk County, MA') \n```", "```py\nsnow.loc[[1978, 1996, 2015]] \n```", "```py\nYEAR\n1978    100.6\n1996    124.2\n2015    141.1\nName: SNOW, dtype: float64 \n```", "```py\nfrom empiricaldist import Pmf\n\npmf_snowfall = Pmf.from_seq(snow) \n```", "```py\nmean, std = pmf_snowfall.mean(), pmf_snowfall.std()\nmean, std \n```", "```py\n(63.62363636363636, 25.851147072396568) \n```", "```py\nfrom scipy.stats import norm\n\ndist = norm(mean, std)\nqs = pmf_snowfall.qs\nps = dist.cdf(qs) \n```", "```py\nimport matplotlib.pyplot as plt\n\nplt.plot(qs, ps, color='C5', label='model')\npmf_snowfall.make_cdf().plot(label='data')\n\ndecorate(xlabel='Total snowfall (inches)',\n         ylabel='CDF',\n         title='Normal model of variation in snowfall') \n```", "```py\ndata = snow.reset_index()\ndata.head(3) \n```", "```py\noffset = round(data['YEAR'].mean())\ndata['x'] = data['YEAR'] - offset\noffset \n```", "```py\n1995 \n```", "```py\ndata['y'] = data['SNOW'] \n```", "```py\nimport statsmodels.formula.api as smf\n\nformula = 'y ~ x'\nresults = smf.ols(formula, data=data).fit()\nresults.params \n```", "```py\nIntercept    63.623636\nx             0.376421\ndtype: float64 \n```", "```py\nresults.resid.std() \n```", "```py\n25.382858670693558 \n```", "```py\nimport numpy as np\nfrom utils import make_uniform\n\nqs = np.linspace(-0.5, 1.5, 51)\nprior_slope = make_uniform(qs, 'Slope') \n```", "```py\nqs = np.linspace(54, 75, 41)\nprior_inter = make_uniform(qs, 'Intercept') \n```", "```py\nqs = np.linspace(20, 35, 31)\nprior_sigma = make_uniform(qs, 'Sigma') \n```", "```py\nfrom utils import make_joint\n\ndef make_joint3(pmf1, pmf2, pmf3):\n  \"\"\"Make a joint distribution with three parameters.\"\"\"\n    joint2 = make_joint(pmf2, pmf1).stack()\n    joint3 = make_joint(pmf3, joint2).stack()\n    return Pmf(joint3) \n```", "```py\nprior = make_joint3(prior_slope, prior_inter, prior_sigma)\nprior.head(3) \n```", "```py\nlen(prior_slope), len(prior_inter), len(prior_sigma) \n```", "```py\n(51, 41, 31) \n```", "```py\nlen(prior_slope) * len(prior_inter) * len(prior_sigma) \n```", "```py\n64821 \n```", "```py\nlen(prior) \n```", "```py\n64821 \n```", "```py\ninter = 64\nslope = 0.51\nsigma = 25 \n```", "```py\nxs = data['x']\nys = data['y'] \n```", "```py\nexpected = slope * xs + inter\nresid = ys - expected \n```", "```py\ndensities = norm(0, sigma).pdf(resid) \n```", "```py\nlikelihood = densities.prod()\nlikelihood \n```", "```py\n9.70222384229511e-112 \n```", "```py\nlikelihood = prior.copy()\n\nfor slope, inter, sigma in prior.index:\n    expected = slope * xs + inter\n    resid = ys - expected\n    densities = norm.pdf(resid, 0, sigma)\n    likelihood[slope, inter, sigma] = densities.prod() \n```", "```py\nposterior = prior * likelihood\nposterior.normalize() \n```", "```py\n5.116955523342424e-113 \n```", "```py\nposterior_slope = posterior.marginal(0)\nposterior_inter = posterior.marginal(1)\nposterior_sigma = posterior.marginal(2) \n```", "```py\nposterior_sigma.plot()\n\ndecorate(xlabel='$\\sigma$, standard deviation of $\\epsilon/details>,\n         ylabel='PDF',\n         title='Posterior marginal distribution of $\\sigma/details>) \n```", "```py\nposterior_inter.plot(color='C1')\ndecorate(xlabel='intercept (inches)',\n         ylabel='PDF',\n         title='Posterior marginal distribution of intercept') \n```", "```py\nfrom utils import summarize\n\nsummarize(posterior_inter) \n```", "```py\n63.65 [57.675 69.225] \n```", "```py\nposterior_slope.plot(color='C4')\ndecorate(xlabel='Slope (inches per year)',\n         ylabel='PDF',\n         title='Posterior marginal distribution of slope') \n```", "```py\nsummarize(posterior_slope) \n```", "```py\n0.376 [0.02 0.74] \n```", "```py\nposterior_slope.make_cdf()(0) \n```", "```py\narray(0.04584032) \n```", "```py\njoint3 = prior.unstack()\njoint3.head(3) \n```", "```py\nfrom utils import normalize\n\ndef update_optimized(prior, data):\n  \"\"\"Posterior distribution of regression parameters\n `slope`, `inter`, and `sigma`.\n\n prior: Pmf representing the joint prior\n data: DataFrame with columns `x` and `y`\n\n returns: Pmf representing the joint posterior\n \"\"\"\n    xs = data['x']\n    ys = data['y']\n    sigmas = prior.columns    \n    likelihood = prior.copy()\n\n    for slope, inter in prior.index:\n        expected = slope * xs + inter\n        resid = ys - expected\n        resid_mesh, sigma_mesh = np.meshgrid(resid, sigmas)\n        densities = norm.pdf(resid_mesh, 0, sigma_mesh)\n        likelihood.loc[slope, inter] = densities.prod(axis=1)\n\n    posterior = prior * likelihood\n    normalize(posterior)\n    return posterior \n```", "```py\nlen(prior_slope) * len(prior_inter) \n```", "```py\n2091 \n```", "```py\n%time posterior_opt = update_optimized(joint3, data) \n```", "```py\nCPU times: user 996 ms, sys: 5 \u00b5s, total: 996 ms\nWall time: 994 ms \n```", "```py\nnp.allclose(posterior, posterior_opt.stack()) \n```", "```py\nTrue \n```", "```py\nfrom utils import marginal\n\nposterior2 = marginal(posterior_opt, 1)\nposterior2.head(3) \n```", "```py\njoint_posterior = posterior2.unstack().transpose()\njoint_posterior.head(3) \n```", "```py\nfrom utils import plot_contour\n\nplot_contour(joint_posterior)\ndecorate(title='Posterior joint distribution of slope and intercept') \n```", "```py\nurl = 'https://en.wikipedia.org/wiki/Marathon_world_record_progression#Men'\ntables = pd.read_html(url)\nlen(tables) \n```", "```py\n5 \n```", "```py\n#import os\n\n#datafile = 'Marathon_world_record_progression.html'\n#download('https://github.com/AllenDowney/ThinkBayes2/raw/master/data/Marathon_world_record_progression.html')\n\n#tables = pd.read_html(datafile)\n#len(tables) \n```", "```py\ntable = tables[0]\ntable.tail(3) \n```", "```py\ntable['date'] = pd.to_datetime(table['Date'], errors='coerce')\ntable['date'].head() \n```", "```py\n0   1908-07-24\n1   1909-01-01\n2   1909-02-12\n3   1909-05-08\n4          NaT\nName: date, dtype: datetime64[ns] \n```", "```py\ntable['time'] = pd.to_timedelta(table['Time']) \n```", "```py\ntable['y'] = 26.2 / table['time'].dt.total_seconds() * 3600\ntable['y'].head() \n```", "```py\n0    8.967143\n1    9.099504\n2    9.419942\n3    9.465508\n4    9.672854\nName: y, dtype: float64 \n```", "```py\ndef plot_speeds(df):\n  \"\"\"Plot marathon world record speed as a function of time.\n\n df: DataFrame with date and mph\n \"\"\"\n    plt.axhline(13.1, color='C5', ls='--')\n    plt.plot(df['date'], df['y'], 'o', \n             label='World record speed', \n             color='C1', alpha=0.5)\n\n    decorate(xlabel='Date',\n             ylabel='Speed (mph)') \n```", "```py\nplot_speeds(table) \n```", "```py\nrecent = table['date'] > pd.to_datetime('1970')\ndata = table.loc[recent].copy()\ndata.head() \n```", "```py\nplot_speeds(data) \n```", "```py\noffset = pd.to_datetime('1995')\ntimedelta = table['date'] - offset \n```", "```py\ndata['x'] = timedelta.dt.total_seconds() / 3600 / 24 / 365.24 \n```", "```py\ndata['x'].describe() \n```", "```py\ncount    19.000000\nmean      2.161520\nstd      16.212660\nmin     -24.444201\n25%     -11.633447\n50%       4.810536\n75%      15.236557\nmax      27.732450\nName: x, dtype: float64 \n```", "```py\nimport statsmodels.formula.api as smf\n\nformula = 'y ~ x'\nresults = smf.ols(formula, data=data).fit()\nresults.params \n```", "```py\nIntercept    12.464040\nx             0.015931\ndtype: float64 \n```", "```py\nresults.resid.std() \n```", "```py\n0.04419653543387639 \n```", "```py\nqs = np.linspace(0.012, 0.018, 51)\nprior_slope = make_uniform(qs, 'Slope') \n```", "```py\nqs = np.linspace(12.4, 12.5, 41)\nprior_inter = make_uniform(qs, 'Intercept') \n```", "```py\nqs = np.linspace(0.01, 0.21, 31)\nprior_sigma = make_uniform(qs, 'Sigma') \n```", "```py\nprior = make_joint3(prior_slope, prior_inter, prior_sigma)\nprior.head() \n```", "```py\nxs = data['x']\nys = data['y']\nlikelihood = prior.copy()\n\nfor slope, inter, sigma in prior.index:\n    expected = slope * xs + inter\n    resid = ys - expected\n    densities = norm.pdf(resid, 0, sigma)\n    likelihood[slope, inter, sigma] = densities.prod() \n```", "```py\nposterior = prior * likelihood\nposterior.normalize() \n```", "```py\n1161389020603.8816 \n```", "```py\nposterior_slope = posterior.marginal(0)\nposterior_inter = posterior.marginal(1)\nposterior_sigma = posterior.marginal(2) \n```", "```py\nposterior_sigma.plot(); \n```", "```py\nposterior_inter.plot(color='C1')\ndecorate(xlabel='intercept',\n         ylabel='PDF',\n         title='Posterior marginal distribution of intercept') \n```", "```py\nsummarize(posterior_inter) \n```", "```py\n12.464 [12.445  12.4825] \n```", "```py\nposterior_slope.plot(color='C4')\ndecorate(xlabel='Slope',\n         ylabel='PDF',\n         title='Posterior marginal distribution of slope') \n```", "```py\nsummarize(posterior_slope) \n```", "```py\n0.016 [0.01476 0.01704] \n```", "```py\nsample = posterior.choice(101) \n```", "```py\nxs = np.arange(-25, 50, 2)\npred = np.empty((len(sample), len(xs)))\n\nfor i, (slope, inter, sigma) in enumerate(sample):\n    epsilon = norm(0, sigma).rvs(len(xs))\n    pred[i] = inter + slope * xs + epsilon \n```", "```py\nlow, median, high = np.percentile(pred, [5, 50, 95], axis=0) \n```", "```py\ntimes = pd.to_timedelta(xs*365.24, unit='days') + offset\n\nplt.fill_between(times, low, high, \n                 color='C2', alpha=0.1)\nplt.plot(times, median, color='C2')\n\nplot_speeds(data) \n```", "```py\nfrom scipy.interpolate import interp1d\n\nfuture = np.array([interp1d(high, xs)(13.1),\n                   interp1d(median, xs)(13.1),\n                   interp1d(low, xs)(13.1)]) \n```", "```py\ndts = pd.to_timedelta(future*365.24, unit='day') + offset\npd.DataFrame(dict(datetime=dts),\n             index=['early', 'median', 'late']) \n```", "```py\ndf = pd.read_csv('2239075.csv', parse_dates=[2])\ndf.head(3) \n```", "```py\ndf['YEAR'] = df['DATE'].dt.year \n```", "```py\ndf['TMID'] = (df['TMIN'] + df['TMAX']) / 2 \n```", "```py\ntmid = df.groupby('YEAR')['TMID'].mean()\nlen(tmid) \n```", "```py\n54 \n```", "```py\ncomplete = tmid.iloc[1:-1]\nlen(complete) \n```", "```py\n52 \n```", "```py\ncomplete.plot(ls='', marker='o', alpha=0.5)\n\ndecorate(xlabel='Year',\n         ylabel='Annual average of daily temperature (deg F)') \n```", "```py\ndata = complete.reset_index()\ndata.head() \n```", "```py\noffset = round(data['YEAR'].mean())\noffset \n```", "```py\n1994 \n```", "```py\ndata['x'] = data['YEAR'] - offset\ndata['x'].mean() \n```", "```py\n-0.5 \n```", "```py\ndata['y'] = data['TMID']\ndata['y'].std() \n```", "```py\n1.2389114009625752 \n```", "```py\nimport statsmodels.formula.api as smf\n\nformula = 'y ~ x'\nresults = smf.ols(formula, data=data).fit()\nresults.params \n```", "```py\nIntercept    49.430172\nx             0.044252\ndtype: float64 \n```", "```py\nresults.resid.std() \n```", "```py\n1.041705765390206 \n```", "```py\n# Solution\n\nqs = np.linspace(0, 0.1, num=51)\nprior_slope = make_uniform(qs, 'Slope') \n```", "```py\n# Solution\n\nqs = np.linspace(48, 52, num=41)\nprior_inter = make_uniform(qs, 'Intercept') \n```", "```py\n# Solution\n\nqs = np.linspace(0.5, 2, num=31)\nprior_sigma = make_uniform(qs, 'Sigma') \n```", "```py\n# Solution\n\nprior = make_joint3(prior_slope, prior_inter, prior_sigma)\nprior.head() \n```", "```py\n# Solution\n\nxs = data['x']\nys = data['y']\nlikelihood = prior.copy()\n\nfor slope, inter, sigma in prior.index:\n    expected = slope * xs + inter\n    resid = ys - expected\n    densities = norm.pdf(resid, 0, sigma)\n    likelihood[slope, inter, sigma] = densities.prod() \n```", "```py\n# Solution\n\nposterior = prior * likelihood\nposterior.normalize() \n```", "```py\n6.471589606597477e-36 \n```", "```py\n# Solution\n\nposterior_slope = posterior.marginal(0)\nposterior_inter = posterior.marginal(1)\nposterior_sigma = posterior.marginal(2) \n```", "```py\n# Solution\n\nposterior_inter.plot()\ndecorate(xlabel='intercept (inches)',\n         ylabel='PDF',\n         title='Posterior marginal distribution of intercept') \n```", "```py\n# Solution\n\nposterior_inter.mean(), posterior_inter.credible_interval(0.9) \n```", "```py\n(49.430172755332116, array([49.2, 49.7])) \n```", "```py\n# Solution\n\nposterior_slope.plot()\ndecorate(xlabel='Slope (inches per year)',\n         ylabel='PDF',\n         title='Posterior marginal distribution of slope') \n```", "```py\n# Solution\n\nposterior_slope.mean(), posterior_slope.credible_interval(0.9) \n```", "```py\n(0.04425308067803314, array([0.028, 0.06 ])) \n```", "```py\n# Solution\n\nsample = posterior.choice(101)\n\nyears = np.arange(1967, 2067, 2)\nxs = years - offset\n\npred = np.empty((len(sample), len(xs)))\nfor i, (slope, inter, sigma) in enumerate(sample):\n    pred[i] = inter + slope * xs + norm(0, sigma).rvs(len(xs))\n\npred.shape \n```", "```py\n(101, 50) \n```", "```py\n# Solution\n\nlow, median, high = np.percentile(pred, [5, 50, 95], axis=0)\nmedian.shape \n```", "```py\n(50,) \n```", "```py\n# Solution\n\nplt.fill_between(years, low, high, alpha=0.1)\nplt.plot(years, median, color='C0')\n\ncomplete.plot(ls='', marker='o', alpha=0.5)\n\ndecorate(xlabel='Year',\n         ylabel='Annual average of daily temperature (deg F)') \n```", "```py\n# Solution\n\n# median increase over my lifetime in degrees F\n\nmedian[-1] - median[0] \n```", "```py\n4.264154393858554 \n```"]