["```py\nimport networkx as nx\n\nG = nx.random_k_out_graph(n=8, k=2, alpha=0.75) \n```", "```py\ndef draw_graph(G):\n    nx.draw_circular(G, node_size=400, with_labels=True)\n\ndraw_graph(G) \n```", "```py\nranks_pr = nx.pagerank(G)\nranks_pr \n```", "```py\n{0: 0.1529214627122818,\n 1: 0.3707896283472802,\n 2: 0.14402452847002478,\n 3: 0.018750000000000003,\n 4: 0.18430400881769338,\n 5: 0.018750000000000003,\n 6: 0.018750000000000003,\n 7: 0.09171037165271977} \n```", "```py\nimport numpy as np\n\ndef flip(p):\n    return np.random.random() < p \n```", "```py\nfrom collections import Counter\n\ndef random_walk(G, alpha=0.85, iters=1000):\n    counter = Counter()\n    node = next(iter(G))\n\n    for _ in range(iters):\n        if flip(alpha):\n            node = np.random.choice(list(G[node]))\n        else:\n            node = np.random.choice(list(G))\n\n        counter[node] += 1\n\n    total = sum(counter.values())\n    for key in counter:\n        counter[key] /= total\n    return counter \n```", "```py\nranks_rw = random_walk(G)\nranks_rw \n```", "```py\nCounter({7: 0.093,\n         2: 0.145,\n         1: 0.39,\n         4: 0.19,\n         6: 0.019,\n         0: 0.133,\n         3: 0.009,\n         5: 0.021}) \n```", "```py\nimport pandas as pd\n\ns1 = pd.Series(ranks_pr)\ns2 = pd.Series(ranks_rw)\n\ndf = pd.DataFrame(dict(PageRank=s1, RandomWalk=s2))\ndf['Diff'] = df['RandomWalk'] - df['PageRank']\ndf*100 \n```", "```py\nM = nx.to_numpy_array(G)\nM \n```", "```py\narray([[1., 0., 0., 0., 0., 0., 0., 1.],\n       [0., 1., 0., 0., 1., 0., 0., 0.],\n       [1., 1., 0., 0., 0., 0., 0., 0.],\n       [0., 0., 1., 0., 0., 0., 0., 1.],\n       [0., 1., 1., 0., 0., 0., 0., 0.],\n       [0., 1., 0., 0., 1., 0., 0., 0.],\n       [1., 1., 0., 0., 0., 0., 0., 0.],\n       [0., 1., 1., 0., 0., 0., 0., 0.]]) \n```", "```py\nM /= M.sum(axis=1)\nM \n```", "```py\narray([[0.5, 0\\. , 0\\. , 0\\. , 0\\. , 0\\. , 0\\. , 0.5],\n       [0\\. , 0.5, 0\\. , 0\\. , 0.5, 0\\. , 0\\. , 0\\. ],\n       [0.5, 0.5, 0\\. , 0\\. , 0\\. , 0\\. , 0\\. , 0\\. ],\n       [0\\. , 0\\. , 0.5, 0\\. , 0\\. , 0\\. , 0\\. , 0.5],\n       [0\\. , 0.5, 0.5, 0\\. , 0\\. , 0\\. , 0\\. , 0\\. ],\n       [0\\. , 0.5, 0\\. , 0\\. , 0.5, 0\\. , 0\\. , 0\\. ],\n       [0.5, 0.5, 0\\. , 0\\. , 0\\. , 0\\. , 0\\. , 0\\. ],\n       [0\\. , 0.5, 0.5, 0\\. , 0\\. , 0\\. , 0\\. , 0\\. ]]) \n```", "```py\nN = len(G)\nx = np.full(N, 100)\nx \n```", "```py\narray([100, 100, 100, 100, 100, 100, 100, 100]) \n```", "```py\nx = M.T @ x\nx \n```", "```py\narray([150., 300., 150.,   0., 100.,   0.,   0., 100.]) \n```", "```py\np = np.full((N, N), 1/N)\np \n```", "```py\narray([[0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125],\n       [0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125],\n       [0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125],\n       [0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125],\n       [0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125],\n       [0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125],\n       [0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125],\n       [0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125]]) \n```", "```py\nalpha = 0.85\nGM = alpha * M + (1 - alpha) * p \n```", "```py\nx = np.full(N, 100)\n\nfor i in range(10):\n    x = GM.T @ x \n```", "```py\nranks_am = x / x.sum()\nranks_am \n```", "```py\narray([0.15293199, 0.37077494, 0.14404034, 0.01875   , 0.18427767,\n       0.01875   , 0.01875   , 0.09172506]) \n```", "```py\nimport pandas as pd\n\ns1 = pd.Series(ranks_pr)\ns2 = pd.Series(ranks_am)\n\ndf = pd.DataFrame(dict(PageRank=s1, AdjMatrix=s2))\ndf['Diff'] = df['AdjMatrix'] - df['PageRank']\ndf*100 \n```", "```py\neigenvalues, eigenvectors = np.linalg.eig(GM.T)\neigenvalues \n```", "```py\narray([ 1.00000000e+00+0.j       ,  4.25000000e-01+0.j       ,\n       -2.12500000e-01+0.3680608j, -2.12500000e-01-0.3680608j,\n        8.61220879e-17+0.j       ,  2.07547158e-18+0.j       ,\n       -1.82225683e-17+0.j       ,  0.00000000e+00+0.j       ]) \n```", "```py\nind = np.argmax(eigenvalues)\nind, eigenvalues[ind] \n```", "```py\n(0, (0.9999999999999993+0j)) \n```", "```py\nlargest = eigenvectors[:, ind]\nlargest \n```", "```py\narray([-0.32235148+0.j, -0.78161291+0.j, -0.30359969+0.j, -0.03952437+0.j,\n       -0.38850772+0.j, -0.03952437+0.j, -0.03952437+0.j, -0.19332161+0.j]) \n```", "```py\nlargest = largest.real \n```", "```py\nranks_ev = largest / largest.sum()\nranks_ev \n```", "```py\narray([0.15292059, 0.37079   , 0.14402491, 0.01875   , 0.1843045 ,\n       0.01875   , 0.01875   , 0.09171   ]) \n```", "```py\nimport pandas as pd\n\ns1 = pd.Series(ranks_pr)\ns2 = pd.Series(ranks_ev)\n\ndf = pd.DataFrame(dict(PageRank=s1, Eigenvector=s2))\ndf['Diff'] = df['Eigenvector'] - df['PageRank']\ndf*100 \n```", "```py\ndef google_matrix(G, alpha=0.85):\n  \"\"\"Returns the Google matrix of the graph.\n\n Parameters\n ----------\n G : graph\n A NetworkX graph.  Undirected graphs will be converted to a directed\n graph with two directed edges for each undirected edge.\n\n alpha : float\n The damping factor.\n\n Notes\n -----\n The matrix returned represents the transition matrix that describes the\n Markov chain used in PageRank. For PageRank to converge to a unique\n solution (i.e., a unique stationary distribution in a Markov chain), the\n transition matrix must be irreducible. In other words, it must be that\n there exists a path between every pair of nodes in the graph, or else there\n is the potential of \"rank sinks.\"\n \"\"\"\n    M = np.asmatrix(nx.to_numpy_array(G))\n    N = len(G)\n    if N == 0:\n        return M\n\n    # Personalization vector\n    p = np.repeat(1.0 / N, N)\n\n    # Dangling nodes\n    dangling_weights = p\n    dangling_nodes = np.where(M.sum(axis=1) == 0)[0]\n\n    # Assign dangling_weights to any dangling nodes \n    # (nodes with no out links)\n    for node in dangling_nodes:\n        M[node] = dangling_weights\n\n    M /= M.sum(axis=1)  # Normalize rows to sum to 1\n\n    return alpha * M + (1 - alpha) * p \n```", "```py\ndef pagerank_numpy(G, alpha=0.85):\n  \"\"\"Returns the PageRank of the nodes in the graph.\n\n PageRank computes a ranking of the nodes in the graph G based on\n the structure of the incoming links. It was originally designed as\n an algorithm to rank web pages.\n\n Parameters\n ----------\n G : graph\n A NetworkX graph.  Undirected graphs will be converted to a directed\n graph with two directed edges for each undirected edge.\n\n alpha : float, optional\n Damping parameter for PageRank, default=0.85.\n\n Returns\n -------\n pagerank : dictionary\n Dictionary of nodes with PageRank as value.\n\n Examples\n --------\n >>> G = nx.DiGraph(nx.path_graph(4))\n >>> pr = nx.pagerank_numpy(G, alpha=0.9)\n\n Notes\n -----\n The eigenvector calculation uses NumPy's interface to the LAPACK\n eigenvalue solvers.  This will be the fastest and most accurate\n for small graphs.\n\n References\n ----------\n .. [1] A. Langville and C. Meyer,\n \"A survey of eigenvector methods of web information retrieval.\"\n http://citeseer.ist.psu.edu/713792.html\n .. [2] Page, Lawrence; Brin, Sergey; Motwani, Rajeev and Winograd, Terry,\n The PageRank citation ranking: Bringing order to the Web. 1999\n http://dbpubs.stanford.edu:8090/pub/showDoc.Fulltext?lang=en&doc=1999-66&format=pdf\n \"\"\"\n    if len(G) == 0:\n        return {}\n    M = google_matrix(G, alpha)\n\n    # use numpy LAPACK solver\n    eigenvalues, eigenvectors = np.linalg.eig(M.T)\n    ind = np.argmax(eigenvalues)\n\n    # eigenvector of largest eigenvalue is at ind, normalized\n    largest = np.array(eigenvectors[:, ind]).flatten().real\n    norm = float(largest.sum())\n    return dict(zip(G, map(float, largest / norm))) \n```", "```py\npagerank_numpy(G) \n```", "```py\n{0: 0.15292058743886122,\n 1: 0.370790000338484,\n 2: 0.14402491241728307,\n 3: 0.01875000000000002,\n 4: 0.1843045001438557,\n 5: 0.018750000000000013,\n 6: 0.018750000000000013,\n 7: 0.09170999966151594} \n```"]