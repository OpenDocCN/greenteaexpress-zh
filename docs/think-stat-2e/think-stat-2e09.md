# 第八章 估计

> 原文：[`greenteapress.com/thinkstats2/html/thinkstats2009.html`](https://greenteapress.com/thinkstats2/html/thinkstats2009.html)

本章的代码在`estimation.py`中。有关下载和使用此代码的信息，请参见第[0.2]节（thinkstats2001.html#code）。

## 8.1  估计游戏

让我们玩一个游戏。我想到一个分布，你必须猜测它是什么。我给你两个提示：它是一个正态分布，这是从中抽取的一个随机样本：

`[-0.441, 1.774, -0.101, -1.138, 2.975, -2.138]`

这个分布的均值参数µ是多少？

一个选择是使用样本均值 x 作为µ的估计值。在这个例子中，x 是 0.155，所以猜测µ=0.155 是合理的。这个过程称为估计，我们使用的统计量（样本均值）称为估计量。

使用样本均值来估计µ是如此明显，以至于很难想象一个合理的替代方案。但是假设我们通过引入异常值来改变游戏。

*我在想一个分布。* 它是一个正态分布，这是一个由偶尔将小数点放错位置的不可靠调查员收集的样本。

`[-0.441, 1.774, -0.101, -1.138, 2.975, -213.8]`

现在你对µ的估计是多少？如果你使用样本均值，你的猜测是-35.12。这是最佳选择吗？还有其他选择吗？

一个选择是识别并丢弃异常值，然后计算其余部分的样本均值。另一个选择是使用中位数作为估计量。

哪个估计量是最佳的取决于情况（例如，是否存在异常值）和目标是什么。你是在尽量减少错误，还是在最大化获得正确答案的机会？

如果没有异常值，样本均值将最小化均方误差（MSE）。也就是说，如果我们玩游戏很多次，并且每次计算误差 x − µ，样本均值将最小化

| MSE =  |
| --- |

&#124; 1 &#124;

&#124;  &#124;

&#124; m &#124;

|  ∑(x − µ)²  |
| --- |

其中 m 是你玩估计游戏的次数，不要与 n 混淆，n 是用于计算 x 的样本的大小。

这是一个模拟估计游戏并计算均方根误差（RMSE）的函数，它是 MSE 的平方根：

```py
def Estimate1(n=7, m=1000):
    mu = 0
    sigma = 1

    means = []
    medians = []
    for _ in range(m):
        xs = [random.gauss(mu, sigma) for i in range(n)]
        xbar = np.mean(xs)
        median = np.median(xs)
        means.append(xbar)
        medians.append(median)

    print('rmse xbar', RMSE(means, mu))
    print('rmse median', RMSE(medians, mu)) 
```

再次，`n`是样本的大小，`m`是我们玩游戏的次数。`means`是基于 x 的估计列表。`medians`是中位数列表。

这是计算 RMSE 的函数：

```py
def RMSE(estimates, actual):
    e2 = [(estimate-actual)**2 for estimate in estimates]
    mse = np.mean(e2)
    return math.sqrt(mse) 
```

`estimates`是估计值列表；`actual`是正在估计的实际值。当然，在实践中，我们不知道`actual`；如果知道，我们就不需要估计它。这个实验的目的是比较这两个估计量的性能。

当我运行这段代码时，样本均值的 RMSE 为 0.41，这意味着如果我们使用 x 来估计 n=7 的样本的均值，我们应该预计平均偏差为 0.41。使用中位数来估计均值得到 RMSE 0.53，这证实了 x 产生了更低的 RMSE，至少对于这个例子是这样。

最小化 MSE 是一个很好的特性，但并不总是最佳策略。例如，假设我们正在估计建筑工地上的风速分布。如果估计值太高，我们可能会过度建造结构，增加成本。但如果估计值太低，建筑物可能会倒塌。因为成本作为误差的函数不对称，最小化 MSE 并不是最佳策略。

再举一个例子，假设我掷三个六面骰子，并要求你预测总数。如果你预测完全正确，你将获得奖品；否则你将一无所获。在这种情况下，最小化 MSE 的值是 10.5，但那将是一个糟糕的猜测，因为三个骰子的总数从来不会是 10.5。对于这个游戏，你需要一个具有最高获胜机会的估计量，这就是最大似然估计（MLE）。如果你选择 10 或 11，你获胜的机会是 8 分之 1，这是你能做到的最好的。

## 8.2  猜测方差

*我在考虑一个分布。* 它是一个正态分布，这是一个（熟悉的）样本：

`[-0.441, 1.774, -0.101, -1.138, 2.975, -2.138]`

你认为我的分布的方差σ²是多少？再次，显而易见的选择是使用样本方差 S²作为估计量。

| S² =  |
| --- |

&#124; 1 &#124;

&#124;  &#124;

&#124; n &#124;

|  ∑(x[i] − x)²  |
| --- |

对于大样本，S²是一个合适的估计量，但对于小样本来说，它往往偏低。由于这个不幸的特性，它被称为有偏估计量。如果在估计游戏的多次迭代之后，期望的总误差（或平均误差）为 0，则估计量是无偏的。

幸运的是，还有另一个简单的统计量是σ²的无偏估计量：

| S[n−1]² =  |
| --- |

&#124; 1 &#124;

&#124;  &#124;

&#124; n−1 &#124;

|  ∑(x[i] − x)²  |
| --- |

关于为什么 S²是有偏的，以及 S[n−1]²是无偏的证明，请参见[`wikipedia.org/wiki/Bias_of_an_estimator`](http://wikipedia.org/wiki/Bias_of_an_estimator)。

这个估计量最大的问题是它的名称和符号的使用不一致。名称“样本方差”可以指 S²或 S[n−1]²，符号 S²用于任何一个或两者。

这是一个模拟估计游戏并测试 S²和 S[n−1]²性能的函数：

```py
def Estimate2(n=7, m=1000):
    mu = 0
    sigma = 1

    estimates1 = []
    estimates2 = []
    for _ in range(m):
        xs = [random.gauss(mu, sigma) for i in range(n)]
        biased = np.var(xs)
        unbiased = np.var(xs, ddof=1)
        estimates1.append(biased)
        estimates2.append(unbiased)

    print('mean error biased', MeanError(estimates1, sigma**2))
    print('mean error unbiased', MeanError(estimates2, sigma**2)) 
```

再次，n 是样本大小，m 是我们玩游戏的次数。`np.var`默认计算 S²，如果提供参数`ddof=1`，则计算 S[n−1]²，它代表“delta 自由度”。我不会解释这个术语，但你可以在[`en.wikipedia.org/wiki/Degrees_of_freedom_(statistics)`](http://en.wikipedia.org/wiki/Degrees_of_freedom_(statistics))上了解它。

`MeanError`计算估计和实际值之间的平均差异：

```py
def MeanError(estimates, actual):
    errors = [estimate-actual for estimate in estimates]
    return np.mean(errors) 
```

当我运行这段代码时，S²的平均误差为-0.13。正如预期的那样，这个有偏估计量往往偏低。对于 S[n−1]²，平均误差为 0.014，大约是 S²的 10 倍。随着 m 的增加，我们期望 S[n−1]²的平均误差接近 0。

像 MSE 和偏差这样的性质是基于估计游戏的许多迭代的长期期望。通过运行本章中的类似模拟，我们可以比较估计量，并检查它们是否具有期望的性质。

但当你将一个估计量应用于真实数据时，你只会得到一个估计。说估计是无偏的是没有意义的；无偏是估计量的一个特性，而不是估计的特性。

在选择具有适当特性的估计量并使用它生成估计之后，下一步是描述估计的不确定性，这是下一节的主题。

## 8.3  抽样分布

假设你是一名研究野生动物保护区大猩猩的科学家。你想知道保护区成年雌性大猩猩的平均体重。为了称重它们，你必须使它们安静下来，这是危险的、昂贵的，可能对大猩猩有害的。但如果获得这些信息很重要，可能可以接受称重 9 只大猩猩的样本。假设保护区的种群是众所周知的，因此我们可以选择代表性的成年雌性大猩猩样本。我们可以使用样本均值 x 来估计未知的种群均值µ。

称重了 9 只雌性大猩猩后，你可能发现 x=90 千克，样本标准差 S=7.5 千克。样本均值是µ的无偏估计量，并且从长远来看，它最小化了 MSE。因此，如果你报告一个总结结果的单一估计，你会报告 90 千克。

但你对这个估计有多自信呢？如果你只从一个更大的种群中称重了 n=9 只大猩猩，你可能会不幸地只是偶然选择了 9 只最重的大猩猩（或者 9 只最轻的）。由随机选择引起的估计变化称为抽样误差。

为了量化抽样误差，我们可以用µ和σ的假设值模拟抽样过程，看 x 变化多少。

由于我们不知道人口中µ和σ的实际值，我们将使用估计值 x 和 S。所以我们要回答的问题是：“如果µ和σ的实际值分别为 90 公斤和 7.5 公斤，我们运行相同的实验多次，估计均值 x 会变化多少？”

以下函数回答了这个问题：

```py
def SimulateSample(mu=90, sigma=7.5, n=9, m=1000):
    means = []
    for j in range(m):
        xs = np.random.normal(mu, sigma, n)
        xbar = np.mean(xs)
        means.append(xbar)

    cdf = thinkstats2.Cdf(means)
    ci = cdf.Percentile(5), cdf.Percentile(95)
    stderr = RMSE(means, mu) 
```

`mu`和`sigma`是参数的*假设*值。`n`是样本量，我们测量的大猩猩数量。`m`是我们运行模拟的次数。

> * * *
> 
> ![](img/27c11a2c428f41ee8725ae5850149ff7.png)
> 
> | 图 8.1：x 的采样分布，带置信区间。 |
> | --- |
> 
> * * *

在每次迭代中，我们从具有给定参数的正态分布中选择`n`个值，并计算样本均值`xbar`。我们运行 1000 次模拟，然后计算估计值的分布`cdf`。结果显示在图 8.1 中。这个分布被称为估计量的采样分布。它显示了如果我们一遍又一遍地运行实验，估计值会变化多少。

采样分布的均值与µ的假设值非常接近，这意味着实验平均得出了正确的答案。经过 1000 次尝试，最低的结果是 82 公斤，最高的是 98 公斤。这个范围表明估计值可能偏差多达 8 公斤。

总结采样分布的两种常见方法：

+   标准误差（SE）是我们预计估计值平均偏离的度量。对于每个模拟实验，我们计算误差 x − µ，然后计算均方根误差（RMSE）。在这个例子中，大约是 2.5 公斤。

+   置信区间（CI）是包括给定分数的采样分布的范围。例如，90%的置信区间是从第 5 到第 95 百分位数的范围。在这个例子中，90%的 CI 是（86，94）公斤。

标准误差和置信区间是许多混淆的根源：

+   人们经常混淆标准误差和标准偏差。记住标准偏差描述了测量数量的变异性；在这个例子中，大猩猩体重的标准偏差是 7.5 公斤。标准误差描述了估计的变异性。在这个例子中，基于 9 次测量的均值的标准误差是 2.5 公斤。

    记住区别的一种方法是，随着样本量的增加，标准误差会变小；标准偏差不会。

+   人们经常认为实际参数µ有 90%的概率落在 90%的置信区间内。遗憾的是，这并不是真的。如果你想要做出这样的断言，你必须使用贝叶斯方法（见我的书《Bayes 思维》）。

    采样分布回答了一个不同的问题：通过告诉你如果你再次运行实验，估计值会变化多少，它让你对估计值的可靠性有了一个概念。

重要的是要记住，置信区间和标准误差只量化了抽样误差；也就是说，由于只测量了人口的一部分而产生的误差。采样分布并没有考虑其他误差来源，尤其是抽样偏差和测量误差，这是下一节的主题。

## 8.4 采样偏差

假设你想知道你所在城市的女性的平均体重，而不是自然保护区大猩猩的体重。你不太可能被允许选择代表性的女性样本并称重。

一个简单的替代方法是“电话抽样”；也就是说，你可以从电话簿中随机选择号码，打电话询问成年女性的体重。

电话抽样显然有局限性。例如，样本仅限于电话号码在名单上的人，因此排除了没有电话的人（可能比平均贫穷）和电话号码未列出的人（可能比平均富有）。此外，如果你白天打家庭电话，你就不太可能抽样到有工作的人。如果你只抽样接电话的人，你就不太可能抽样到共享电话线的人。

如果收入、就业和家庭规模等因素与体重有关——这是很有可能的——那么你的调查结果会受到影响。这个问题被称为抽样偏差，因为它是抽样过程的一个特性。

这种抽样过程也容易受到自我选择的影响，这是一种抽样偏差。有些人会拒绝回答问题，如果拒绝的倾向与体重有关，那么这将影响结果。

最后，如果你问人们他们的体重，而不是称量他们，结果可能不准确。即使是乐意回答的受访者，如果他们对自己的实际体重感到不舒服，也可能四舍五入。而且并非所有受访者都是乐意回答的。这些不准确性是测量误差的例子。

当你报告一个估计数量时，报告标准误差或置信区间或两者都是有用的，以便量化抽样误差。但重要的是要记住，抽样误差只是错误的一个来源，而且通常不是最大的。

## 8.5 指数分布

让我们再玩一轮估计游戏。*我在想一个分布。*它是一个指数分布，这里是一个样本：

[5.384, 4.493, 19.198, 2.790, 6.122, 12.844]

你认为这个分布的参数λ是多少？

一般来说，指数分布的均值是 1/λ，所以往回推，我们可以选择

| L = 1 / x |
| --- |

L 是λ的估计量。不仅是任何估计量；它还是最大似然估计量（见[`wikipedia.org/wiki/Exponential_distribution#Maximum_likelihood`](http://wikipedia.org/wiki/Exponential_distribution#Maximum_likelihood)）。所以如果你想最大化猜测λ的机会，L 是一个好选择。

但我们知道在存在异常值的情况下，x 不是稳健的，所以我们预计 L 也会有同样的问题。

我们可以选择一个基于样本中位数的替代方案。指数分布的中位数是 ln(2) / λ，所以再次往回推，我们可以定义一个估计量

| L[m] = ln(2) / m |
| --- |

其中 m 是样本中位数。

为了测试这些估计量的性能，我们可以模拟抽样过程：

```py
def Estimate3(n=7, m=1000):
    lam = 2

    means = []
    medians = []
    for _ in range(m):
        xs = np.random.exponential(1.0/lam, n)
        L = 1 / np.mean(xs)
        Lm = math.log(2) / thinkstats2.Median(xs)
        means.append(L)
        medians.append(Lm)

    print('rmse L', RMSE(means, lam))
    print('rmse Lm', RMSE(medians, lam))
    print('mean error L', MeanError(means, lam))
    print('mean error Lm', MeanError(medians, lam)) 
```

当我用λ=2 运行这个实验时，L 的 RMSE 为 1.1。对于基于中位数的估计量 L[m]，RMSE 为 1.8。从这个实验中我们无法判断 L 是否最小化了 MSE，但至少它似乎比 L[m]更好。

遗憾的是，似乎这两个估计量都是有偏的。对于 L，平均误差为 0.33；对于 L[m]，平均误差为 0.45。随着`m`的增加，两者都不会收敛到 0。

事实证明，x 是分布均值 1/λ的无偏估计量，但 L 不是λ的无偏估计量。

## 8.6 练习

对于以下练习，你可以在`chap08ex.ipynb`中找到起始代码。解决方案在`chap08soln.py`中。

练习 1

在本章中，我们使用* x *和中位数来估计* µ *，并发现* x *产生更低的均方误差。此外，我们使用* S² *和* S[n−1]² *来估计* σ *，并发现* S² *是有偏的，而* S[n−1]² *是无偏的。

*运行类似的实验，看看* x *和中位数是否是* µ *的有偏估计。还要检查* S² *或* S[n−1]² *哪个产生更低的 MSE。*

练习 2

*假设你从* λ=2 *的指数分布中抽取大小为* n=10 *的样本。模拟这个实验 1000 次，并绘制估计* L *的抽样分布。计算估计的标准误差和 90%的置信区间。*

*重复实验，使用几个不同的* n *值，并绘制标准误差与* n *的关系图。*

练习 3

在冰球和足球等比赛中，进球之间的时间大致呈指数分布。因此，你可以通过观察他们在一场比赛中得分的进球数来估计球队的进球率。这种估计过程与抽样进球时间有些不同，让我们看看它是如何工作的。

*编写一个函数，接受一个目标得分率`lam`，以每场比赛的进球数为单位，通过生成进球之间的时间来模拟一场比赛，直到总时间超过 1 场比赛，然后返回进球数。*

*编写另一个函数，模拟许多比赛，存储`lam`的估计值，然后计算它们的平均误差和均方根误差（RMSE）。*

*这种估计方式是否存在偏差？绘制估计的抽样分布和 90%的置信区间。标准误差是多少？随着`lam`值的增加，抽样误差会发生什么变化？*

## 8.7 术语表

+   估计：从样本推断分布参数的过程。

+   估计器：用于估计参数的统计量。

+   均方误差（MSE）：估计误差的度量。

+   均方根误差（RMSE）：MSE 的平方根，更有意义地表示典型误差的大小。

+   最大似然估计（MLE）：计算最有可能正确的点估计的估计器。

+   偏差（估计器的）：估计器在重复实验中平均偏离参数实际值的倾向。

+   抽样误差：由于样本的有限大小和由于偶然因素的变化而导致的估计误差。

+   抽样偏差：由于抽样过程不代表总体而导致的估计误差。

+   测量误差：由于数据收集或记录的不准确性而导致的估计误差。

+   抽样分布：如果实验重复多次，统计量的分布。

+   标准误差：估计的均方根误差，用于量化由于抽样误差（但不包括其他误差来源）而产生的变异性。

+   置信区间：如果实验重复多次，代表估计范围的区间。
